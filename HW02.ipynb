{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_aBFSsxql86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "6e246c55-b717-4c28-f321-d6041f50dea2"
      },
      "source": [
        "import itertools\n",
        "!pip install pymorphy2\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from collections import Counter, defaultdict\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from nltk.tokenize import sent_tokenize\n",
        "morph = MorphAnalyzer()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.4MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 7.7MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T3dfuDdp62a",
        "colab_type": "text"
      },
      "source": [
        "# Задание 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHAuTXUfqVHZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "977c1800-6d57-4b25-8dea-16a2278bf819"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/besy_dostoevsky.txt\n",
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/anna_karenina.txt\n",
        "tolstoy = open('anna_karenina.txt').read()\n",
        "dostoevsky = open('besy_dostoevsky.txt').read()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-23 20:47:27--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/besy_dostoevsky.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2334469 (2.2M) [text/plain]\n",
            "Saving to: ‘besy_dostoevsky.txt’\n",
            "\n",
            "besy_dostoevsky.txt 100%[===================>]   2.23M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-10-23 20:47:28 (21.3 MB/s) - ‘besy_dostoevsky.txt’ saved [2334469/2334469]\n",
            "\n",
            "--2019-10-23 20:47:30--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/anna_karenina.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3073442 (2.9M) [text/plain]\n",
            "Saving to: ‘anna_karenina.txt’\n",
            "\n",
            "anna_karenina.txt   100%[===================>]   2.93M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-10-23 20:47:33 (28.9 MB/s) - ‘anna_karenina.txt’ saved [3073442/3073442]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE5jwEKTqZR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(text):\n",
        "    normalized_text = [morph.parse(word.strip(punctuation))[0].normal_form for word in text.lower().split()]\n",
        "    normalized_text = [word for word in normalized_text if word]\n",
        "    return normalized_text\n",
        "\n",
        "norm_tolstoy = normalize(tolstoy)\n",
        "norm_dostoevsky = normalize(dostoevsky)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Qu9WAprFwo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2c897210-c4ee-476e-a25a-13db87a0eec7"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "sentences_tolstoy = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(tolstoy)]\n",
        "sentences_tolstoy = sentences_tolstoy[:1000]\n",
        "sentences_dostoevsky = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dostoevsky)]\n",
        "sentences_dostoevsky = sentences_dostoevsky[:1000]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw_5wlZLrJNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ngrammer(tokens, n):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se97Cs1ErWLt",
        "colab_type": "text"
      },
      "source": [
        "Биграм"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtoMh-xMrc3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unigrams_tolstoy = Counter()\n",
        "bigrams_tolstoy = Counter()\n",
        "\n",
        "for sentence in sentences_tolstoy:\n",
        "\tunigrams_tolstoy.update(sentence)\n",
        "\tbigrams_tolstoy.update(ngrammer(sentence, 2))\n",
        "\n",
        "unigrams_dostoevsky = Counter()\n",
        "bigrams_dostoevsky = Counter()\n",
        "\n",
        "for sentence in sentences_dostoevsky:\n",
        "\tunigrams_dostoevsky.update(sentence)\n",
        "\tbigrams_dostoevsky.update(ngrammer(sentence, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATF68telrvRw",
        "colab_type": "text"
      },
      "source": [
        "матрикс"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pZ7UtcVrupu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_dostoevsky = np.zeros((len(unigrams_dostoevsky), len(unigrams_dostoevsky))) # 初始值0矩阵\n",
        "id2word_dostoevsky = list(unigrams_dostoevsky) # 列表值为('word', count)\n",
        "word2id_dostoevsky = {word:i for i, word in enumerate(id2word_dostoevsky)} # 字典值为('word', count):0（矩阵行和列定位）\n",
        "\n",
        "for ngram in bigrams_dostoevsky: # 矩阵传值\n",
        "    word1, word2 = ngram.split()\n",
        "    matrix_dostoevsky[word2id_dostoevsky[word1]][word2id_dostoevsky[word2]] =  (bigrams_dostoevsky[ngram]/unigrams_dostoevsky[word1])\n",
        "\n",
        "matrix_tolstoy = np.zeros((len(unigrams_tolstoy), len(unigrams_tolstoy)))\n",
        "\n",
        "id2word_tolstoy = list(unigrams_tolstoy)\n",
        "word2id_tolstoy = {word:i for i, word in enumerate(id2word_tolstoy)}\n",
        "\n",
        "for ngram in bigrams_tolstoy:\n",
        "    word1, word2 = ngram.split()\n",
        "    matrix_tolstoy[word2id_tolstoy[word1]][word2id_tolstoy[word2]] =  (bigrams_tolstoy[ngram]/unigrams_tolstoy[word1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J3AM_i2r3T8",
        "colab_type": "text"
      },
      "source": [
        "генерация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu9EOfCMr5dM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "00874cb6-f1b6-4f2d-cda5-5d9405d74975"
      },
      "source": [
        "def generate(matrix, id2word, word2id, n=100, start='<start>'):\n",
        "    text = []\n",
        "    current_idx = word2id[start]\n",
        "    \n",
        "    for i in range(n):\n",
        "        \n",
        "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "        text.append(id2word[chosen])\n",
        "        \n",
        "        if id2word[chosen] == '<end>':\n",
        "            chosen = word2id['<start>']\n",
        "        current_idx = chosen\n",
        "    \n",
        "    return ' '.join(text)\n",
        "print(generate(matrix_dostoevsky, id2word_dostoevsky, word2id_dostoevsky).replace('<end>', '\\n'))\n",
        "print(generate(matrix_tolstoy, id2word_tolstoy, word2id_tolstoy).replace('<end>', '\\n'))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "варвар пётр \n",
            " кстати уж конечно никто и так много о портрет поэт воплотить укоризна сохраняться и не приметить до тот подписаться \n",
            " — и мы столько год в скобка что ещё не в гнев \n",
            " впрочем нет это смеяться \n",
            " — он быть возможно быть хотя в шестьдесят третье час только голова в то есть и мы стать плоть от весь это не слышать что-то страшный быть и у она и стоять уставать и даровитый человек хоть ждать ли вы свой семилетний и счесть себя дробный сам забытый и эксплуатировать труд материал собрать и о право и мы —\n",
            "оказаться что быть ребёнок когда левин войти старый гувернантка о тот боль в зоологический сад обвиснуть весь он ты другой в рука стоялый разговаривать с развратный отец удержать лёгкий туман который он \n",
            " в дом щербацкий делать но надо же вы я заплатить \n",
            " – ну в тот дело быть бы позвать ты и англичанин выработать бы калач с она вскоре после тот что даже этот молитва который она производить в рука улыбаться \n",
            " – продолжать – закричать она несколько раз как это быть \n",
            " степан аркадьй который она мало интересовать старший брат николай толстой часть население и каша блана\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClKc0Z-AvGKR",
        "colab_type": "text"
      },
      "source": [
        "триграмм"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j8gGQCfJdd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_tolstoy_2 = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(tolstoy)]\n",
        "sentences_tolstoy_2 = sentences_tolstoy_2[:1000]\n",
        "sentences_dostoevsky_2 = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dostoevsky)]\n",
        "sentences_dostoevsky_2 = sentences_dostoevsky_2[:1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnjKA5ECvIu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unigrams_tolstoy_2 = Counter()\n",
        "bigrams_tolstoy_2 = Counter()\n",
        "trigrams_tolstoy_2 = Counter()\n",
        "\n",
        "for sentence in sentences_tolstoy_2:\n",
        "  unigrams_tolstoy_2.update(sentence)\n",
        "  bigrams_tolstoy_2.update(ngrammer(sentence, 2))\n",
        "  trigrams_tolstoy.update(ngrammer(sentence, 3))\n",
        "\n",
        "unigrams_dostoevsky_2 = Counter()\n",
        "bigrams_dostoevsky_2 = Counter()\n",
        "trigrams_dostoevsky_2 = Counter()\n",
        "\n",
        "for sentence in sentences_dostoevsky_2:\n",
        "  unigrams_dostoevsky_2.update(sentence)\n",
        "  bigrams_dostoevsky_2.update(ngrammer(sentence, 2))\n",
        "  trigrams_dostoevsky_2.update(ngrammer(sentence, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GOaC6rXVWYo",
        "colab_type": "text"
      },
      "source": [
        "матрикс"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwVKBDFcVI_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_dostoevsky_2 = np.zeros((len(bigrams_dostoevsky_2), len(unigrams_dostoevsky_2))) # 初始值0矩阵\n",
        "id2word_dostoevsky_u = list(unigrams_dostoevsky_2) # 列表值为('word', count)\n",
        "word2id_dostoevsky_u = {word:i for i, word in enumerate(id2word_dostoevsky_u)} # 字典值为('word', count):0（矩阵列定位）\n",
        "id2word_dostoevsky_b = list(bigrams_dostoevsky_2) # 列表值为('word', count)\n",
        "word2id_dostoevsky_b = {word:i for i, word in enumerate(id2word_dostoevsky_b)} # 字典值为('word', count):0（矩阵行定位）\n",
        "\n",
        "for ngram in trigrams_dostoevsky_2: # 矩阵传值\n",
        "  word1, word2, word3 = ngram.split()\n",
        "  bigram = \"{} {}\".format(word1, word2)\n",
        "  matrix_dostoevsky_2[word2id_dostoevsky_b[bigram]][word2id_dostoevsky_u[word3]] =  (trigrams_dostoevsky_2[ngram]/bigrams_dostoevsky_2[bigram])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4kzav3GVQYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_tolstoy_2 = np.zeros((len(bigrams_tolstoy_2), len(unigrams_tolstoy_2)))\n",
        "id2word_tolstoy_u = list(unigrams_tolstoy_2) # 列表值为('word', count)\n",
        "word2id_tolstoy_u = {word:i for i, word in enumerate(id2word_tolstoy_u)} # 字典值为('word', count):0（矩阵列定位）\n",
        "id2word_tolstoy_b = list(bigrams_tolstoy_2) # 列表值为('word', count)\n",
        "word2id_tolstoy_b = {word:i for i, word in enumerate(id2word_tolstoy_b)} # 字典值为('word', count):0（矩阵行定位）\n",
        "\n",
        "for ngram in trigrams_tolstoy_2:\n",
        "    word1, word2, word3 = ngram.split()\n",
        "    bigram = \"{} {}\".format(word1, word2)\n",
        "    matrix_tolstoy[word2id_tolstoy_b[bigram]][word2id_tolstoy_u[word3]] =  (trigrams_tolstoy[ngram]/bigrams_tolstoy[bigram])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP7ZswK0VZSL",
        "colab_type": "text"
      },
      "source": [
        "генерация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "894f7418-0107-469f-d67f-85895d3974bf",
        "id": "UwZpB-fJC6XM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "def generate_2(matrix, id2word_u, word2id_u, id2word_b, word2id_b, start = '<start> <start>', n=100):\n",
        "    text = []\n",
        "    current_idx = word2id_b[start]\n",
        "    \n",
        "    for i in range(n):\n",
        "      chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "      text.append(id2word_u[chosen])\n",
        "        \n",
        "      if id2word_u[chosen] == '<start>' and start.split()[1] != '<start>':\n",
        "        id2word_u[chosen] = '<end>'\n",
        "        \n",
        "      if id2word_u[chosen] == '<end>':\n",
        "        chosen = word2id_b['<start> <start>']\n",
        "        \n",
        "      start = start.split()[1] + ' ' + id2word_u[chosen]\n",
        "          \n",
        "      current_idx = word2id_b[start]\n",
        "    \n",
        "    return ' '.join(text)\n",
        "print(generate_2(matrix_dostoevsky_2, id2word_dostoevsky_u, word2id_dostoevsky_u, id2word_dostoevsky_b, word2id_dostoevsky_b).replace('<end>', '\\n'))\n",
        "print(generate_2(matrix_tolstoy_2, id2word_tolstoy_u, word2id_tolstoy_u, id2word_tolstoy_b, word2id_tolstoy_b).replace('<end>', '\\n'))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-71f62a4bf0e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_dostoevsky_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word_dostoevsky_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2id_dostoevsky_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word_dostoevsky_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2id_dostoevsky_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<end>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_tolstoy_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word_tolstoy_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2id_tolstoy_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word_tolstoy_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2id_tolstoy_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<end>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-71f62a4bf0e3>\u001b[0m in \u001b[0;36mgenerate_2\u001b[0;34m(matrix, id2word_u, word2id_u, id2word_b, word2id_b, start, n)\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mid2word_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchosen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mcurrent_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2id_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'почему <start>'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv7ZGlWirRbB",
        "colab_type": "text"
      },
      "source": [
        "# Задание 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHmPVdBj1bxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re, gensim\n",
        "from gensim.utils import tokenize\n",
        "from gensim.summarization.textcleaner import split_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ADazvUyBoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = '''Президент США сообщил, что правительство Турции проинформировало о прекращении боевых действий. По его мнению, перемирие на севере Сирии будет соблюдаться постоянно.\n",
        "\n",
        "Господин Трамп назвал заслугой США перемирие, благодаря которому курды смогли спокойно покинуть границу с Турцией. «Этого добились мы, Соединенные Штаты, а не кто-то еще, никакая другая страна»,— сказал глава государства. По его словам, США удалось сохранить жизни многих курдов.\n",
        "\n",
        "Дональд Трамп сообщил, что на территории Сирии останется небольшое число военных — «в районах, где есть нефть». «Мы будем ее защищать и решим, что делать с этим в будущем»,— сказал президент США.\n",
        "\n",
        "Турция начала военную операцию «Источник мира» в Сирии 9 октября. В полночь 18 октября Анкара приостановила операцию. Ее завершили сегодня, 23 октября. Однако Турция не намерена полностью уходить с территории Сирии. В рамках договоренностей Вашингтон пообещал вывести курдские формирования за демаркационную линию в 30 км к югу от границы Сирии с Турцией. Россия и Турция начнут совместное патрулирование освобожденной курдами территории.\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmCIWVPazt2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "364d808d-b525-4bed-e644-c6ceb70340ac"
      },
      "source": [
        "sents_text = list(split_sentences(text))\n",
        "print(sents_text)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Президент США сообщил, что правительство Турции проинформировало о прекращении боевых действий.', 'По его мнению, перемирие на севере Сирии будет соблюдаться постоянно.', 'Господин Трамп назвал заслугой США перемирие, благодаря которому курды смогли спокойно покинуть границу с Турцией.', '«Этого добились мы, Соединенные Штаты, а не кто-то еще, никакая другая страна»,— сказал глава государства.', 'По его словам, США удалось сохранить жизни многих курдов.', 'Дональд Трамп сообщил, что на территории Сирии останется небольшое число военных — «в районах, где есть нефть».', '«Мы будем ее защищать и решим, что делать с этим в будущем»,— сказал президент США.', 'Турция начала военную операцию «Источник мира» в Сирии 9 октября.', 'В полночь 18 октября Анкара приостановила операцию.', 'Ее завершили сегодня, 23 октября.', 'Однако Турция не намерена полностью уходить с территории Сирии.', 'В рамках договоренностей Вашингтон пообещал вывести курдские формирования за демаркационную линию в 30 км к югу от границы Сирии с Турцией.', 'Россия и Турция начнут совместное патрулирование освобожденной курдами территории.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-mxr5W77Bq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "00164dd4-a90c-4ef0-9521-c9f76840955d"
      },
      "source": [
        "symbols_sents = []\n",
        "for sent in sents_text:\n",
        "  symbols = []\n",
        "  for smbl in sent:\n",
        "    symbols.append(smbl)\n",
        "  symbols_sents.append(symbols)\n",
        "print(symbols_sents)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['П', 'р', 'е', 'з', 'и', 'д', 'е', 'н', 'т', ' ', 'С', 'Ш', 'А', ' ', 'с', 'о', 'о', 'б', 'щ', 'и', 'л', ',', ' ', 'ч', 'т', 'о', ' ', 'п', 'р', 'а', 'в', 'и', 'т', 'е', 'л', 'ь', 'с', 'т', 'в', 'о', ' ', 'Т', 'у', 'р', 'ц', 'и', 'и', ' ', 'п', 'р', 'о', 'и', 'н', 'ф', 'о', 'р', 'м', 'и', 'р', 'о', 'в', 'а', 'л', 'о', ' ', 'о', ' ', 'п', 'р', 'е', 'к', 'р', 'а', 'щ', 'е', 'н', 'и', 'и', ' ', 'б', 'о', 'е', 'в', 'ы', 'х', ' ', 'д', 'е', 'й', 'с', 'т', 'в', 'и', 'й', '.'], ['П', 'о', ' ', 'е', 'г', 'о', ' ', 'м', 'н', 'е', 'н', 'и', 'ю', ',', ' ', 'п', 'е', 'р', 'е', 'м', 'и', 'р', 'и', 'е', ' ', 'н', 'а', ' ', 'с', 'е', 'в', 'е', 'р', 'е', ' ', 'С', 'и', 'р', 'и', 'и', ' ', 'б', 'у', 'д', 'е', 'т', ' ', 'с', 'о', 'б', 'л', 'ю', 'д', 'а', 'т', 'ь', 'с', 'я', ' ', 'п', 'о', 'с', 'т', 'о', 'я', 'н', 'н', 'о', '.'], ['Г', 'о', 'с', 'п', 'о', 'д', 'и', 'н', ' ', 'Т', 'р', 'а', 'м', 'п', ' ', 'н', 'а', 'з', 'в', 'а', 'л', ' ', 'з', 'а', 'с', 'л', 'у', 'г', 'о', 'й', ' ', 'С', 'Ш', 'А', ' ', 'п', 'е', 'р', 'е', 'м', 'и', 'р', 'и', 'е', ',', ' ', 'б', 'л', 'а', 'г', 'о', 'д', 'а', 'р', 'я', ' ', 'к', 'о', 'т', 'о', 'р', 'о', 'м', 'у', ' ', 'к', 'у', 'р', 'д', 'ы', ' ', 'с', 'м', 'о', 'г', 'л', 'и', ' ', 'с', 'п', 'о', 'к', 'о', 'й', 'н', 'о', ' ', 'п', 'о', 'к', 'и', 'н', 'у', 'т', 'ь', ' ', 'г', 'р', 'а', 'н', 'и', 'ц', 'у', ' ', 'с', ' ', 'Т', 'у', 'р', 'ц', 'и', 'е', 'й', '.'], ['«', 'Э', 'т', 'о', 'г', 'о', ' ', 'д', 'о', 'б', 'и', 'л', 'и', 'с', 'ь', ' ', 'м', 'ы', ',', ' ', 'С', 'о', 'е', 'д', 'и', 'н', 'е', 'н', 'н', 'ы', 'е', ' ', 'Ш', 'т', 'а', 'т', 'ы', ',', ' ', 'а', ' ', 'н', 'е', ' ', 'к', 'т', 'о', '-', 'т', 'о', ' ', 'е', 'щ', 'е', ',', ' ', 'н', 'и', 'к', 'а', 'к', 'а', 'я', ' ', 'д', 'р', 'у', 'г', 'а', 'я', ' ', 'с', 'т', 'р', 'а', 'н', 'а', '»', ',', '—', ' ', 'с', 'к', 'а', 'з', 'а', 'л', ' ', 'г', 'л', 'а', 'в', 'а', ' ', 'г', 'о', 'с', 'у', 'д', 'а', 'р', 'с', 'т', 'в', 'а', '.'], ['П', 'о', ' ', 'е', 'г', 'о', ' ', 'с', 'л', 'о', 'в', 'а', 'м', ',', ' ', 'С', 'Ш', 'А', ' ', 'у', 'д', 'а', 'л', 'о', 'с', 'ь', ' ', 'с', 'о', 'х', 'р', 'а', 'н', 'и', 'т', 'ь', ' ', 'ж', 'и', 'з', 'н', 'и', ' ', 'м', 'н', 'о', 'г', 'и', 'х', ' ', 'к', 'у', 'р', 'д', 'о', 'в', '.'], ['Д', 'о', 'н', 'а', 'л', 'ь', 'д', ' ', 'Т', 'р', 'а', 'м', 'п', ' ', 'с', 'о', 'о', 'б', 'щ', 'и', 'л', ',', ' ', 'ч', 'т', 'о', ' ', 'н', 'а', ' ', 'т', 'е', 'р', 'р', 'и', 'т', 'о', 'р', 'и', 'и', ' ', 'С', 'и', 'р', 'и', 'и', ' ', 'о', 'с', 'т', 'а', 'н', 'е', 'т', 'с', 'я', ' ', 'н', 'е', 'б', 'о', 'л', 'ь', 'ш', 'о', 'е', ' ', 'ч', 'и', 'с', 'л', 'о', ' ', 'в', 'о', 'е', 'н', 'н', 'ы', 'х', ' ', '—', ' ', '«', 'в', ' ', 'р', 'а', 'й', 'о', 'н', 'а', 'х', ',', ' ', 'г', 'д', 'е', ' ', 'е', 'с', 'т', 'ь', ' ', 'н', 'е', 'ф', 'т', 'ь', '»', '.'], ['«', 'М', 'ы', ' ', 'б', 'у', 'д', 'е', 'м', ' ', 'е', 'е', ' ', 'з', 'а', 'щ', 'и', 'щ', 'а', 'т', 'ь', ' ', 'и', ' ', 'р', 'е', 'ш', 'и', 'м', ',', ' ', 'ч', 'т', 'о', ' ', 'д', 'е', 'л', 'а', 'т', 'ь', ' ', 'с', ' ', 'э', 'т', 'и', 'м', ' ', 'в', ' ', 'б', 'у', 'д', 'у', 'щ', 'е', 'м', '»', ',', '—', ' ', 'с', 'к', 'а', 'з', 'а', 'л', ' ', 'п', 'р', 'е', 'з', 'и', 'д', 'е', 'н', 'т', ' ', 'С', 'Ш', 'А', '.'], ['Т', 'у', 'р', 'ц', 'и', 'я', ' ', 'н', 'а', 'ч', 'а', 'л', 'а', ' ', 'в', 'о', 'е', 'н', 'н', 'у', 'ю', ' ', 'о', 'п', 'е', 'р', 'а', 'ц', 'и', 'ю', ' ', '«', 'И', 'с', 'т', 'о', 'ч', 'н', 'и', 'к', ' ', 'м', 'и', 'р', 'а', '»', ' ', 'в', ' ', 'С', 'и', 'р', 'и', 'и', ' ', '9', ' ', 'о', 'к', 'т', 'я', 'б', 'р', 'я', '.'], ['В', ' ', 'п', 'о', 'л', 'н', 'о', 'ч', 'ь', ' ', '1', '8', ' ', 'о', 'к', 'т', 'я', 'б', 'р', 'я', ' ', 'А', 'н', 'к', 'а', 'р', 'а', ' ', 'п', 'р', 'и', 'о', 'с', 'т', 'а', 'н', 'о', 'в', 'и', 'л', 'а', ' ', 'о', 'п', 'е', 'р', 'а', 'ц', 'и', 'ю', '.'], ['Е', 'е', ' ', 'з', 'а', 'в', 'е', 'р', 'ш', 'и', 'л', 'и', ' ', 'с', 'е', 'г', 'о', 'д', 'н', 'я', ',', ' ', '2', '3', ' ', 'о', 'к', 'т', 'я', 'б', 'р', 'я', '.'], ['О', 'д', 'н', 'а', 'к', 'о', ' ', 'Т', 'у', 'р', 'ц', 'и', 'я', ' ', 'н', 'е', ' ', 'н', 'а', 'м', 'е', 'р', 'е', 'н', 'а', ' ', 'п', 'о', 'л', 'н', 'о', 'с', 'т', 'ь', 'ю', ' ', 'у', 'х', 'о', 'д', 'и', 'т', 'ь', ' ', 'с', ' ', 'т', 'е', 'р', 'р', 'и', 'т', 'о', 'р', 'и', 'и', ' ', 'С', 'и', 'р', 'и', 'и', '.'], ['В', ' ', 'р', 'а', 'м', 'к', 'а', 'х', ' ', 'д', 'о', 'г', 'о', 'в', 'о', 'р', 'е', 'н', 'н', 'о', 'с', 'т', 'е', 'й', ' ', 'В', 'а', 'ш', 'и', 'н', 'г', 'т', 'о', 'н', ' ', 'п', 'о', 'о', 'б', 'е', 'щ', 'а', 'л', ' ', 'в', 'ы', 'в', 'е', 'с', 'т', 'и', ' ', 'к', 'у', 'р', 'д', 'с', 'к', 'и', 'е', ' ', 'ф', 'о', 'р', 'м', 'и', 'р', 'о', 'в', 'а', 'н', 'и', 'я', ' ', 'з', 'а', ' ', 'д', 'е', 'м', 'а', 'р', 'к', 'а', 'ц', 'и', 'о', 'н', 'н', 'у', 'ю', ' ', 'л', 'и', 'н', 'и', 'ю', ' ', 'в', ' ', '3', '0', ' ', 'к', 'м', ' ', 'к', ' ', 'ю', 'г', 'у', ' ', 'о', 'т', ' ', 'г', 'р', 'а', 'н', 'и', 'ц', 'ы', ' ', 'С', 'и', 'р', 'и', 'и', ' ', 'с', ' ', 'Т', 'у', 'р', 'ц', 'и', 'е', 'й', '.'], ['Р', 'о', 'с', 'с', 'и', 'я', ' ', 'и', ' ', 'Т', 'у', 'р', 'ц', 'и', 'я', ' ', 'н', 'а', 'ч', 'н', 'у', 'т', ' ', 'с', 'о', 'в', 'м', 'е', 'с', 'т', 'н', 'о', 'е', ' ', 'п', 'а', 'т', 'р', 'у', 'л', 'и', 'р', 'о', 'в', 'а', 'н', 'и', 'е', ' ', 'о', 'с', 'в', 'о', 'б', 'о', 'ж', 'д', 'е', 'н', 'н', 'о', 'й', ' ', 'к', 'у', 'р', 'д', 'а', 'м', 'и', ' ', 'т', 'е', 'р', 'р', 'и', 'т', 'о', 'р', 'и', 'и', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJkCZD6a4EIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = gensim.models.Phrases(symbols_sents, scoring='npmi', threshold=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E22kU_zz4lXA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4debd0a0-bdb3-435e-df3c-65e45a6df14e"
      },
      "source": [
        "p1 = gensim.models.Phrases(p[symbols_sents], scoring='npmi', threshold=-1)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b1tDVWs4rRY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7b27e4e5-8900-41c3-8e69-74a6dde40aed"
      },
      "source": [
        "p2 = gensim.models.Phrases(p1[p[symbols_sents]], scoring='npmi', threshold=-1)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lHN61jOFOzO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "292d4845-bd7f-4ee0-95dc-b5fff6e7eec2"
      },
      "source": [
        "p3 = gensim.models.Phrases(p2[p1[p[symbols_sents]]], scoring='npmi', threshold=-1)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDqpHrG741MT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22151681-4d60-40d9-b541-21f064c70336"
      },
      "source": [
        "list(p3[p2[p1[p[symbols_sents]]]])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['П',\n",
              "  'р_е',\n",
              "  'з',\n",
              "  'и',\n",
              "  'д_е',\n",
              "  'н',\n",
              "  'т_ ',\n",
              "  'С',\n",
              "  'Ш',\n",
              "  'А',\n",
              "  ' _с',\n",
              "  'о',\n",
              "  'о_б',\n",
              "  'щ',\n",
              "  'и_л',\n",
              "  ',_ ',\n",
              "  'ч',\n",
              "  'т_о',\n",
              "  ' _п',\n",
              "  'р_а',\n",
              "  'в',\n",
              "  'и_т',\n",
              "  'е',\n",
              "  'л',\n",
              "  'ь',\n",
              "  'с_т',\n",
              "  'в_о',\n",
              "  ' _Т',\n",
              "  'у_р',\n",
              "  'ц_и',\n",
              "  'и_ ',\n",
              "  'п_р',\n",
              "  'о',\n",
              "  'и_н',\n",
              "  'ф',\n",
              "  'о_р',\n",
              "  'м_и',\n",
              "  'р_о',\n",
              "  'в_а',\n",
              "  'л',\n",
              "  'о_ ',\n",
              "  'о_ ',\n",
              "  'п_р',\n",
              "  'е',\n",
              "  'к',\n",
              "  'р_а',\n",
              "  'щ',\n",
              "  'е_н',\n",
              "  'и_и',\n",
              "  ' _б',\n",
              "  'о_е',\n",
              "  'в',\n",
              "  'ы',\n",
              "  'х',\n",
              "  ' _д',\n",
              "  'е',\n",
              "  'й',\n",
              "  'с_т',\n",
              "  'в',\n",
              "  'и',\n",
              "  'й',\n",
              "  '.'],\n",
              " ['П',\n",
              "  'о_ ',\n",
              "  'е',\n",
              "  'г_о',\n",
              "  ' ',\n",
              "  'м',\n",
              "  'н_е',\n",
              "  'н_и',\n",
              "  'ю',\n",
              "  ',_ ',\n",
              "  'п',\n",
              "  'е_р',\n",
              "  'е_м',\n",
              "  'и_р',\n",
              "  'и_е',\n",
              "  ' _н',\n",
              "  'а_ ',\n",
              "  'с',\n",
              "  'е',\n",
              "  'в',\n",
              "  'е_р',\n",
              "  'е_ ',\n",
              "  'С_и',\n",
              "  'р_и',\n",
              "  'и_ ',\n",
              "  'б',\n",
              "  'у_д',\n",
              "  'е',\n",
              "  'т_ ',\n",
              "  'с_о',\n",
              "  'б',\n",
              "  'л',\n",
              "  'ю',\n",
              "  'д_а',\n",
              "  'т_ь',\n",
              "  'с',\n",
              "  'я_ ',\n",
              "  'п_о',\n",
              "  'с_т',\n",
              "  'о',\n",
              "  'я',\n",
              "  'н_н',\n",
              "  'о',\n",
              "  '.'],\n",
              " ['Г',\n",
              "  'о_с',\n",
              "  'п_о',\n",
              "  'д',\n",
              "  'и_н',\n",
              "  ' _Т',\n",
              "  'р_а',\n",
              "  'м',\n",
              "  'п',\n",
              "  ' _н',\n",
              "  'а',\n",
              "  'з',\n",
              "  'в_а',\n",
              "  'л',\n",
              "  ' ',\n",
              "  'з_а',\n",
              "  'с',\n",
              "  'л',\n",
              "  'у',\n",
              "  'г_о',\n",
              "  'й',\n",
              "  ' _С',\n",
              "  'Ш',\n",
              "  'А',\n",
              "  ' _п',\n",
              "  'е_р',\n",
              "  'е_м',\n",
              "  'и_р',\n",
              "  'и_е',\n",
              "  ',_ ',\n",
              "  'б',\n",
              "  'л_а',\n",
              "  'г_о',\n",
              "  'д_а',\n",
              "  'р',\n",
              "  'я_ ',\n",
              "  'к',\n",
              "  'о',\n",
              "  'т_о',\n",
              "  'р_о',\n",
              "  'м',\n",
              "  'у',\n",
              "  ' _к',\n",
              "  'у_р',\n",
              "  'д',\n",
              "  'ы',\n",
              "  ' _с',\n",
              "  'м',\n",
              "  'о',\n",
              "  'г',\n",
              "  'л_и',\n",
              "  ' _с',\n",
              "  'п_о',\n",
              "  'к',\n",
              "  'о',\n",
              "  'й',\n",
              "  'н_о',\n",
              "  ' _п',\n",
              "  'о_к',\n",
              "  'и_н',\n",
              "  'у',\n",
              "  'т_ь',\n",
              "  ' _г',\n",
              "  'р_а',\n",
              "  'н_и',\n",
              "  'ц',\n",
              "  'у',\n",
              "  ' _с',\n",
              "  ' _Т',\n",
              "  'у_р',\n",
              "  'ц_и',\n",
              "  'е',\n",
              "  'й',\n",
              "  '.'],\n",
              " ['«',\n",
              "  'Э',\n",
              "  'т_о',\n",
              "  'г_о',\n",
              "  ' _д',\n",
              "  'о_б',\n",
              "  'и_л',\n",
              "  'и',\n",
              "  'с',\n",
              "  'ь_ ',\n",
              "  'м',\n",
              "  'ы',\n",
              "  ',_ ',\n",
              "  'С',\n",
              "  'о_е',\n",
              "  'д',\n",
              "  'и_н',\n",
              "  'е_н',\n",
              "  'н',\n",
              "  'ы',\n",
              "  'е_ ',\n",
              "  'Ш',\n",
              "  'т',\n",
              "  'а_т',\n",
              "  'ы',\n",
              "  ',_ ',\n",
              "  'а_ ',\n",
              "  'н_е',\n",
              "  ' _к',\n",
              "  'т_о',\n",
              "  '-',\n",
              "  'т_о',\n",
              "  ' _е',\n",
              "  'щ',\n",
              "  'е',\n",
              "  ',_ ',\n",
              "  'н_и',\n",
              "  'к_а',\n",
              "  'к_а',\n",
              "  'я_ ',\n",
              "  'д',\n",
              "  'р',\n",
              "  'у',\n",
              "  'г',\n",
              "  'а',\n",
              "  'я_ ',\n",
              "  'с_т',\n",
              "  'р_а',\n",
              "  'н_а',\n",
              "  '»',\n",
              "  ',',\n",
              "  '—',\n",
              "  ' _с',\n",
              "  'к_а',\n",
              "  'з_а',\n",
              "  'л',\n",
              "  ' _г',\n",
              "  'л_а',\n",
              "  'в_а',\n",
              "  ' _г',\n",
              "  'о_с',\n",
              "  'у_д',\n",
              "  'а',\n",
              "  'р',\n",
              "  'с_т',\n",
              "  'в_а',\n",
              "  '.'],\n",
              " ['П',\n",
              "  'о_ ',\n",
              "  'е',\n",
              "  'г_о',\n",
              "  ' _с',\n",
              "  'л',\n",
              "  'о_в',\n",
              "  'а_м',\n",
              "  ',_ ',\n",
              "  'С',\n",
              "  'Ш',\n",
              "  'А',\n",
              "  ' ',\n",
              "  'у_д',\n",
              "  'а_л',\n",
              "  'о_с',\n",
              "  'ь_ ',\n",
              "  'с_о',\n",
              "  'х',\n",
              "  'р_а',\n",
              "  'н_и',\n",
              "  'т_ь',\n",
              "  ' ',\n",
              "  'ж',\n",
              "  'и',\n",
              "  'з',\n",
              "  'н_и',\n",
              "  ' ',\n",
              "  'м',\n",
              "  'н_о',\n",
              "  'г',\n",
              "  'и',\n",
              "  'х',\n",
              "  ' _к',\n",
              "  'у_р',\n",
              "  'д',\n",
              "  'о_в',\n",
              "  '.'],\n",
              " ['Д',\n",
              "  'о',\n",
              "  'н_а',\n",
              "  'л',\n",
              "  'ь',\n",
              "  'д',\n",
              "  ' _Т',\n",
              "  'р_а',\n",
              "  'м',\n",
              "  'п',\n",
              "  ' _с',\n",
              "  'о',\n",
              "  'о_б',\n",
              "  'щ',\n",
              "  'и_л',\n",
              "  ',_ ',\n",
              "  'ч',\n",
              "  'т_о',\n",
              "  ' _н',\n",
              "  'а_ ',\n",
              "  'т_е',\n",
              "  'р',\n",
              "  'р_и',\n",
              "  'т_о',\n",
              "  'р_и',\n",
              "  'и_ ',\n",
              "  'С_и',\n",
              "  'р_и',\n",
              "  'и_ ',\n",
              "  'о_с',\n",
              "  'т',\n",
              "  'а_н',\n",
              "  'е',\n",
              "  'т',\n",
              "  'с',\n",
              "  'я_ ',\n",
              "  'н_е',\n",
              "  'б',\n",
              "  'о',\n",
              "  'л',\n",
              "  'ь',\n",
              "  'ш',\n",
              "  'о_е',\n",
              "  ' ',\n",
              "  'ч',\n",
              "  'и',\n",
              "  'с',\n",
              "  'л',\n",
              "  'о_ ',\n",
              "  'в_о',\n",
              "  'е_н',\n",
              "  'н',\n",
              "  'ы',\n",
              "  'х',\n",
              "  ' ',\n",
              "  '—',\n",
              "  ' ',\n",
              "  '«',\n",
              "  'в',\n",
              "  ' ',\n",
              "  'р_а',\n",
              "  'й',\n",
              "  'о',\n",
              "  'н_а',\n",
              "  'х',\n",
              "  ',_ ',\n",
              "  'г',\n",
              "  'д_е',\n",
              "  ' _е',\n",
              "  'с_т',\n",
              "  'ь_ ',\n",
              "  'н_е',\n",
              "  'ф',\n",
              "  'т_ь',\n",
              "  '»',\n",
              "  '.'],\n",
              " ['«',\n",
              "  'М',\n",
              "  'ы',\n",
              "  ' _б',\n",
              "  'у_д',\n",
              "  'е_м',\n",
              "  ' _е',\n",
              "  'е_ ',\n",
              "  'з_а',\n",
              "  'щ',\n",
              "  'и',\n",
              "  'щ',\n",
              "  'а_т',\n",
              "  'ь_ ',\n",
              "  'и_ ',\n",
              "  'р_е',\n",
              "  'ш',\n",
              "  'и',\n",
              "  'м',\n",
              "  ',_ ',\n",
              "  'ч',\n",
              "  'т_о',\n",
              "  ' _д',\n",
              "  'е',\n",
              "  'л_а',\n",
              "  'т_ь',\n",
              "  ' _с',\n",
              "  ' ',\n",
              "  'э',\n",
              "  'т',\n",
              "  'и',\n",
              "  'м',\n",
              "  ' _в',\n",
              "  ' _б',\n",
              "  'у_д',\n",
              "  'у',\n",
              "  'щ',\n",
              "  'е_м',\n",
              "  '»',\n",
              "  ',',\n",
              "  '—',\n",
              "  ' _с',\n",
              "  'к_а',\n",
              "  'з_а',\n",
              "  'л',\n",
              "  ' _п',\n",
              "  'р_е',\n",
              "  'з',\n",
              "  'и',\n",
              "  'д_е',\n",
              "  'н',\n",
              "  'т_ ',\n",
              "  'С',\n",
              "  'Ш',\n",
              "  'А',\n",
              "  '.'],\n",
              " ['Т_у',\n",
              "  'р_ц',\n",
              "  'и_я',\n",
              "  ' _н',\n",
              "  'а',\n",
              "  'ч',\n",
              "  'а_л',\n",
              "  'а_ ',\n",
              "  'в_о',\n",
              "  'е_н',\n",
              "  'н',\n",
              "  'у',\n",
              "  'ю_ ',\n",
              "  'о',\n",
              "  'п',\n",
              "  'е_р',\n",
              "  'а',\n",
              "  'ц_и',\n",
              "  'ю_ ',\n",
              "  '«',\n",
              "  'И',\n",
              "  'с_т',\n",
              "  'о',\n",
              "  'ч',\n",
              "  'н_и',\n",
              "  'к',\n",
              "  ' ',\n",
              "  'м_и',\n",
              "  'р_а',\n",
              "  '»',\n",
              "  ' _в',\n",
              "  ' _С',\n",
              "  'и_р',\n",
              "  'и_и',\n",
              "  ' ',\n",
              "  '9',\n",
              "  ' _о',\n",
              "  'к',\n",
              "  'т',\n",
              "  'я',\n",
              "  'б',\n",
              "  'р',\n",
              "  'я',\n",
              "  '.'],\n",
              " ['В',\n",
              "  ' _п',\n",
              "  'о',\n",
              "  'л',\n",
              "  'н_о',\n",
              "  'ч',\n",
              "  'ь_ ',\n",
              "  '1',\n",
              "  '8',\n",
              "  ' _о',\n",
              "  'к',\n",
              "  'т',\n",
              "  'я',\n",
              "  'б',\n",
              "  'р',\n",
              "  'я_ ',\n",
              "  'А',\n",
              "  'н',\n",
              "  'к_а',\n",
              "  'р_а',\n",
              "  ' _п',\n",
              "  'р_и',\n",
              "  'о_с',\n",
              "  'т',\n",
              "  'а_н',\n",
              "  'о_в',\n",
              "  'и_л',\n",
              "  'а_ ',\n",
              "  'о',\n",
              "  'п',\n",
              "  'е_р',\n",
              "  'а',\n",
              "  'ц_и',\n",
              "  'ю',\n",
              "  '.'],\n",
              " ['Е',\n",
              "  'е_ ',\n",
              "  'з_а',\n",
              "  'в',\n",
              "  'е_р',\n",
              "  'ш',\n",
              "  'и_л',\n",
              "  'и_ ',\n",
              "  'с',\n",
              "  'е',\n",
              "  'г_о',\n",
              "  'д',\n",
              "  'н',\n",
              "  'я',\n",
              "  ',_ ',\n",
              "  '2',\n",
              "  '3',\n",
              "  ' _о',\n",
              "  'к',\n",
              "  'т',\n",
              "  'я',\n",
              "  'б',\n",
              "  'р',\n",
              "  'я',\n",
              "  '.'],\n",
              " ['О',\n",
              "  'д',\n",
              "  'н_а',\n",
              "  'к',\n",
              "  'о_ ',\n",
              "  'Т_у',\n",
              "  'р_ц',\n",
              "  'и_я',\n",
              "  ' _н',\n",
              "  'е_ ',\n",
              "  'н_а',\n",
              "  'м',\n",
              "  'е_р',\n",
              "  'е_н',\n",
              "  'а_ ',\n",
              "  'п_о',\n",
              "  'л',\n",
              "  'н_о',\n",
              "  'с_т',\n",
              "  'ь',\n",
              "  'ю_ ',\n",
              "  'у',\n",
              "  'х',\n",
              "  'о',\n",
              "  'д',\n",
              "  'и_т',\n",
              "  'ь_ ',\n",
              "  'с',\n",
              "  ' ',\n",
              "  'т_е',\n",
              "  'р',\n",
              "  'р_и',\n",
              "  'т_о',\n",
              "  'р_и',\n",
              "  'и_ ',\n",
              "  'С_и',\n",
              "  'р_и',\n",
              "  'и',\n",
              "  '.'],\n",
              " ['В',\n",
              "  ' ',\n",
              "  'р_а',\n",
              "  'м',\n",
              "  'к_а',\n",
              "  'х',\n",
              "  ' _д',\n",
              "  'о',\n",
              "  'г_о',\n",
              "  'в_о',\n",
              "  'р_е',\n",
              "  'н_н',\n",
              "  'о_с',\n",
              "  'т_е',\n",
              "  'й',\n",
              "  ' ',\n",
              "  'В',\n",
              "  'а',\n",
              "  'ш',\n",
              "  'и_н',\n",
              "  'г',\n",
              "  'т_о',\n",
              "  'н',\n",
              "  ' _п',\n",
              "  'о',\n",
              "  'о_б',\n",
              "  'е',\n",
              "  'щ',\n",
              "  'а_л',\n",
              "  ' _в',\n",
              "  'ы',\n",
              "  'в',\n",
              "  'е',\n",
              "  'с_т',\n",
              "  'и_ ',\n",
              "  'к',\n",
              "  'у_р',\n",
              "  'д',\n",
              "  'с',\n",
              "  'к',\n",
              "  'и_е',\n",
              "  ' ',\n",
              "  'ф',\n",
              "  'о_р',\n",
              "  'м_и',\n",
              "  'р_о',\n",
              "  'в_а',\n",
              "  'н_и',\n",
              "  'я_ ',\n",
              "  'з_а',\n",
              "  ' _д',\n",
              "  'е_м',\n",
              "  'а',\n",
              "  'р',\n",
              "  'к_а',\n",
              "  'ц_и',\n",
              "  'о',\n",
              "  'н_н',\n",
              "  'у',\n",
              "  'ю_ ',\n",
              "  'л_и',\n",
              "  'н_и',\n",
              "  'ю_ ',\n",
              "  'в',\n",
              "  ' ',\n",
              "  '3',\n",
              "  '0',\n",
              "  ' _к',\n",
              "  'м',\n",
              "  ' _к',\n",
              "  ' ',\n",
              "  'ю',\n",
              "  'г',\n",
              "  'у',\n",
              "  ' _о',\n",
              "  'т_ ',\n",
              "  'г',\n",
              "  'р_а',\n",
              "  'н_и',\n",
              "  'ц',\n",
              "  'ы',\n",
              "  ' _С',\n",
              "  'и_р',\n",
              "  'и_и',\n",
              "  ' _с',\n",
              "  ' _Т',\n",
              "  'у_р',\n",
              "  'ц_и',\n",
              "  'е',\n",
              "  'й',\n",
              "  '.'],\n",
              " ['Р',\n",
              "  'о_с',\n",
              "  'с',\n",
              "  'и_я',\n",
              "  ' ',\n",
              "  'и_ ',\n",
              "  'Т_у',\n",
              "  'р_ц',\n",
              "  'и_я',\n",
              "  ' _н',\n",
              "  'а',\n",
              "  'ч',\n",
              "  'н',\n",
              "  'у',\n",
              "  'т_ ',\n",
              "  'с_о',\n",
              "  'в',\n",
              "  'м',\n",
              "  'е',\n",
              "  'с_т',\n",
              "  'н_о',\n",
              "  'е_ ',\n",
              "  'п',\n",
              "  'а_т',\n",
              "  'р',\n",
              "  'у',\n",
              "  'л_и',\n",
              "  'р_о',\n",
              "  'в_а',\n",
              "  'н_и',\n",
              "  'е_ ',\n",
              "  'о_с',\n",
              "  'в_о',\n",
              "  'б',\n",
              "  'о',\n",
              "  'ж',\n",
              "  'д_е',\n",
              "  'н_н',\n",
              "  'о',\n",
              "  'й',\n",
              "  ' _к',\n",
              "  'у_р',\n",
              "  'д_а',\n",
              "  'м_и',\n",
              "  ' ',\n",
              "  'т_е',\n",
              "  'р',\n",
              "  'р_и',\n",
              "  'т_о',\n",
              "  'р_и',\n",
              "  'и',\n",
              "  '.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    }
  ]
}