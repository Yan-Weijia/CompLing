{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_aBFSsxql86",
        "colab_type": "code",
        "outputId": "127a1687-149a-4fc6-9c9c-a1004e630000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "import itertools\n",
        "!pip install pymorphy2[fast]\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from collections import Counter, defaultdict\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from nltk.tokenize import sent_tokenize\n",
        "morph = MorphAnalyzer()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2[fast]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 7.3MB/s \n",
            "\u001b[?25hCollecting DAWG>=0.7.3; extra == \"fast\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c0/d8d967bcaa0b572f9dc1d878bbf5a7bfd5afa2102a5ae426731f6ce3bc26/DAWG-0.7.8.tar.gz (255kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 52.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: DAWG\n",
            "  Building wheel for DAWG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DAWG: filename=DAWG-0.7.8-cp36-cp36m-linux_x86_64.whl size=781906 sha256=1eaa882d4da88a4752b86d2a5d512334786094db520ae5f905f3523e837050f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/88/d0/4e4abc83eb8f59a71e8dbd8ba99fd5615a3af1fac1ef7f8825\n",
            "Successfully built DAWG\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts, DAWG, pymorphy2\n",
            "Successfully installed DAWG-0.7.8 dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T3dfuDdp62a",
        "colab_type": "text"
      },
      "source": [
        "# Задание 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHAuTXUfqVHZ",
        "colab_type": "code",
        "outputId": "a3bc916c-9cc4-4585-add4-7076a2755b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/besy_dostoevsky.txt\n",
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/anna_karenina.txt\n",
        "tolstoy = open('anna_karenina.txt').read()\n",
        "dostoevsky = open('besy_dostoevsky.txt').read()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-27 14:25:44--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/besy_dostoevsky.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2334469 (2.2M) [text/plain]\n",
            "Saving to: ‘besy_dostoevsky.txt’\n",
            "\n",
            "\rbesy_dostoevsky.txt   0%[                    ]       0  --.-KB/s               \rbesy_dostoevsky.txt 100%[===================>]   2.23M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-10-27 14:25:44 (23.9 MB/s) - ‘besy_dostoevsky.txt’ saved [2334469/2334469]\n",
            "\n",
            "--2019-10-27 14:25:46--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/anna_karenina.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3073442 (2.9M) [text/plain]\n",
            "Saving to: ‘anna_karenina.txt’\n",
            "\n",
            "anna_karenina.txt   100%[===================>]   2.93M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-10-27 14:25:47 (29.0 MB/s) - ‘anna_karenina.txt’ saved [3073442/3073442]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE5jwEKTqZR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(text):\n",
        "    normalized_text = [morph.parse(word.strip(punctuation))[0].normal_form for word in text.lower().split()]\n",
        "    normalized_text = [word for word in normalized_text if word]\n",
        "    return normalized_text\n",
        "\n",
        "norm_tolstoy = normalize(tolstoy)\n",
        "norm_dostoevsky = normalize(dostoevsky)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Qu9WAprFwo",
        "colab_type": "code",
        "outputId": "c42359b8-375e-46b2-d2ec-44d05d3d477f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "sentences_tolstoy = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(tolstoy)]\n",
        "sentences_tolstoy = sentences_tolstoy[:1000]\n",
        "sentences_dostoevsky = [['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dostoevsky)]\n",
        "sentences_dostoevsky = sentences_dostoevsky[:1000]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw_5wlZLrJNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ngrammer(tokens, n):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se97Cs1ErWLt",
        "colab_type": "text"
      },
      "source": [
        "Биграм"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtoMh-xMrc3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unigrams_tolstoy = Counter()\n",
        "bigrams_tolstoy = Counter()\n",
        "\n",
        "for sentence in sentences_tolstoy:\n",
        "\tunigrams_tolstoy.update(sentence)\n",
        "\tbigrams_tolstoy.update(ngrammer(sentence, 2))\n",
        "\n",
        "unigrams_dostoevsky = Counter()\n",
        "bigrams_dostoevsky = Counter()\n",
        "\n",
        "for sentence in sentences_dostoevsky:\n",
        "\tunigrams_dostoevsky.update(sentence)\n",
        "\tbigrams_dostoevsky.update(ngrammer(sentence, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATF68telrvRw",
        "colab_type": "text"
      },
      "source": [
        "матрикс"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pZ7UtcVrupu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_dostoevsky = np.zeros((len(unigrams_dostoevsky), len(unigrams_dostoevsky))) # 初始值0矩阵\n",
        "id2word_dostoevsky = list(unigrams_dostoevsky) # 列表值为('word', count)\n",
        "word2id_dostoevsky = {word:i for i, word in enumerate(id2word_dostoevsky)} # 字典值为('word', count):0（矩阵行和列定位）\n",
        "\n",
        "for ngram in bigrams_dostoevsky: # 矩阵传值\n",
        "    word1, word2 = ngram.split()\n",
        "    matrix_dostoevsky[word2id_dostoevsky[word1]][word2id_dostoevsky[word2]] =  (bigrams_dostoevsky[ngram]/unigrams_dostoevsky[word1])\n",
        "\n",
        "matrix_tolstoy = np.zeros((len(unigrams_tolstoy), len(unigrams_tolstoy)))\n",
        "\n",
        "id2word_tolstoy = list(unigrams_tolstoy)\n",
        "word2id_tolstoy = {word:i for i, word in enumerate(id2word_tolstoy)}\n",
        "\n",
        "for ngram in bigrams_tolstoy:\n",
        "    word1, word2 = ngram.split()\n",
        "    matrix_tolstoy[word2id_tolstoy[word1]][word2id_tolstoy[word2]] =  (bigrams_tolstoy[ngram]/unigrams_tolstoy[word1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J3AM_i2r3T8",
        "colab_type": "text"
      },
      "source": [
        "генерация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu9EOfCMr5dM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(matrix, id2word, word2id, n=100, start='<start>'):\n",
        "    text = []\n",
        "    current_idx = word2id[start]\n",
        "    \n",
        "    for i in range(n):\n",
        "        \n",
        "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "        text.append(id2word[chosen])\n",
        "        \n",
        "        if id2word[chosen] == '<end>':\n",
        "            chosen = word2id['<start>']\n",
        "        current_idx = chosen\n",
        "    \n",
        "    return ' '.join(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DfLDW-5taT4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "745ae2af-7198-4d80-a39d-e5d8e145ec0c"
      },
      "source": [
        "print(generate(matrix_dostoevsky, id2word_dostoevsky, word2id_dostoevsky).replace('<end>', '\\n'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "однажды в тринадцать год неутешный прасковья иван осип приходиться совершенно пред он безжалостно освистать так он с он за окно приглядываться к губернатор наш франт смотреть очень уж очень скоро начать обожание вопить теперь уважаю» но это быть в город от скворешник не мочь быть ещё с средство и частенько полёживать на чёрный кон и к он и не знать верно не захотеть тотчас же степан трофим отклонить предложение мамаша и степан трофим и это невинный привычка \n",
            " губернатор как изволить почивать и запоминать такой тонкий и домашний анекдотец \n",
            " видеть как бы и плакать \n",
            " супруг весь они и\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bla7bT6lta3V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "004a6633-730c-4638-dae8-23c6aeaa62fb"
      },
      "source": [
        "print(generate(matrix_tolstoy, id2word_tolstoy, word2id_tolstoy).replace('<end>', '\\n'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "место начальник один \n",
            " левин тотчас заметить изменение она одежда ни в ожидание когда в москва как хотеть слышать она \n",
            " – подхватить степан аркадьй покачивать голова на знакомый игра она манер grande dame – и почему он не иметь взгляд оглядеть с отчаянный он это \n",
            " это признак тот пора чтобы разъяснить недоразумение возникнуть между палец бумага из этот предмет который он быть ты приказать доложить \n",
            " – ну разумеется – нешто выйти из совокупность весь готовый на современность и мастер кататься \n",
            " он лицо он \n",
            " левин войти к матерь \n",
            " «там видно обойтись надо же женщины» –\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClKc0Z-AvGKR",
        "colab_type": "text"
      },
      "source": [
        "триграмм"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j8gGQCfJdd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_tolstoy_2 = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(tolstoy)]\n",
        "sentences_tolstoy_2 = sentences_tolstoy_2[:1000]\n",
        "sentences_dostoevsky_2 = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dostoevsky)]\n",
        "sentences_dostoevsky_2 = sentences_dostoevsky_2[:1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnjKA5ECvIu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unigrams_tolstoy_2 = Counter()\n",
        "bigrams_tolstoy_2 = Counter()\n",
        "trigrams_tolstoy_2 = Counter()\n",
        "\n",
        "for sentence in sentences_tolstoy_2:\n",
        "  unigrams_tolstoy_2.update(sentence)\n",
        "  bigrams_tolstoy_2.update(ngrammer(sentence, 2))\n",
        "  trigrams_tolstoy_2.update(ngrammer(sentence, 3))\n",
        "\n",
        "unigrams_dostoevsky_2 = Counter()\n",
        "bigrams_dostoevsky_2 = Counter()\n",
        "trigrams_dostoevsky_2 = Counter()\n",
        "\n",
        "for sentence in sentences_dostoevsky_2:\n",
        "  unigrams_dostoevsky_2.update(sentence)\n",
        "  bigrams_dostoevsky_2.update(ngrammer(sentence, 2))\n",
        "  trigrams_dostoevsky_2.update(ngrammer(sentence, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GOaC6rXVWYo",
        "colab_type": "text"
      },
      "source": [
        "матрикс"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwVKBDFcVI_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_dostoevsky_2 = np.zeros((len(bigrams_dostoevsky_2), len(unigrams_dostoevsky_2))) # 初始值0矩阵\n",
        "id2word_dostoevsky_u = list(unigrams_dostoevsky_2) # 列表值为('word', count)\n",
        "word2id_dostoevsky_u = {word:i for i, word in enumerate(id2word_dostoevsky_u)} # 字典值为('word', count):0（矩阵列定位）\n",
        "id2word_dostoevsky_b = list(bigrams_dostoevsky_2) # 列表值为('word', count)\n",
        "word2id_dostoevsky_b = {word:i for i, word in enumerate(id2word_dostoevsky_b)} # 字典值为('word', count):0（矩阵行定位）\n",
        "\n",
        "for ngram in trigrams_dostoevsky_2: # 矩阵传值\n",
        "  word1, word2, word3 = ngram.split()\n",
        "  bigram = \"{} {}\".format(word1, word2)\n",
        "  matrix_dostoevsky_2[word2id_dostoevsky_b[bigram]][word2id_dostoevsky_u[word3]] =  (trigrams_dostoevsky_2[ngram]/bigrams_dostoevsky_2[bigram])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4kzav3GVQYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_tolstoy_2 = np.zeros((len(bigrams_tolstoy_2), len(unigrams_tolstoy_2)))\n",
        "id2word_tolstoy_u = list(unigrams_tolstoy_2) # 列表值为('word', count)\n",
        "word2id_tolstoy_u = {word:i for i, word in enumerate(id2word_tolstoy_u)} # 字典值为('word', count):0（矩阵列定位）\n",
        "id2word_tolstoy_b = list(bigrams_tolstoy_2) # 列表值为('word', count)\n",
        "word2id_tolstoy_b = {word:i for i, word in enumerate(id2word_tolstoy_b)} # 字典值为('word', count):0（矩阵行定位）\n",
        "\n",
        "for ngram in trigrams_tolstoy_2:\n",
        "    word1, word2, word3 = ngram.split()\n",
        "    bigram = \"{} {}\".format(word1, word2)\n",
        "    matrix_tolstoy_2[word2id_tolstoy_b[bigram]][word2id_tolstoy_u[word3]] =  (trigrams_tolstoy_2[ngram]/bigrams_tolstoy_2[bigram])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP7ZswK0VZSL",
        "colab_type": "text"
      },
      "source": [
        "генерация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UwZpB-fJC6XM",
        "colab": {}
      },
      "source": [
        "def generate_2(matrix, id2word_u, word2id_u, id2word_b, word2id_b, start = '<start> <start>', n=100):\n",
        "    text = []\n",
        "    current_idx = word2id_b[start]\n",
        "    \n",
        "    for i in range(n):\n",
        "      chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
        "      text.append(id2word_u[chosen])\n",
        "        \n",
        "      start = start.split()[1] + ' ' + id2word_u[chosen]\n",
        "        \n",
        "      if id2word_u[chosen] == '<end>':\n",
        "        start = '<start> <start>'\n",
        "          \n",
        "      current_idx = word2id_b[start]\n",
        "    \n",
        "    return ' '.join(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJwRfhwommqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "eefa2bc0-5e41-461d-d489-a3acdbf61175"
      },
      "source": [
        "print(generate_2(matrix_dostoevsky_2, id2word_dostoevsky_u, word2id_dostoevsky_u, id2word_dostoevsky_b, word2id_dostoevsky_b).replace('<end>', '\\n'))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "степан трофим несколько раз и иногда после самый оживлённый и поэтический разговор они дружески расстаться горячо пожать друг друг в объятие не весь о один какой-нибудь домашний анекдотец \n",
            " в один лишь излияние самый чувствительный любовь к он талантам» \n",
            " но хроника она не иметь столько значение и влияние как в последний год стать член кружка \n",
            " да н-н-ничего большой \n",
            " но в удовлетворительный вид и если возможно войти в они \n",
            " весь этот публика знать не знать как тут судить но вероятный что ничто не желать потому что ведь весь это она доставляться но у она быть несколько изящный\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtKkeVT2mpXf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "6412a8d1-fd70-4549-bff7-ce9ff1e6cab7"
      },
      "source": [
        "print(generate_2(matrix_tolstoy_2, id2word_tolstoy_u, word2id_tolstoy_u, id2word_tolstoy_b, word2id_tolstoy_b).replace('<end>', '\\n'))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "– а у я настоящее – так я иногда кажется \n",
            " левин молчать поглядывать на степан аркадьй с салфетка и карточка в рука ожидать приказание \n",
            " – да я непременно поехать – отвечать облонский \n",
            " и то в этот таинственность совершаться \n",
            " – я быть пьян… ну ты как поживать \n",
            " когда он быть нужный так как краснеть взрослый человек – слегка сам тот не замечать но так как краснеть взрослый человек – слегка сам тот не замечать но так как краснеть мальчик – чувствовать что бояться он и он такой земной низменный существо что не удержаться \n",
            " – я\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKWRQN118P3U",
        "colab_type": "text"
      },
      "source": [
        "Сравнение:\n",
        "\n",
        "> биграм: \n",
        "\n",
        "1. Имеет более достоверную статистическую информацию, обладает больше верностью и практичностью;  \n",
        "2.  Имеет меньше ограниченную информацию для следующего слова и обладает меньше различимостью.\n",
        "\n",
        "> триграм: \n",
        "\n",
        "1.  Имеет больше ограниченную информацию для следующего слова и обладает больше различимостью;\n",
        "2.  Нехватка длинности текста может привести к искажению вероятности; \n",
        "3.  занимает слишком великое пространство.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv7ZGlWirRbB",
        "colab_type": "text"
      },
      "source": [
        "# Задание 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHmPVdBj1bxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re, gensim\n",
        "from gensim.utils import tokenize\n",
        "from gensim.summarization.textcleaner import split_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ADazvUyBoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = '''Президент США сообщил, что правительство Турции проинформировало о прекращении боевых действий. По его мнению, перемирие на севере Сирии будет соблюдаться постоянно.\n",
        "\n",
        "Господин Трамп назвал заслугой США перемирие, благодаря которому курды смогли спокойно покинуть границу с Турцией. «Этого добились мы, Соединенные Штаты, а не кто-то еще, никакая другая страна»,— сказал глава государства. По его словам, США удалось сохранить жизни многих курдов.\n",
        "\n",
        "Дональд Трамп сообщил, что на территории Сирии останется небольшое число военных — «в районах, где есть нефть». «Мы будем ее защищать и решим, что делать с этим в будущем»,— сказал президент США.\n",
        "\n",
        "Турция начала военную операцию «Источник мира» в Сирии 9 октября. В полночь 18 октября Анкара приостановила операцию. Ее завершили сегодня, 23 октября. Однако Турция не намерена полностью уходить с территории Сирии. В рамках договоренностей Вашингтон пообещал вывести курдские формирования за демаркационную линию в 30 км к югу от границы Сирии с Турцией. Россия и Турция начнут совместное патрулирование освобожденной курдами территории.\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmCIWVPazt2V",
        "colab_type": "code",
        "outputId": "3f3ae7dd-8f39-435f-982c-e98ce399ebc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "sents_text = list(split_sentences(text))\n",
        "print(sents_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Президент США сообщил, что правительство Турции проинформировало о прекращении боевых действий.', 'По его мнению, перемирие на севере Сирии будет соблюдаться постоянно.', 'Господин Трамп назвал заслугой США перемирие, благодаря которому курды смогли спокойно покинуть границу с Турцией.', '«Этого добились мы, Соединенные Штаты, а не кто-то еще, никакая другая страна»,— сказал глава государства.', 'По его словам, США удалось сохранить жизни многих курдов.', 'Дональд Трамп сообщил, что на территории Сирии останется небольшое число военных — «в районах, где есть нефть».', '«Мы будем ее защищать и решим, что делать с этим в будущем»,— сказал президент США.', 'Турция начала военную операцию «Источник мира» в Сирии 9 октября.', 'В полночь 18 октября Анкара приостановила операцию.', 'Ее завершили сегодня, 23 октября.', 'Однако Турция не намерена полностью уходить с территории Сирии.', 'В рамках договоренностей Вашингтон пообещал вывести курдские формирования за демаркационную линию в 30 км к югу от границы Сирии с Турцией.', 'Россия и Турция начнут совместное патрулирование освобожденной курдами территории.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-mxr5W77Bq6",
        "colab_type": "code",
        "outputId": "e49deca5-73e9-48db-e5e0-9a2a825b5c05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "symbols_sents = []\n",
        "for sent in sents_text:\n",
        "  symbols = []\n",
        "  for smbl in sent:\n",
        "    symbols.append(smbl)\n",
        "  symbols_sents.append(symbols)\n",
        "print(symbols_sents)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['П', 'р', 'е', 'з', 'и', 'д', 'е', 'н', 'т', ' ', 'С', 'Ш', 'А', ' ', 'с', 'о', 'о', 'б', 'щ', 'и', 'л', ',', ' ', 'ч', 'т', 'о', ' ', 'п', 'р', 'а', 'в', 'и', 'т', 'е', 'л', 'ь', 'с', 'т', 'в', 'о', ' ', 'Т', 'у', 'р', 'ц', 'и', 'и', ' ', 'п', 'р', 'о', 'и', 'н', 'ф', 'о', 'р', 'м', 'и', 'р', 'о', 'в', 'а', 'л', 'о', ' ', 'о', ' ', 'п', 'р', 'е', 'к', 'р', 'а', 'щ', 'е', 'н', 'и', 'и', ' ', 'б', 'о', 'е', 'в', 'ы', 'х', ' ', 'д', 'е', 'й', 'с', 'т', 'в', 'и', 'й', '.'], ['П', 'о', ' ', 'е', 'г', 'о', ' ', 'м', 'н', 'е', 'н', 'и', 'ю', ',', ' ', 'п', 'е', 'р', 'е', 'м', 'и', 'р', 'и', 'е', ' ', 'н', 'а', ' ', 'с', 'е', 'в', 'е', 'р', 'е', ' ', 'С', 'и', 'р', 'и', 'и', ' ', 'б', 'у', 'д', 'е', 'т', ' ', 'с', 'о', 'б', 'л', 'ю', 'д', 'а', 'т', 'ь', 'с', 'я', ' ', 'п', 'о', 'с', 'т', 'о', 'я', 'н', 'н', 'о', '.'], ['Г', 'о', 'с', 'п', 'о', 'д', 'и', 'н', ' ', 'Т', 'р', 'а', 'м', 'п', ' ', 'н', 'а', 'з', 'в', 'а', 'л', ' ', 'з', 'а', 'с', 'л', 'у', 'г', 'о', 'й', ' ', 'С', 'Ш', 'А', ' ', 'п', 'е', 'р', 'е', 'м', 'и', 'р', 'и', 'е', ',', ' ', 'б', 'л', 'а', 'г', 'о', 'д', 'а', 'р', 'я', ' ', 'к', 'о', 'т', 'о', 'р', 'о', 'м', 'у', ' ', 'к', 'у', 'р', 'д', 'ы', ' ', 'с', 'м', 'о', 'г', 'л', 'и', ' ', 'с', 'п', 'о', 'к', 'о', 'й', 'н', 'о', ' ', 'п', 'о', 'к', 'и', 'н', 'у', 'т', 'ь', ' ', 'г', 'р', 'а', 'н', 'и', 'ц', 'у', ' ', 'с', ' ', 'Т', 'у', 'р', 'ц', 'и', 'е', 'й', '.'], ['«', 'Э', 'т', 'о', 'г', 'о', ' ', 'д', 'о', 'б', 'и', 'л', 'и', 'с', 'ь', ' ', 'м', 'ы', ',', ' ', 'С', 'о', 'е', 'д', 'и', 'н', 'е', 'н', 'н', 'ы', 'е', ' ', 'Ш', 'т', 'а', 'т', 'ы', ',', ' ', 'а', ' ', 'н', 'е', ' ', 'к', 'т', 'о', '-', 'т', 'о', ' ', 'е', 'щ', 'е', ',', ' ', 'н', 'и', 'к', 'а', 'к', 'а', 'я', ' ', 'д', 'р', 'у', 'г', 'а', 'я', ' ', 'с', 'т', 'р', 'а', 'н', 'а', '»', ',', '—', ' ', 'с', 'к', 'а', 'з', 'а', 'л', ' ', 'г', 'л', 'а', 'в', 'а', ' ', 'г', 'о', 'с', 'у', 'д', 'а', 'р', 'с', 'т', 'в', 'а', '.'], ['П', 'о', ' ', 'е', 'г', 'о', ' ', 'с', 'л', 'о', 'в', 'а', 'м', ',', ' ', 'С', 'Ш', 'А', ' ', 'у', 'д', 'а', 'л', 'о', 'с', 'ь', ' ', 'с', 'о', 'х', 'р', 'а', 'н', 'и', 'т', 'ь', ' ', 'ж', 'и', 'з', 'н', 'и', ' ', 'м', 'н', 'о', 'г', 'и', 'х', ' ', 'к', 'у', 'р', 'д', 'о', 'в', '.'], ['Д', 'о', 'н', 'а', 'л', 'ь', 'д', ' ', 'Т', 'р', 'а', 'м', 'п', ' ', 'с', 'о', 'о', 'б', 'щ', 'и', 'л', ',', ' ', 'ч', 'т', 'о', ' ', 'н', 'а', ' ', 'т', 'е', 'р', 'р', 'и', 'т', 'о', 'р', 'и', 'и', ' ', 'С', 'и', 'р', 'и', 'и', ' ', 'о', 'с', 'т', 'а', 'н', 'е', 'т', 'с', 'я', ' ', 'н', 'е', 'б', 'о', 'л', 'ь', 'ш', 'о', 'е', ' ', 'ч', 'и', 'с', 'л', 'о', ' ', 'в', 'о', 'е', 'н', 'н', 'ы', 'х', ' ', '—', ' ', '«', 'в', ' ', 'р', 'а', 'й', 'о', 'н', 'а', 'х', ',', ' ', 'г', 'д', 'е', ' ', 'е', 'с', 'т', 'ь', ' ', 'н', 'е', 'ф', 'т', 'ь', '»', '.'], ['«', 'М', 'ы', ' ', 'б', 'у', 'д', 'е', 'м', ' ', 'е', 'е', ' ', 'з', 'а', 'щ', 'и', 'щ', 'а', 'т', 'ь', ' ', 'и', ' ', 'р', 'е', 'ш', 'и', 'м', ',', ' ', 'ч', 'т', 'о', ' ', 'д', 'е', 'л', 'а', 'т', 'ь', ' ', 'с', ' ', 'э', 'т', 'и', 'м', ' ', 'в', ' ', 'б', 'у', 'д', 'у', 'щ', 'е', 'м', '»', ',', '—', ' ', 'с', 'к', 'а', 'з', 'а', 'л', ' ', 'п', 'р', 'е', 'з', 'и', 'д', 'е', 'н', 'т', ' ', 'С', 'Ш', 'А', '.'], ['Т', 'у', 'р', 'ц', 'и', 'я', ' ', 'н', 'а', 'ч', 'а', 'л', 'а', ' ', 'в', 'о', 'е', 'н', 'н', 'у', 'ю', ' ', 'о', 'п', 'е', 'р', 'а', 'ц', 'и', 'ю', ' ', '«', 'И', 'с', 'т', 'о', 'ч', 'н', 'и', 'к', ' ', 'м', 'и', 'р', 'а', '»', ' ', 'в', ' ', 'С', 'и', 'р', 'и', 'и', ' ', '9', ' ', 'о', 'к', 'т', 'я', 'б', 'р', 'я', '.'], ['В', ' ', 'п', 'о', 'л', 'н', 'о', 'ч', 'ь', ' ', '1', '8', ' ', 'о', 'к', 'т', 'я', 'б', 'р', 'я', ' ', 'А', 'н', 'к', 'а', 'р', 'а', ' ', 'п', 'р', 'и', 'о', 'с', 'т', 'а', 'н', 'о', 'в', 'и', 'л', 'а', ' ', 'о', 'п', 'е', 'р', 'а', 'ц', 'и', 'ю', '.'], ['Е', 'е', ' ', 'з', 'а', 'в', 'е', 'р', 'ш', 'и', 'л', 'и', ' ', 'с', 'е', 'г', 'о', 'д', 'н', 'я', ',', ' ', '2', '3', ' ', 'о', 'к', 'т', 'я', 'б', 'р', 'я', '.'], ['О', 'д', 'н', 'а', 'к', 'о', ' ', 'Т', 'у', 'р', 'ц', 'и', 'я', ' ', 'н', 'е', ' ', 'н', 'а', 'м', 'е', 'р', 'е', 'н', 'а', ' ', 'п', 'о', 'л', 'н', 'о', 'с', 'т', 'ь', 'ю', ' ', 'у', 'х', 'о', 'д', 'и', 'т', 'ь', ' ', 'с', ' ', 'т', 'е', 'р', 'р', 'и', 'т', 'о', 'р', 'и', 'и', ' ', 'С', 'и', 'р', 'и', 'и', '.'], ['В', ' ', 'р', 'а', 'м', 'к', 'а', 'х', ' ', 'д', 'о', 'г', 'о', 'в', 'о', 'р', 'е', 'н', 'н', 'о', 'с', 'т', 'е', 'й', ' ', 'В', 'а', 'ш', 'и', 'н', 'г', 'т', 'о', 'н', ' ', 'п', 'о', 'о', 'б', 'е', 'щ', 'а', 'л', ' ', 'в', 'ы', 'в', 'е', 'с', 'т', 'и', ' ', 'к', 'у', 'р', 'д', 'с', 'к', 'и', 'е', ' ', 'ф', 'о', 'р', 'м', 'и', 'р', 'о', 'в', 'а', 'н', 'и', 'я', ' ', 'з', 'а', ' ', 'д', 'е', 'м', 'а', 'р', 'к', 'а', 'ц', 'и', 'о', 'н', 'н', 'у', 'ю', ' ', 'л', 'и', 'н', 'и', 'ю', ' ', 'в', ' ', '3', '0', ' ', 'к', 'м', ' ', 'к', ' ', 'ю', 'г', 'у', ' ', 'о', 'т', ' ', 'г', 'р', 'а', 'н', 'и', 'ц', 'ы', ' ', 'С', 'и', 'р', 'и', 'и', ' ', 'с', ' ', 'Т', 'у', 'р', 'ц', 'и', 'е', 'й', '.'], ['Р', 'о', 'с', 'с', 'и', 'я', ' ', 'и', ' ', 'Т', 'у', 'р', 'ц', 'и', 'я', ' ', 'н', 'а', 'ч', 'н', 'у', 'т', ' ', 'с', 'о', 'в', 'м', 'е', 'с', 'т', 'н', 'о', 'е', ' ', 'п', 'а', 'т', 'р', 'у', 'л', 'и', 'р', 'о', 'в', 'а', 'н', 'и', 'е', ' ', 'о', 'с', 'в', 'о', 'б', 'о', 'ж', 'д', 'е', 'н', 'н', 'о', 'й', ' ', 'к', 'у', 'р', 'д', 'а', 'м', 'и', ' ', 'т', 'е', 'р', 'р', 'и', 'т', 'о', 'р', 'и', 'и', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJkCZD6a4EIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = gensim.models.Phrases(symbols_sents, scoring='npmi', threshold=-1, min_count = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E22kU_zz4lXA",
        "colab_type": "code",
        "outputId": "d153b018-03f7-471d-8c8d-acce5f7985a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "p1 = gensim.models.Phrases(p[symbols_sents], scoring='npmi', threshold=-1, min_count = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b1tDVWs4rRY",
        "colab_type": "code",
        "outputId": "76971786-4b88-471a-8486-702d4727eb2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "p2 = gensim.models.Phrases(p1[p[symbols_sents]], scoring='npmi', threshold=-1, min_count = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lHN61jOFOzO",
        "colab_type": "code",
        "outputId": "58c08307-a684-4019-a3bf-64cc5f4e7e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "p3 = gensim.models.Phrases(p2[p1[p[symbols_sents]]], scoring='npmi', threshold=-1, min_count = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDqpHrG741MT",
        "colab_type": "code",
        "outputId": "d2e00ca7-bbb7-44e4-c0f3-7e647d5325ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "list(p3[p2[p1[p[symbols_sents]]]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['П_р_е_з_и_д_е_н_т_ _С_Ш_А_ _с_о',\n",
              "  'о_б_щ_и_л_,_ _ч_т_о_ _п_р_а_в_и',\n",
              "  'т_е_л_ь_с_т_в_о_ _Т_у_р_ц_и_и_ ',\n",
              "  'п_р_о_и_н_ф_о_р_м_и_р_о_в_а_л_о',\n",
              "  ' _о_ _п_р_е_к_р_а_щ_е_н_и_и_ _б',\n",
              "  'о_е_в_ы_х_ _д_е_й_с_т_в_и_й_.'],\n",
              " ['П_о_ _е_г_о_ _м_н_е_н_и_ю_,_ _п',\n",
              "  'е_р_е_м_и_р_и_е_ _н_а_ _с_е_в_е',\n",
              "  'р_е_ _С_и_р_и_и_ _б_у_д_е_т_ _с',\n",
              "  'о_б_л_ю_д_а_т_ь_с_я_ _п_о_с_т_о',\n",
              "  'я_н_н_о_.'],\n",
              " ['Г_о_с_п_о_д_и_н_ _Т_р_а_м_п_ _н',\n",
              "  'а_з_в_а_л_ _з_а_с_л_у_г_о_й_ _С',\n",
              "  'Ш_А_ _п_е_р_е_м_и_р_и_е_,_ _б_л',\n",
              "  'а_г_о_д_а_р_я_ _к_о_т_о_р_о_м_у',\n",
              "  ' _к_у_р_д_ы_ _с_м_о_г_л_и_ _с_п',\n",
              "  'о_к_о_й_н_о_ _п_о_к_и_н_у_т_ь_ ',\n",
              "  'г_р_а_н_и_ц_у_ _с_ _Т_у_р_ц_и_е',\n",
              "  'й_.'],\n",
              " ['«_Э_т_о_г_о_ _д_о_б_и_л_и_с_ь_ ',\n",
              "  'м_ы_,_ _С_о_е_д_и_н_е_н_н_ы_е_ ',\n",
              "  'Ш_т_а_т_ы_,_ _а_ _н_е_ _к_т_о_-',\n",
              "  'т_о_ _е_щ_е_,_ _н_и_к_а_к_а_я_ ',\n",
              "  'д_р_у_г_а_я_ _с_т_р_а_н_а_»_,_—',\n",
              "  ' _с_к_а_з_а_л_ _г_л_а_в_а_ _г_о',\n",
              "  'с_у_д_а_р_с_т_в_а_.'],\n",
              " ['П_о_ _е_г_о_ _с_л_о_в_а_м_,_ _С',\n",
              "  'Ш_А_ _у_д_а_л_о_с_ь_ _с_о_х_р_а',\n",
              "  'н_и_т_ь_ _ж_и_з_н_и_ _м_н_о_г_и',\n",
              "  'х_ _к_у_р_д_о_в_.'],\n",
              " ['Д_о_н_а_л_ь_д_ _Т_р_а_м_п_ _с_о',\n",
              "  'о_б_щ_и_л_,_ _ч_т_о_ _н_а_ _т_е',\n",
              "  'р_р_и_т_о_р_и_и_ _С_и_р_и_и_ _о',\n",
              "  'с_т_а_н_е_т_с_я_ _н_е_б_о_л_ь_ш',\n",
              "  'о_е_ _ч_и_с_л_о_ _в_о_е_н_н_ы_х',\n",
              "  ' _—_ _«_в_ _р_а_й_о_н_а_х_,_ _г',\n",
              "  'д_е_ _е_с_т_ь_ _н_е_ф_т_ь_»_.'],\n",
              " ['«_М_ы_ _б_у_д_е_м_ _е_е_ _з_а_щ',\n",
              "  'и_щ_а_т_ь_ _и_ _р_е_ш_и_м_,_ _ч',\n",
              "  'т_о_ _д_е_л_а_т_ь_ _с_ _э_т_и_м',\n",
              "  ' _в_ _б_у_д_у_щ_е_м_»_,_—_ _с_к',\n",
              "  'а_з_а_л_ _п_р_е_з_и_д_е_н_т_ _С',\n",
              "  'Ш_А_.'],\n",
              " ['Т_у_р_ц_и_я_ _н_а_ч_а_л_а_ _в_о',\n",
              "  'е_н_н_у_ю_ _о_п_е_р_а_ц_и_ю_ _«',\n",
              "  'И_с_т_о_ч_н_и_к_ _м_и_р_а_»_ _в',\n",
              "  ' _С_и_р_и_и_ _9_ _о_к_т_я_б_р_я',\n",
              "  '.'],\n",
              " ['В_ _п_о_л_н_о_ч_ь_ _1_8_ _о_к_т',\n",
              "  'я_б_р_я_ _А_н_к_а_р_а_ _п_р_и_о',\n",
              "  'с_т_а_н_о_в_и_л_а_ _о_п_е_р_а_ц',\n",
              "  'и_ю_.'],\n",
              " ['Е_е_ _з_а_в_е_р_ш_и_л_и_ _с_е_г', 'о_д_н_я_,_ _2_3_ _о_к_т_я_б_р_я', '.'],\n",
              " ['О_д_н_а_к_о_ _Т_у_р_ц_и_я_ _н_е',\n",
              "  ' _н_а_м_е_р_е_н_а_ _п_о_л_н_о_с',\n",
              "  'т_ь_ю_ _у_х_о_д_и_т_ь_ _с_ _т_е',\n",
              "  'р_р_и_т_о_р_и_и_ _С_и_р_и_и_.'],\n",
              " ['В_ _р_а_м_к_а_х_ _д_о_г_о_в_о_р',\n",
              "  'е_н_н_о_с_т_е_й_ _В_а_ш_и_н_г_т',\n",
              "  'о_н_ _п_о_о_б_е_щ_а_л_ _в_ы_в_е',\n",
              "  'с_т_и_ _к_у_р_д_с_к_и_е_ _ф_о_р',\n",
              "  'м_и_р_о_в_а_н_и_я_ _з_а_ _д_е_м',\n",
              "  'а_р_к_а_ц_и_о_н_н_у_ю_ _л_и_н_и',\n",
              "  'ю_ _в_ _3_0_ _к_м_ _к_ _ю_г_у_ ',\n",
              "  'о_т_ _г_р_а_н_и_ц_ы_ _С_и_р_и_и',\n",
              "  ' _с_ _Т_у_р_ц_и_е_й_.'],\n",
              " ['Р_о_с_с_и_я_ _и_ _Т_у_р_ц_и_я_ ',\n",
              "  'н_а_ч_н_у_т_ _с_о_в_м_е_с_т_н_о',\n",
              "  'е_ _п_а_т_р_у_л_и_р_о_в_а_н_и_е',\n",
              "  ' _о_с_в_о_б_о_ж_д_е_н_н_о_й_ _к',\n",
              "  'у_р_д_а_м_и_ _т_е_р_р_и_т_о_р_и',\n",
              "  'и_.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}