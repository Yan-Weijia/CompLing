{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 用 Word2vec 模型（自己训练的和rusvectores的）向量化文本，根据重述定义在所得向量上训练2个模型，找到最好的模型。\n",
    "\n",
    "Обучите 2 модели по определению перефразирования на получившихся векторах\n",
    "Word2Vec要在另外的库训练（不在平行句子上），可以选用课堂上的数据或其它的\n",
    "\n",
    "要用cross-validation评价模型，кросс-валидации! Метрика - f1\n",
    "\n",
    "2) 分别用5种方法训练成对的文本向量：SVD, NMF, Word2Vec (自己的和rucvectores的), Fastext. \n",
    "数据库的每行应有五对向量。在每对向量之间计算余弦相似度（一对5个） \n",
    "\n",
    "通过这些相似度建立训练样本。在此样本上训练任何一个模型（Logreg，Random Forest或其他），\n",
    "并评估cross-validation(交叉验证)的质量（使用micro-f1-measure）。\n",
    "尝试通过更改向量化时的参数来改进指标。\n",
    "\n",
    "SVD 和 NMF 直接应用于数据,  w2w 和 fastext 在其他库训练（与第一问一样） \n",
    "\n",
    "Выложите код к себе на гитхаб и вставьте ссылку в поле ниже (в тетрадке должны быть показатели метрик и ваши комментарии).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lxml import html\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import gensim\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter,defaultdict\n",
    "from string import punctuation\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "%matplotlib inline\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "punct = punctuation+'«»—…“”*№–'\n",
    "stops = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    \n",
    "    words = [word.strip(punct) for word in text.lower().split()]\n",
    "    words = [morph.parse(word)[0].normal_form for word in words if word and word not in stops]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "def tokenize(text):\n",
    "    \n",
    "    words = [word.strip(punct) for word in text.lower().split()]\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## corpus_hum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('corpus_hum.txt', encoding=\"utf-8\").read().splitlines()\n",
    "data_norm = [normalize(text) for text in data]\n",
    "data_norm = [text for text in data_norm if text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['абай василий васо иван 1900–2001 русский лингвист родиться 2 15 декабрь 1900 с.коби тифлисский губерния ныне грузия 1925 окончить факультет общественный наука ленинградский университет 1928 аспирантура 1928–1930 сотрудник кавказский историко-археологический институт ан ссср 1930 полвека работать яфетический институт затем институт язык мышление институт языкознание ан ссср ленинград 1950 москва доктор филологический наука 1962 профессор 1969 лауреат государственный премия ссср 1981 почётный член азиатский королевский общество великобритания ирландия 1966 член-корреспондент финно-угорский общество хельсинки 1973 умереть абай москва 18 март 2001',\n",
       " 'также тема']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115082"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=3, max_df=0.4, max_features=1000)\n",
    "X = cv.fit_transform(data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115082, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD & NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(4)\n",
    "svd.fit(X)\n",
    "tsne = TSNE(2).fit_transform(svd.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i:w for i,w in enumerate(cv.get_feature_names())}\n",
    "word2id = {w:i for i,w in id2word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "    n_components=50, random_state=None, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf = NMF(50)\n",
    "nmf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
       "             random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(50)\n",
    "svd.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2vec_svd = nmf.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2vec_nmf = svd.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, id2vec):\n",
    "    similar = [id2word[i] for i in cosine_distances(id2vec[word2id[word]].reshape(1, -1), id2vec).argsort()[0][:10]]\n",
    "    return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init 1/3 with method: k-means++\n",
      "Inertia for init 1/3: 7.847001\n",
      "Init 2/3 with method: k-means++\n",
      "Inertia for init 2/3: 9.277354\n",
      "Init 3/3 with method: k-means++\n",
      "Inertia for init 3/3: 7.719683\n",
      "Minibatch iteration 1/1000: mean batch inertia: 0.026884, ewa inertia: 0.026884 \n",
      "Minibatch iteration 2/1000: mean batch inertia: 0.035086, ewa inertia: 0.028523 \n",
      "Minibatch iteration 3/1000: mean batch inertia: 0.049890, ewa inertia: 0.032792 \n",
      "Minibatch iteration 4/1000: mean batch inertia: 0.038418, ewa inertia: 0.033916 \n",
      "Minibatch iteration 5/1000: mean batch inertia: 0.021644, ewa inertia: 0.031464 \n",
      "Minibatch iteration 6/1000: mean batch inertia: 0.020122, ewa inertia: 0.029198 \n",
      "Minibatch iteration 7/1000: mean batch inertia: 0.050604, ewa inertia: 0.033475 \n",
      "Minibatch iteration 8/1000: mean batch inertia: 0.029602, ewa inertia: 0.032701 \n",
      "Minibatch iteration 9/1000: mean batch inertia: 0.033506, ewa inertia: 0.032862 \n",
      "[MiniBatchKMeans] Reassigning 29 cluster centers.\n",
      "Minibatch iteration 10/1000: mean batch inertia: 0.036695, ewa inertia: 0.033628 \n",
      "Minibatch iteration 11/1000: mean batch inertia: 0.030024, ewa inertia: 0.032908 \n",
      "Minibatch iteration 12/1000: mean batch inertia: 0.020258, ewa inertia: 0.030380 \n",
      "Minibatch iteration 13/1000: mean batch inertia: 0.052549, ewa inertia: 0.034810 \n",
      "Minibatch iteration 14/1000: mean batch inertia: 0.028431, ewa inertia: 0.033535 \n",
      "Minibatch iteration 15/1000: mean batch inertia: 0.044391, ewa inertia: 0.035704 \n",
      "Minibatch iteration 16/1000: mean batch inertia: 0.036144, ewa inertia: 0.035792 \n",
      "Minibatch iteration 17/1000: mean batch inertia: 0.046645, ewa inertia: 0.037960 \n",
      "Minibatch iteration 18/1000: mean batch inertia: 0.064545, ewa inertia: 0.043272 \n",
      "Minibatch iteration 19/1000: mean batch inertia: 0.050842, ewa inertia: 0.044784 \n",
      "Minibatch iteration 20/1000: mean batch inertia: 0.031202, ewa inertia: 0.042071 \n",
      "Minibatch iteration 21/1000: mean batch inertia: 0.043927, ewa inertia: 0.042442 \n",
      "Minibatch iteration 22/1000: mean batch inertia: 0.028096, ewa inertia: 0.039575 \n",
      "Minibatch iteration 23/1000: mean batch inertia: 0.028174, ewa inertia: 0.037297 \n",
      "Minibatch iteration 24/1000: mean batch inertia: 0.020776, ewa inertia: 0.033996 \n",
      "Minibatch iteration 25/1000: mean batch inertia: 0.032009, ewa inertia: 0.033599 \n",
      "Minibatch iteration 26/1000: mean batch inertia: 0.033714, ewa inertia: 0.033622 \n",
      "Minibatch iteration 27/1000: mean batch inertia: 0.047918, ewa inertia: 0.036479 \n",
      "Minibatch iteration 28/1000: mean batch inertia: 0.027452, ewa inertia: 0.034675 \n",
      "Minibatch iteration 29/1000: mean batch inertia: 0.019918, ewa inertia: 0.031727 \n",
      "Minibatch iteration 30/1000: mean batch inertia: 0.037243, ewa inertia: 0.032829 \n",
      "Minibatch iteration 31/1000: mean batch inertia: 0.052015, ewa inertia: 0.036662 \n",
      "Minibatch iteration 32/1000: mean batch inertia: 0.060262, ewa inertia: 0.041378 \n",
      "Minibatch iteration 33/1000: mean batch inertia: 0.026971, ewa inertia: 0.038499 \n",
      "Minibatch iteration 34/1000: mean batch inertia: 0.054408, ewa inertia: 0.041678 \n",
      "Minibatch iteration 35/1000: mean batch inertia: 0.040816, ewa inertia: 0.041506 \n",
      "Minibatch iteration 36/1000: mean batch inertia: 0.031449, ewa inertia: 0.039496 \n",
      "Minibatch iteration 37/1000: mean batch inertia: 0.047817, ewa inertia: 0.041159 \n",
      "Minibatch iteration 38/1000: mean batch inertia: 0.034593, ewa inertia: 0.039847 \n",
      "Minibatch iteration 39/1000: mean batch inertia: 0.039976, ewa inertia: 0.039873 \n",
      "Minibatch iteration 40/1000: mean batch inertia: 0.037427, ewa inertia: 0.039384 \n",
      "Minibatch iteration 41/1000: mean batch inertia: 0.064891, ewa inertia: 0.044480 \n",
      "Minibatch iteration 42/1000: mean batch inertia: 0.033794, ewa inertia: 0.042345 \n",
      "Minibatch iteration 43/1000: mean batch inertia: 0.021668, ewa inertia: 0.038214 \n",
      "Minibatch iteration 44/1000: mean batch inertia: 0.059458, ewa inertia: 0.042459 \n",
      "Minibatch iteration 45/1000: mean batch inertia: 0.067517, ewa inertia: 0.047465 \n",
      "Minibatch iteration 46/1000: mean batch inertia: 0.047294, ewa inertia: 0.047431 \n",
      "Minibatch iteration 47/1000: mean batch inertia: 0.039449, ewa inertia: 0.045836 \n",
      "Minibatch iteration 48/1000: mean batch inertia: 0.043885, ewa inertia: 0.045446 \n",
      "Minibatch iteration 49/1000: mean batch inertia: 0.020453, ewa inertia: 0.040453 \n",
      "Minibatch iteration 50/1000: mean batch inertia: 0.052126, ewa inertia: 0.042785 \n",
      "Minibatch iteration 51/1000: mean batch inertia: 0.045934, ewa inertia: 0.043414 \n",
      "Minibatch iteration 52/1000: mean batch inertia: 0.059412, ewa inertia: 0.046611 \n",
      "Minibatch iteration 53/1000: mean batch inertia: 0.016694, ewa inertia: 0.040633 \n",
      "Minibatch iteration 54/1000: mean batch inertia: 0.021949, ewa inertia: 0.036900 \n",
      "Minibatch iteration 55/1000: mean batch inertia: 0.049181, ewa inertia: 0.039354 \n",
      "Minibatch iteration 56/1000: mean batch inertia: 0.041561, ewa inertia: 0.039795 \n",
      "Minibatch iteration 57/1000: mean batch inertia: 0.030368, ewa inertia: 0.037911 \n",
      "Minibatch iteration 58/1000: mean batch inertia: 0.044335, ewa inertia: 0.039195 \n",
      "Minibatch iteration 59/1000: mean batch inertia: 0.021793, ewa inertia: 0.035718 \n",
      "Minibatch iteration 60/1000: mean batch inertia: 0.037895, ewa inertia: 0.036153 \n",
      "Minibatch iteration 61/1000: mean batch inertia: 0.062380, ewa inertia: 0.041393 \n",
      "Minibatch iteration 62/1000: mean batch inertia: 0.032460, ewa inertia: 0.039608 \n",
      "Minibatch iteration 63/1000: mean batch inertia: 0.027582, ewa inertia: 0.037205 \n",
      "Minibatch iteration 64/1000: mean batch inertia: 0.068760, ewa inertia: 0.043510 \n",
      "Minibatch iteration 65/1000: mean batch inertia: 0.043212, ewa inertia: 0.043450 \n",
      "Minibatch iteration 66/1000: mean batch inertia: 0.052295, ewa inertia: 0.045218 \n",
      "Minibatch iteration 67/1000: mean batch inertia: 0.038334, ewa inertia: 0.043842 \n",
      "Minibatch iteration 68/1000: mean batch inertia: 0.034960, ewa inertia: 0.042068 \n",
      "Minibatch iteration 69/1000: mean batch inertia: 0.037974, ewa inertia: 0.041250 \n",
      "Minibatch iteration 70/1000: mean batch inertia: 0.026697, ewa inertia: 0.038342 \n",
      "Minibatch iteration 71/1000: mean batch inertia: 0.028021, ewa inertia: 0.036280 \n",
      "Minibatch iteration 72/1000: mean batch inertia: 0.030191, ewa inertia: 0.035063 \n",
      "Minibatch iteration 73/1000: mean batch inertia: 0.054075, ewa inertia: 0.038862 \n",
      "Minibatch iteration 74/1000: mean batch inertia: 0.025054, ewa inertia: 0.036103 \n",
      "Minibatch iteration 75/1000: mean batch inertia: 0.039130, ewa inertia: 0.036708 \n",
      "Minibatch iteration 76/1000: mean batch inertia: 0.045617, ewa inertia: 0.038488 \n",
      "Minibatch iteration 77/1000: mean batch inertia: 0.066768, ewa inertia: 0.044138 \n",
      "Minibatch iteration 78/1000: mean batch inertia: 0.011918, ewa inertia: 0.037701 \n",
      "Minibatch iteration 79/1000: mean batch inertia: 0.042969, ewa inertia: 0.038753 \n",
      "Minibatch iteration 80/1000: mean batch inertia: 0.020002, ewa inertia: 0.035007 \n",
      "Minibatch iteration 81/1000: mean batch inertia: 0.020364, ewa inertia: 0.032081 \n",
      "Minibatch iteration 82/1000: mean batch inertia: 0.030725, ewa inertia: 0.031810 \n",
      "Minibatch iteration 83/1000: mean batch inertia: 0.045525, ewa inertia: 0.034551 \n",
      "Minibatch iteration 84/1000: mean batch inertia: 0.039995, ewa inertia: 0.035638 \n",
      "Minibatch iteration 85/1000: mean batch inertia: 0.069070, ewa inertia: 0.042318 \n",
      "Minibatch iteration 86/1000: mean batch inertia: 0.042284, ewa inertia: 0.042311 \n",
      "Minibatch iteration 87/1000: mean batch inertia: 0.022700, ewa inertia: 0.038393 \n",
      "Minibatch iteration 88/1000: mean batch inertia: 0.026598, ewa inertia: 0.036036 \n",
      "Minibatch iteration 89/1000: mean batch inertia: 0.072086, ewa inertia: 0.043239 \n",
      "Minibatch iteration 90/1000: mean batch inertia: 0.030530, ewa inertia: 0.040700 \n",
      "Minibatch iteration 91/1000: mean batch inertia: 0.029269, ewa inertia: 0.038416 \n",
      "Minibatch iteration 92/1000: mean batch inertia: 0.024956, ewa inertia: 0.035727 \n",
      "Minibatch iteration 93/1000: mean batch inertia: 0.040954, ewa inertia: 0.036771 \n",
      "Minibatch iteration 94/1000: mean batch inertia: 0.043092, ewa inertia: 0.038034 \n",
      "Minibatch iteration 95/1000: mean batch inertia: 0.037523, ewa inertia: 0.037932 \n",
      "Minibatch iteration 96/1000: mean batch inertia: 0.026304, ewa inertia: 0.035609 \n",
      "Minibatch iteration 97/1000: mean batch inertia: 0.031982, ewa inertia: 0.034884 \n",
      "Minibatch iteration 98/1000: mean batch inertia: 0.043349, ewa inertia: 0.036576 \n",
      "Minibatch iteration 99/1000: mean batch inertia: 0.028306, ewa inertia: 0.034923 \n",
      "Minibatch iteration 100/1000: mean batch inertia: 0.025127, ewa inertia: 0.032966 \n",
      "Minibatch iteration 101/1000: mean batch inertia: 0.038977, ewa inertia: 0.034167 \n",
      "Converged (lack of improvement in inertia) at iteration 101/1000\n",
      "Computing label assignment and total inertia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
       "                init_size=None, max_iter=100, max_no_improvement=100,\n",
       "                n_clusters=30, n_init=3, random_state=None,\n",
       "                reassignment_ratio=0.4, tol=0.0, verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_svd = MiniBatchKMeans(30, n_init=3, verbose=1, max_no_improvement=100, reassignment_ratio=0.4)\n",
    "cluster_svd.fit(svd.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_svd = defaultdict(list)\n",
    "\n",
    "for i, cl in enumerate(cluster_svd.labels_):\n",
    "    cls_svd[cl].append(id2word[i])\n",
    "\n",
    "f = open('cluster_svd.txt', 'w')\n",
    "for cl in cls_svd:\n",
    "    f.write('### '+ str(cl) + ' ###\\n')\n",
    "    f.write('\\n'.join(cls_svd[cl]))\n",
    "    f.write('\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init 1/3 with method: k-means++\n",
      "Inertia for init 1/3: 1934.028094\n",
      "Init 2/3 with method: k-means++\n",
      "Inertia for init 2/3: 963.635824\n",
      "Init 3/3 with method: k-means++\n",
      "Inertia for init 3/3: 1376.979588\n",
      "Minibatch iteration 1/1000: mean batch inertia: 16.652668, ewa inertia: 16.652668 \n",
      "Minibatch iteration 2/1000: mean batch inertia: 13.113488, ewa inertia: 15.945539 \n",
      "Minibatch iteration 3/1000: mean batch inertia: 7.904567, ewa inertia: 14.338951 \n",
      "Minibatch iteration 4/1000: mean batch inertia: 9.932406, ewa inertia: 13.458523 \n",
      "Minibatch iteration 5/1000: mean batch inertia: 7.350332, ewa inertia: 12.238105 \n",
      "Minibatch iteration 6/1000: mean batch inertia: 12.477005, ewa inertia: 12.285837 \n",
      "Minibatch iteration 7/1000: mean batch inertia: 3.562819, ewa inertia: 10.542976 \n",
      "Minibatch iteration 8/1000: mean batch inertia: 8.969881, ewa inertia: 10.228672 \n",
      "Minibatch iteration 9/1000: mean batch inertia: 10.864403, ewa inertia: 10.355691 \n",
      "[MiniBatchKMeans] Reassigning 39 cluster centers.\n",
      "Minibatch iteration 10/1000: mean batch inertia: 8.723543, ewa inertia: 10.029587 \n",
      "Minibatch iteration 11/1000: mean batch inertia: 13.269987, ewa inertia: 10.677020 \n",
      "Minibatch iteration 12/1000: mean batch inertia: 9.358248, ewa inertia: 10.413529 \n",
      "Minibatch iteration 13/1000: mean batch inertia: 10.970044, ewa inertia: 10.524721 \n",
      "Minibatch iteration 14/1000: mean batch inertia: 38.145811, ewa inertia: 16.043420 \n",
      "Minibatch iteration 15/1000: mean batch inertia: 43.078711, ewa inertia: 21.445077 \n",
      "Minibatch iteration 16/1000: mean batch inertia: 18.447480, ewa inertia: 20.846156 \n",
      "Minibatch iteration 17/1000: mean batch inertia: 34.727649, ewa inertia: 23.619681 \n",
      "Minibatch iteration 18/1000: mean batch inertia: 7.142399, ewa inertia: 20.327517 \n",
      "Minibatch iteration 19/1000: mean batch inertia: 8.527507, ewa inertia: 17.969873 \n",
      "Minibatch iteration 20/1000: mean batch inertia: 11.664777, ewa inertia: 16.710113 \n",
      "Minibatch iteration 21/1000: mean batch inertia: 9.433622, ewa inertia: 15.256269 \n",
      "Minibatch iteration 22/1000: mean batch inertia: 24.552924, ewa inertia: 17.113742 \n",
      "Minibatch iteration 23/1000: mean batch inertia: 30.129436, ewa inertia: 19.714281 \n",
      "Minibatch iteration 24/1000: mean batch inertia: 11.832603, ewa inertia: 18.139520 \n",
      "Minibatch iteration 25/1000: mean batch inertia: 4.381189, ewa inertia: 15.390603 \n",
      "Minibatch iteration 26/1000: mean batch inertia: 38.779765, ewa inertia: 20.063762 \n",
      "Minibatch iteration 27/1000: mean batch inertia: 59.582959, ewa inertia: 27.959705 \n",
      "Minibatch iteration 28/1000: mean batch inertia: 29.439840, ewa inertia: 28.255437 \n",
      "Minibatch iteration 29/1000: mean batch inertia: 10.458706, ewa inertia: 24.699646 \n",
      "Minibatch iteration 30/1000: mean batch inertia: 15.848789, ewa inertia: 22.931243 \n",
      "Minibatch iteration 31/1000: mean batch inertia: 10.333598, ewa inertia: 20.414231 \n",
      "Minibatch iteration 32/1000: mean batch inertia: 9.679847, ewa inertia: 18.269499 \n",
      "Minibatch iteration 33/1000: mean batch inertia: 4.279606, ewa inertia: 15.474316 \n",
      "Minibatch iteration 34/1000: mean batch inertia: 18.732911, ewa inertia: 16.125384 \n",
      "Minibatch iteration 35/1000: mean batch inertia: 13.854850, ewa inertia: 15.671731 \n",
      "Minibatch iteration 36/1000: mean batch inertia: 11.946163, ewa inertia: 14.927361 \n",
      "Minibatch iteration 37/1000: mean batch inertia: 45.178724, ewa inertia: 20.971590 \n",
      "Minibatch iteration 38/1000: mean batch inertia: 10.250475, ewa inertia: 18.829509 \n",
      "Minibatch iteration 39/1000: mean batch inertia: 2.157441, ewa inertia: 15.498426 \n",
      "Minibatch iteration 40/1000: mean batch inertia: 11.049436, ewa inertia: 14.609517 \n",
      "Minibatch iteration 41/1000: mean batch inertia: 9.173764, ewa inertia: 13.523453 \n",
      "Minibatch iteration 42/1000: mean batch inertia: 15.741832, ewa inertia: 13.966685 \n",
      "Minibatch iteration 43/1000: mean batch inertia: 9.941431, ewa inertia: 13.162439 \n",
      "Minibatch iteration 44/1000: mean batch inertia: 10.730128, ewa inertia: 12.676462 \n",
      "Minibatch iteration 45/1000: mean batch inertia: 37.517093, ewa inertia: 17.639625 \n",
      "Minibatch iteration 46/1000: mean batch inertia: 7.159338, ewa inertia: 15.545662 \n",
      "Minibatch iteration 47/1000: mean batch inertia: 18.616262, ewa inertia: 16.159168 \n",
      "Minibatch iteration 48/1000: mean batch inertia: 9.234628, ewa inertia: 14.775644 \n",
      "Minibatch iteration 49/1000: mean batch inertia: 10.260243, ewa inertia: 13.873466 \n",
      "Minibatch iteration 50/1000: mean batch inertia: 16.240268, ewa inertia: 14.346353 \n",
      "Minibatch iteration 51/1000: mean batch inertia: 17.933569, ewa inertia: 15.063080 \n",
      "Minibatch iteration 52/1000: mean batch inertia: 16.264145, ewa inertia: 15.303053 \n",
      "Minibatch iteration 53/1000: mean batch inertia: 12.603595, ewa inertia: 14.763701 \n",
      "Minibatch iteration 54/1000: mean batch inertia: 14.834937, ewa inertia: 14.777934 \n",
      "Minibatch iteration 55/1000: mean batch inertia: 17.043744, ewa inertia: 15.230643 \n",
      "Minibatch iteration 56/1000: mean batch inertia: 53.612203, ewa inertia: 22.899287 \n",
      "Minibatch iteration 57/1000: mean batch inertia: 26.091922, ewa inertia: 23.537176 \n",
      "Minibatch iteration 58/1000: mean batch inertia: 20.427416, ewa inertia: 22.915845 \n",
      "Minibatch iteration 59/1000: mean batch inertia: 28.022548, ewa inertia: 23.936166 \n",
      "Minibatch iteration 60/1000: mean batch inertia: 12.425056, ewa inertia: 21.636244 \n",
      "Minibatch iteration 61/1000: mean batch inertia: 13.943225, ewa inertia: 20.099177 \n",
      "Minibatch iteration 62/1000: mean batch inertia: 9.749847, ewa inertia: 18.031379 \n",
      "Minibatch iteration 63/1000: mean batch inertia: 8.385556, ewa inertia: 16.104141 \n",
      "Minibatch iteration 64/1000: mean batch inertia: 11.016040, ewa inertia: 15.087538 \n",
      "Minibatch iteration 65/1000: mean batch inertia: 11.498876, ewa inertia: 14.370522 \n",
      "Minibatch iteration 66/1000: mean batch inertia: 13.074338, ewa inertia: 14.111545 \n",
      "Minibatch iteration 67/1000: mean batch inertia: 18.017167, ewa inertia: 14.891889 \n",
      "Minibatch iteration 68/1000: mean batch inertia: 21.417100, ewa inertia: 16.195627 \n",
      "Minibatch iteration 69/1000: mean batch inertia: 14.253031, ewa inertia: 15.807496 \n",
      "Minibatch iteration 70/1000: mean batch inertia: 8.942665, ewa inertia: 14.435901 \n",
      "Minibatch iteration 71/1000: mean batch inertia: 10.647884, ewa inertia: 13.679055 \n",
      "Minibatch iteration 72/1000: mean batch inertia: 15.864095, ewa inertia: 14.115626 \n",
      "Minibatch iteration 73/1000: mean batch inertia: 6.676002, ewa inertia: 12.629188 \n",
      "Minibatch iteration 74/1000: mean batch inertia: 11.287199, ewa inertia: 12.361058 \n",
      "Minibatch iteration 75/1000: mean batch inertia: 7.861941, ewa inertia: 11.462134 \n",
      "Minibatch iteration 76/1000: mean batch inertia: 23.828140, ewa inertia: 13.932864 \n",
      "Minibatch iteration 77/1000: mean batch inertia: 8.430605, ewa inertia: 12.833512 \n",
      "Minibatch iteration 78/1000: mean batch inertia: 11.698144, ewa inertia: 12.606665 \n",
      "Minibatch iteration 79/1000: mean batch inertia: 9.401587, ewa inertia: 11.966290 \n",
      "Minibatch iteration 80/1000: mean batch inertia: 31.178369, ewa inertia: 15.804867 \n",
      "Minibatch iteration 81/1000: mean batch inertia: 11.691660, ewa inertia: 14.983047 \n",
      "Minibatch iteration 82/1000: mean batch inertia: 11.794253, ewa inertia: 14.345926 \n",
      "Minibatch iteration 83/1000: mean batch inertia: 24.487672, ewa inertia: 16.372249 \n",
      "Minibatch iteration 84/1000: mean batch inertia: 10.321919, ewa inertia: 15.163392 \n",
      "Minibatch iteration 85/1000: mean batch inertia: 12.948508, ewa inertia: 14.720857 \n",
      "Minibatch iteration 86/1000: mean batch inertia: 8.175405, ewa inertia: 13.413075 \n",
      "Minibatch iteration 87/1000: mean batch inertia: 2.588105, ewa inertia: 11.250244 \n",
      "Minibatch iteration 88/1000: mean batch inertia: 19.165663, ewa inertia: 12.831746 \n",
      "Minibatch iteration 89/1000: mean batch inertia: 14.778802, ewa inertia: 13.220768 \n",
      "Minibatch iteration 90/1000: mean batch inertia: 12.723067, ewa inertia: 13.121327 \n",
      "Minibatch iteration 91/1000: mean batch inertia: 7.907908, ewa inertia: 12.079685 \n",
      "Minibatch iteration 92/1000: mean batch inertia: 32.910974, ewa inertia: 16.241781 \n",
      "Minibatch iteration 93/1000: mean batch inertia: 16.735818, ewa inertia: 16.340489 \n",
      "Minibatch iteration 94/1000: mean batch inertia: 12.346340, ewa inertia: 15.542458 \n",
      "Minibatch iteration 95/1000: mean batch inertia: 7.311623, ewa inertia: 13.897935 \n",
      "Minibatch iteration 96/1000: mean batch inertia: 11.106567, ewa inertia: 13.340219 \n",
      "Minibatch iteration 97/1000: mean batch inertia: 17.928763, ewa inertia: 14.257011 \n",
      "Minibatch iteration 98/1000: mean batch inertia: 20.949119, ewa inertia: 15.594096 \n",
      "Minibatch iteration 99/1000: mean batch inertia: 8.038270, ewa inertia: 14.084440 \n",
      "Minibatch iteration 100/1000: mean batch inertia: 6.684538, ewa inertia: 12.605938 \n",
      "Minibatch iteration 101/1000: mean batch inertia: 14.941875, ewa inertia: 13.072659 \n",
      "Minibatch iteration 102/1000: mean batch inertia: 3.897916, ewa inertia: 11.239543 \n",
      "Minibatch iteration 103/1000: mean batch inertia: 15.917689, ewa inertia: 12.174238 \n",
      "Minibatch iteration 104/1000: mean batch inertia: 11.128462, ewa inertia: 11.965292 \n",
      "Minibatch iteration 105/1000: mean batch inertia: 15.707729, ewa inertia: 12.713031 \n",
      "Minibatch iteration 106/1000: mean batch inertia: 6.520803, ewa inertia: 11.475823 \n",
      "Minibatch iteration 107/1000: mean batch inertia: 25.085679, ewa inertia: 14.195075 \n",
      "Minibatch iteration 108/1000: mean batch inertia: 12.003532, ewa inertia: 13.757204 \n",
      "Minibatch iteration 109/1000: mean batch inertia: 16.395812, ewa inertia: 14.284398 \n",
      "Minibatch iteration 110/1000: mean batch inertia: 17.003287, ewa inertia: 14.827633 \n",
      "Converged (lack of improvement in inertia) at iteration 110/1000\n",
      "Computing label assignment and total inertia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
       "                init_size=None, max_iter=100, max_no_improvement=100,\n",
       "                n_clusters=40, n_init=3, random_state=None,\n",
       "                reassignment_ratio=0.5, tol=0.0, verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_nmf = MiniBatchKMeans(40, n_init=3, verbose=1, max_no_improvement=100, reassignment_ratio=0.5)\n",
    "cluster_nmf.fit(nmf.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_nmf = defaultdict(list)\n",
    "\n",
    "for i, cl in enumerate(cluster_nmf.labels_):\n",
    "    cls_nmf[cl].append(id2word[i])\n",
    "# откройте в любом текстовом редакторе\n",
    "f = open('cluster_nmf.txt', 'w')\n",
    "for cl in cls_nmf:\n",
    "    f.write('### '+ str(cl) + ' ###\\n')\n",
    "    f.write('\\n'.join(cls_nmf[cl]))\n",
    "    f.write('\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w2v самостоятельно обученная (лучше)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_xml = html.fromstring(open('paraphrases.xml', 'rb').read())\n",
    "texts_1 = []\n",
    "texts_2 = []\n",
    "classes = []\n",
    "\n",
    "for p in corpus_xml.xpath('//paraphrase'):\n",
    "    texts_1.append(p.xpath('./value[@name=\"text_1\"]/text()')[0])\n",
    "    texts_2.append(p.xpath('./value[@name=\"text_2\"]/text()')[0])\n",
    "    classes.append(p.xpath('./value[@name=\"class\"]/text()')[0])\n",
    "    \n",
    "data = pd.DataFrame({'text_1':texts_1, 'text_2':texts_2, 'label':classes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_1_norm'] = data['text_1'].apply(normalize)\n",
    "data['text_2_norm'] = data['text_2'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>label</th>\n",
       "      <th>text_1_norm</th>\n",
       "      <th>text_2_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Полицейским разрешат стрелять на поражение по ...</td>\n",
       "      <td>Полиции могут разрешить стрелять по хулиганам ...</td>\n",
       "      <td>0</td>\n",
       "      <td>полицейский разрешить стрелять поражение гражд...</td>\n",
       "      <td>полиция мочь разрешить стрелять хулиган травма...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Право полицейских на проникновение в жилище ре...</td>\n",
       "      <td>Правила внесудебного проникновения полицейских...</td>\n",
       "      <td>0</td>\n",
       "      <td>право полицейский проникновение жилища решить ...</td>\n",
       "      <td>правило внесудебный проникновение полицейский ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Президент Египта ввел чрезвычайное положение в...</td>\n",
       "      <td>Власти Египта угрожают ввести в стране чрезвыч...</td>\n",
       "      <td>0</td>\n",
       "      <td>президент египет ввести чрезвычайный положение...</td>\n",
       "      <td>власть египет угрожать ввести страна чрезвычай...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Вернувшихся из Сирии россиян волнует вопрос тр...</td>\n",
       "      <td>Самолеты МЧС вывезут россиян из разрушенной Си...</td>\n",
       "      <td>-1</td>\n",
       "      <td>вернуться сирия россиянин волновать вопрос тру...</td>\n",
       "      <td>самолёт мчс вывезти россиянин разрушить сирия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>В Москву из Сирии вернулись 2 самолета МЧС с р...</td>\n",
       "      <td>Самолеты МЧС вывезут россиян из разрушенной Си...</td>\n",
       "      <td>0</td>\n",
       "      <td>москва сирия вернуться 2 самолёт мчс россиянин...</td>\n",
       "      <td>самолёт мчс вывезти россиянин разрушить сирия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Приставы соберут отпечатки пальцев российских ...</td>\n",
       "      <td>Приставы снимут отпечатки пальцев у злостных н...</td>\n",
       "      <td>1</td>\n",
       "      <td>пристав собрать отпечаток палец российский дол...</td>\n",
       "      <td>пристав снять отпечаток палец злостный неплате...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>На саратовского дебошира с борта самолета Моск...</td>\n",
       "      <td>Саратовский дебошир отказывается возвращаться ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>саратовский дебошир борт самолёт москва хургад...</td>\n",
       "      <td>саратовский дебошир отказываться возвращаться ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ЦИК хочет отказаться от электронной системы по...</td>\n",
       "      <td>ЦИК может отказаться от электронных средств по...</td>\n",
       "      <td>0</td>\n",
       "      <td>цик хотеть отказаться электронный система подс...</td>\n",
       "      <td>цик отказаться электронный средство подсчёт голос</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Суд Петербурга оставил на потом дело о гибели ...</td>\n",
       "      <td>Лондонский Гайд-парк - это не место для митинг...</td>\n",
       "      <td>-1</td>\n",
       "      <td>суд петербург оставить дело гибель подросток п...</td>\n",
       "      <td>лондонский гайд-парк это место митинг прежде парк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Страны ОПЕК сократили добычу нефти на 1 млн ба...</td>\n",
       "      <td>Обама продлил полномочия НАСА по сотрудничеств...</td>\n",
       "      <td>-1</td>\n",
       "      <td>страна опека сократить добыча нефть 1 миллион ...</td>\n",
       "      <td>обама продлить полномочие наса сотрудничество ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_1  \\\n",
       "0  Полицейским разрешат стрелять на поражение по ...   \n",
       "1  Право полицейских на проникновение в жилище ре...   \n",
       "2  Президент Египта ввел чрезвычайное положение в...   \n",
       "3  Вернувшихся из Сирии россиян волнует вопрос тр...   \n",
       "4  В Москву из Сирии вернулись 2 самолета МЧС с р...   \n",
       "5  Приставы соберут отпечатки пальцев российских ...   \n",
       "6  На саратовского дебошира с борта самолета Моск...   \n",
       "7  ЦИК хочет отказаться от электронной системы по...   \n",
       "8  Суд Петербурга оставил на потом дело о гибели ...   \n",
       "9  Страны ОПЕК сократили добычу нефти на 1 млн ба...   \n",
       "\n",
       "                                              text_2 label  \\\n",
       "0  Полиции могут разрешить стрелять по хулиганам ...     0   \n",
       "1  Правила внесудебного проникновения полицейских...     0   \n",
       "2  Власти Египта угрожают ввести в стране чрезвыч...     0   \n",
       "3  Самолеты МЧС вывезут россиян из разрушенной Си...    -1   \n",
       "4  Самолеты МЧС вывезут россиян из разрушенной Си...     0   \n",
       "5  Приставы снимут отпечатки пальцев у злостных н...     1   \n",
       "6  Саратовский дебошир отказывается возвращаться ...    -1   \n",
       "7  ЦИК может отказаться от электронных средств по...     0   \n",
       "8  Лондонский Гайд-парк - это не место для митинг...    -1   \n",
       "9  Обама продлил полномочия НАСА по сотрудничеств...    -1   \n",
       "\n",
       "                                         text_1_norm  \\\n",
       "0  полицейский разрешить стрелять поражение гражд...   \n",
       "1  право полицейский проникновение жилища решить ...   \n",
       "2  президент египет ввести чрезвычайный положение...   \n",
       "3  вернуться сирия россиянин волновать вопрос тру...   \n",
       "4  москва сирия вернуться 2 самолёт мчс россиянин...   \n",
       "5  пристав собрать отпечаток палец российский дол...   \n",
       "6  саратовский дебошир борт самолёт москва хургад...   \n",
       "7  цик хотеть отказаться электронный система подс...   \n",
       "8  суд петербург оставить дело гибель подросток п...   \n",
       "9  страна опека сократить добыча нефть 1 миллион ...   \n",
       "\n",
       "                                         text_2_norm  \n",
       "0  полиция мочь разрешить стрелять хулиган травма...  \n",
       "1  правило внесудебный проникновение полицейский ...  \n",
       "2  власть египет угрожать ввести страна чрезвычай...  \n",
       "3      самолёт мчс вывезти россиянин разрушить сирия  \n",
       "4      самолёт мчс вывезти россиянин разрушить сирия  \n",
       "5  пристав снять отпечаток палец злостный неплате...  \n",
       "6  саратовский дебошир отказываться возвращаться ...  \n",
       "7  цик отказаться электронный средство подсчёт голос  \n",
       "8  лондонский гайд-парк это место митинг прежде парк  \n",
       "9  обама продлить полномочие наса сотрудничество ...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.Word2Vec([text.split() for text in data_norm], size=50, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model, dim):\n",
    "    text = text.split()\n",
    "    \n",
    "    # чтобы не доставать одно слово несколько раз\n",
    "    # сделаем счетчик, а потом векторы домножим на частоту\n",
    "    words = Counter(text)\n",
    "    total = len(text)\n",
    "    vectors = np.zeros((len(words), dim))\n",
    "    \n",
    "    for i,word in enumerate(words):\n",
    "        try:\n",
    "            v = model[word]\n",
    "            vectors[i] = v*(words[word]/total) # просто умножаем вектор на частоту\n",
    "        except (KeyError, ValueError):\n",
    "            continue\n",
    "    \n",
    "    if vectors.any():\n",
    "        vector = np.average(vectors, axis=0)\n",
    "    else:\n",
    "        vector = np.zeros((dim))\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "dim = 50\n",
    "X_text_1_w2v = np.zeros((len(data['text_1_norm']), dim))\n",
    "X_text_2_w2v = np.zeros((len(data['text_2_norm']), dim))\n",
    "\n",
    "for i, text in enumerate(data['text_1_norm'].values):\n",
    "    X_text_1_w2v[i] = get_embedding(text, w2v, dim)\n",
    "    \n",
    "for i, text in enumerate(data['text_2_norm'].values):\n",
    "    X_text_2_w2v[i] = get_embedding(text, w2v, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_w2v = np.concatenate([X_text_1_w2v, X_text_2_w2v], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7227, 100)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_w2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cros val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7227,)\n"
     ]
    }
   ],
   "source": [
    "y = data['label'].values\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.48      0.46      0.47       629\n",
      "           0       0.45      0.67      0.54       737\n",
      "           1       0.37      0.08      0.13       441\n",
      "\n",
      "    accuracy                           0.46      1807\n",
      "   macro avg       0.43      0.41      0.38      1807\n",
      "weighted avg       0.44      0.46      0.42      1807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_X, valid_X, train_y, valid_y = train_test_split(X_text_w2v, y,random_state=1)\n",
    "clf = LogisticRegression(C=1000)\n",
    "clf.fit(train_X, train_y)\n",
    "preds = clf.predict(valid_X)\n",
    "print(classification_report(valid_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4498255886930286"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X_text_w2v, y, scoring='f1_micro', cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k_range = range(1,31)\n",
    "cv_scores = []\n",
    "for n in k_range:\n",
    "    knn = KNeighborsClassifier(n)\n",
    "    scores = cross_val_score(knn, X_text_w2v, y, cv=10,scoring='f1_micro')\n",
    "    cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(k_range,cv_scores)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('f1_micro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4703929164360819\n"
     ]
    }
   ],
   "source": [
    "best_knn = KNeighborsClassifier(n_neighbors=20)\n",
    "best_knn.fit(train_X,train_y)\n",
    "print(best_knn.score(valid_X,valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下为非交叉验证，仅供参考"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X_text_w2v, y,random_state=1)\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_leaf=15,\n",
    "                             class_weight='balanced')\n",
    "clf.fit(train_X, train_y)\n",
    "preds = clf.predict(valid_X)\n",
    "print(classification_report(valid_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogReg\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X_text_w2v, y,random_state=1)\n",
    "clf = LogisticRegression(C=1000)\n",
    "clf.fit(train_X, train_y)\n",
    "preds = clf.predict(valid_X)\n",
    "print(classification_report(valid_y, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w2v rusvectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tag=pd.read_csv('data_paraphraser_norm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>text_1_norm</th>\n",
       "      <th>text_2_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Полицейским разрешат стрелять на поражение по ...</td>\n",
       "      <td>Полиции могут разрешить стрелять по хулиганам ...</td>\n",
       "      <td>полицейский_NOUN разрешать_VERB стрелять_VERB ...</td>\n",
       "      <td>полиция_NOUN мочь_VERB разрешать_VERB стрелять...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Право полицейских на проникновение в жилище ре...</td>\n",
       "      <td>Правила внесудебного проникновения полицейских...</td>\n",
       "      <td>право_ADV полицейский_NOUN на_ADP проникновени...</td>\n",
       "      <td>правило_NOUN внесудебный_ADJ проникновение_NOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Президент Египта ввел чрезвычайное положение в...</td>\n",
       "      <td>Власти Египта угрожают ввести в стране чрезвыч...</td>\n",
       "      <td>президент_NOUN египет_NOUN вводить_VERB чрезвы...</td>\n",
       "      <td>власть_NOUN египет_NOUN угрожать_VERB вводить_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>Вернувшихся из Сирии россиян волнует вопрос тр...</td>\n",
       "      <td>Самолеты МЧС вывезут россиян из разрушенной Си...</td>\n",
       "      <td>вернуться_VERB из_ADP сирия_NOUN россиянин_NOU...</td>\n",
       "      <td>самолет_NOUN мчс_NOUN вывозить_VERB россиянин_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>В Москву из Сирии вернулись 2 самолета МЧС с р...</td>\n",
       "      <td>Самолеты МЧС вывезут россиян из разрушенной Си...</td>\n",
       "      <td>в_ADP москва_NOUN из_ADP сирия_NOUN вернуться_...</td>\n",
       "      <td>самолет_NOUN мчс_NOUN вывозить_VERB россиянин_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Приставы соберут отпечатки пальцев российских ...</td>\n",
       "      <td>Приставы снимут отпечатки пальцев у злостных н...</td>\n",
       "      <td>пристав_NOUN собирать_VERB отпечаток_NOUN пале...</td>\n",
       "      <td>пристав_NOUN снимать_VERB отпечаток_NOUN палец...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1</td>\n",
       "      <td>На саратовского дебошира с борта самолета Моск...</td>\n",
       "      <td>Саратовский дебошир отказывается возвращаться ...</td>\n",
       "      <td>на_ADP саратовский_ADJ дебошир_NOUN с_ADP борт...</td>\n",
       "      <td>саратовский_ADJ дебошир_NOUN отказываться_VERB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>ЦИК хочет отказаться от электронной системы по...</td>\n",
       "      <td>ЦИК может отказаться от электронных средств по...</td>\n",
       "      <td>цик_NOUN хотеть_VERB отказываться_VERB от_ADP ...</td>\n",
       "      <td>цик_NOUN мочь_VERB отказываться_VERB от_ADP эл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1</td>\n",
       "      <td>Суд Петербурга оставил на потом дело о гибели ...</td>\n",
       "      <td>Лондонский Гайд-парк - это не место для митинг...</td>\n",
       "      <td>суд_NOUN петербург_NOUN оставлять_VERB на_ADP ...</td>\n",
       "      <td>лондонский_ADJ гайд_NOUN парк_NOUN это_PART не...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1</td>\n",
       "      <td>Страны ОПЕК сократили добычу нефти на 1 млн ба...</td>\n",
       "      <td>Обама продлил полномочия НАСА по сотрудничеств...</td>\n",
       "      <td>страна_NOUN опек_NOUN сокращать_VERB добыча_NO...</td>\n",
       "      <td>обама_NOUN продлять_VERB полномочие_NOUN нас_N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             text_1  \\\n",
       "0      0  Полицейским разрешат стрелять на поражение по ...   \n",
       "1      0  Право полицейских на проникновение в жилище ре...   \n",
       "2      0  Президент Египта ввел чрезвычайное положение в...   \n",
       "3     -1  Вернувшихся из Сирии россиян волнует вопрос тр...   \n",
       "4      0  В Москву из Сирии вернулись 2 самолета МЧС с р...   \n",
       "5      1  Приставы соберут отпечатки пальцев российских ...   \n",
       "6     -1  На саратовского дебошира с борта самолета Моск...   \n",
       "7      0  ЦИК хочет отказаться от электронной системы по...   \n",
       "8     -1  Суд Петербурга оставил на потом дело о гибели ...   \n",
       "9     -1  Страны ОПЕК сократили добычу нефти на 1 млн ба...   \n",
       "\n",
       "                                              text_2  \\\n",
       "0  Полиции могут разрешить стрелять по хулиганам ...   \n",
       "1  Правила внесудебного проникновения полицейских...   \n",
       "2  Власти Египта угрожают ввести в стране чрезвыч...   \n",
       "3  Самолеты МЧС вывезут россиян из разрушенной Си...   \n",
       "4  Самолеты МЧС вывезут россиян из разрушенной Си...   \n",
       "5  Приставы снимут отпечатки пальцев у злостных н...   \n",
       "6  Саратовский дебошир отказывается возвращаться ...   \n",
       "7  ЦИК может отказаться от электронных средств по...   \n",
       "8  Лондонский Гайд-парк - это не место для митинг...   \n",
       "9  Обама продлил полномочия НАСА по сотрудничеств...   \n",
       "\n",
       "                                         text_1_norm  \\\n",
       "0  полицейский_NOUN разрешать_VERB стрелять_VERB ...   \n",
       "1  право_ADV полицейский_NOUN на_ADP проникновени...   \n",
       "2  президент_NOUN египет_NOUN вводить_VERB чрезвы...   \n",
       "3  вернуться_VERB из_ADP сирия_NOUN россиянин_NOU...   \n",
       "4  в_ADP москва_NOUN из_ADP сирия_NOUN вернуться_...   \n",
       "5  пристав_NOUN собирать_VERB отпечаток_NOUN пале...   \n",
       "6  на_ADP саратовский_ADJ дебошир_NOUN с_ADP борт...   \n",
       "7  цик_NOUN хотеть_VERB отказываться_VERB от_ADP ...   \n",
       "8  суд_NOUN петербург_NOUN оставлять_VERB на_ADP ...   \n",
       "9  страна_NOUN опек_NOUN сокращать_VERB добыча_NO...   \n",
       "\n",
       "                                         text_2_norm  \n",
       "0  полиция_NOUN мочь_VERB разрешать_VERB стрелять...  \n",
       "1  правило_NOUN внесудебный_ADJ проникновение_NOU...  \n",
       "2  власть_NOUN египет_NOUN угрожать_VERB вводить_...  \n",
       "3  самолет_NOUN мчс_NOUN вывозить_VERB россиянин_...  \n",
       "4  самолет_NOUN мчс_NOUN вывозить_VERB россиянин_...  \n",
       "5  пристав_NOUN снимать_VERB отпечаток_NOUN палец...  \n",
       "6  саратовский_ADJ дебошир_NOUN отказываться_VERB...  \n",
       "7  цик_NOUN мочь_VERB отказываться_VERB от_ADP эл...  \n",
       "8  лондонский_ADJ гайд_NOUN парк_NOUN это_PART не...  \n",
       "9  обама_NOUN продлять_VERB полномочие_NOUN нас_N...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tag.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'полицейский_NOUN разрешать_VERB стрелять_VERB на_ADP поражение_NOUN по_ADP гражданин_NOUN с_ADP травматика_NOUN'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tag['text_1_norm'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tag = data_tag['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('март_NOUN', 0.9544488191604614),\n",
       " ('апрель_NOUN', 0.9534032344818115),\n",
       " ('ноябрь_NOUN', 0.9383174777030945),\n",
       " ('октябрь_NOUN', 0.9273386597633362),\n",
       " ('декабрь_NOUN', 0.9178366661071777),\n",
       " ('июнь_NOUN', 0.916779637336731),\n",
       " ('май_NOUN', 0.9141846895217896),\n",
       " ('сентябрь_NOUN', 0.9087847471237183),\n",
       " ('август_NOUN', 0.9031303524971008),\n",
       " ('январь_NOUN', 0.8994792699813843)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('февраль_NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 50\n",
    "X_text_1_rv = np.zeros((len(data_tag['text_1_norm']), dim))\n",
    "X_text_2_rv = np.zeros((len(data_tag['text_2_norm']), dim))\n",
    "\n",
    "for i, text in enumerate(data_tag['text_1_norm'].values):\n",
    "    X_text_1_rv[i] = get_embedding(text, model, dim)\n",
    "    \n",
    "for i, text in enumerate(data_tag['text_2_norm'].values):\n",
    "    X_text_2_rv[i] = get_embedding(text, model, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_rv = np.concatenate([X_text_1_rv, X_text_2_rv], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       629\n",
      "           0       0.41      1.00      0.58       737\n",
      "           1       0.00      0.00      0.00       441\n",
      "\n",
      "    accuracy                           0.41      1807\n",
      "   macro avg       0.14      0.33      0.19      1807\n",
      "weighted avg       0.17      0.41      0.24      1807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_X, valid_X, train_y, valid_y = train_test_split(X_text_rv, y_tag,random_state=1)\n",
    "clf = LogisticRegression(C=1000)\n",
    "clf.fit(train_X, train_y)\n",
    "preds = clf.predict(valid_X)\n",
    "print(classification_report(valid_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40916010007067494"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X_text_rv, y_tag, scoring='f1_micro', cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=0.4, max_features=1000,\n",
       "                min_df=3, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=3, max_df=0.4, max_features=1000)\n",
    "tfidf.fit(pd.concat([data['text_1_norm'], data['text_2_norm']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(200)\n",
    "\n",
    "X_text_1_svd = svd.fit_transform(tfidf.transform(data['text_1_norm']))\n",
    "X_text_2_svd = svd.fit_transform(tfidf.transform(data['text_2_norm']))\n",
    "\n",
    "X_text_svd = np.concatenate([X_text_1_svd, X_text_2_svd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7227, 400)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_svd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cos similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2vec_svd1 = X_text_1.T\n",
    "# id2vec_svd2 = X_text_2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_svd = [cosine_similarity(v.reshape(1, -1), X_text_2_svd[i].reshape(1, -1)).tolist()[0][0] for i, v in enumerate(X_text_1_svd)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.06441175922144012,\n",
       " 0.01829075058195688,\n",
       " 0.050229458401730945,\n",
       " -0.10377657305298164,\n",
       " -0.1103977943571668,\n",
       " 0.007383872254929836,\n",
       " -0.056426303499369834,\n",
       " -0.017098420656201447,\n",
       " 0.006976219517873194,\n",
       " 0.014941552134898641]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_svd[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This NMF instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-33896c194dd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNMF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_text_1_nmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_1_norm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_text_2_nmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_2_norm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python\\lib\\site-packages\\sklearn\\decomposition\\nmf.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1311\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m         \"\"\"\n\u001b[1;32m-> 1313\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n_components_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m         W, _, n_iter_ = non_negative_factorization(\n",
      "\u001b[1;32md:\\program files\\python\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This NMF instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "nmf = NMF(200)\n",
    "\n",
    "X_text_1_nmf = nmf.transform(tfidf.transform(data['text_1_norm']))\n",
    "X_text_2_nmf = nmf.transform(tfidf.transform(data['text_2_norm']))\n",
    "\n",
    "X_text_nmf = np.concatenate([X_text_1_nmf, X_text_2_nmf], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### косинусная близость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_nmf = [cosine_similarity(v.reshape(1, -1), X_text_2_nmf[i].reshape(1, -1)).tolist()[0][0] for i, v in enumerate(X_text_1_nmf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8565607377206113,\n",
       " 0.36964653977640455,\n",
       " 0.7807633195813233,\n",
       " 0.4087839826071128,\n",
       " 0.23797067697922028,\n",
       " 0.05018703371798052,\n",
       " 0.3644721493031122,\n",
       " 0.3489559973434516,\n",
       " 0.08092123044334286,\n",
       " 0.02661114718782815]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_nmf[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V самостоятельно обученная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9093553040093278,\n",
       " 0.9162935532635855,\n",
       " 0.9508713657789876,\n",
       " 0.7610319787133144,\n",
       " 0.9083803325663123,\n",
       " 0.9244763677726099,\n",
       " 0.691226839678667,\n",
       " 0.9688288204766886,\n",
       " 0.7165422628726466,\n",
       " 0.7288469007395649]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_w2v = [cosine_similarity(v.reshape(1, -1), X_text_2_w2v[i].reshape(1, -1)).tolist()[0][0] for i, v in enumerate(X_text_1_w2v)]\n",
    "cos_sim_w2v[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V rusvectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_rv = [cosine_similarity(v.reshape(1, -1), X_text_2_rv[i].reshape(1, -1)).tolist()[0][0] for i, v in enumerate(X_text_1_rv)]\n",
    "cos_sim_rv[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text = gensim.models.FastText([text.split() for text in data_norm], size=50, min_n=4, max_n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "dim = 50\n",
    "data['text_1_notnorm'] = data['text_1'].apply(tokenize)\n",
    "data['text_2_notnorm'] = data['text_2'].apply(tokenize)\n",
    "\n",
    "X_text_1_ft = np.zeros((len(data['text_1_notnorm']), dim))\n",
    "X_text_2_ft = np.zeros((len(data['text_2_notnorm']), dim))\n",
    "\n",
    "for i, text in enumerate(data['text_1_notnorm'].values):\n",
    "    X_text_1_ft[i] = get_embedding(text, fast_text, dim)\n",
    "    \n",
    "for i, text in enumerate(data['text_2_notnorm'].values):\n",
    "    X_text_2_ft[i] = get_embedding(text, fast_text, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8030769453455194,\n",
       " 0.7447322572955146,\n",
       " 0.6308851035754462,\n",
       " 0.3842010740534307,\n",
       " 0.265047370047229,\n",
       " 0.7304068289115696,\n",
       " 0.4336536261772452,\n",
       " 0.8857981894785179,\n",
       " 0.2316844764635385,\n",
       " 0.10900673113157934]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_ft = [cosine_similarity(v.reshape(1, -1), X_text_2_ft[i].reshape(1, -1)).tolist()[0][0] for i, v in enumerate(X_text_1_ft)]\n",
    "cos_sim_ft[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
