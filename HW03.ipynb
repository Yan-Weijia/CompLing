{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yan-Weijia/CompLing/blob/master/HW03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqOgS_2_lhVY",
        "colab_type": "text"
      },
      "source": [
        "# Задание 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMzkTaSelgeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, re # 文件路径库；字符串匹配库\n",
        "from string import punctuation\n",
        "import numpy as np # 维度数组和矩阵，针对数组运算的函数\n",
        "import json # 数据交换格式 \"key\":value {}object无序 []array有序 value可以是\"\"括起来的string, number, true, false, null, object, array\n",
        "from collections import Counter\n",
        "from pprint import pprint # 格式化输出\n",
        "from nltk import sent_tokenize\n",
        "punctuation += \"«»—…“”\"\n",
        "punct = set(punctuation)\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score # 机器学习算法库.矩阵运算；分类，精确度"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CTiqhh37SRt",
        "colab_type": "code",
        "outputId": "9afbe272-fe27-4018-f572-84a63377812b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_YPj_L3PxmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gzip\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGeOUvuUnOsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "59eb50e3-8424-4e07-b7d6-3218da10edb1"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/sents_with_mistakes.txt\n",
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/correct_sents.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-25 06:27:05--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/sents_with_mistakes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 123167 (120K) [text/plain]\n",
            "Saving to: ‘sents_with_mistakes.txt’\n",
            "\n",
            "\rsents_with_mistakes   0%[                    ]       0  --.-KB/s               \rsents_with_mistakes 100%[===================>] 120.28K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-11-25 06:27:06 (3.93 MB/s) - ‘sents_with_mistakes.txt’ saved [123167/123167]\n",
            "\n",
            "--2019-11-25 06:27:08--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/correct_sents.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 120672 (118K) [text/plain]\n",
            "Saving to: ‘correct_sents.txt’\n",
            "\n",
            "correct_sents.txt   100%[===================>] 117.84K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-11-25 06:27:08 (3.79 MB/s) - ‘correct_sents.txt’ saved [120672/120672]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUtpeAobnWCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
        "true = open('correct_sents.txt', encoding='utf8').read().splitlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCe6_dW2rPus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "e53d2262-03ef-42f4-d3e3-b9a7bae44d62"
      },
      "source": [
        "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-25 06:27:18--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191125%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191125T062718Z&X-Amz-Expires=300&X-Amz-Signature=2f642fecb56aa4d77f5649460e4cd34739d0f8d4d6007086c34385f878df0e0a&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-11-25 06:27:18--  https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191125%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191125T062718Z&X-Amz-Expires=300&X-Amz-Signature=2f642fecb56aa4d77f5649460e4cd34739d0f8d4d6007086c34385f878df0e0a&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.230.227\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.230.227|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 527373240 (503M) [application/octet-stream]\n",
            "Saving to: ‘lenta-ru-news.csv.gz’\n",
            "\n",
            "lenta-ru-news.csv.g 100%[===================>] 502.94M  86.5MB/s    in 6.0s    \n",
            "\n",
            "2019-11-25 06:27:24 (84.4 MB/s) - ‘lenta-ru-news.csv.gz’ saved [527373240/527373240]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zo4-yiut9y9C",
        "colab": {}
      },
      "source": [
        "# txt里列表里每一句拆分成词 [[词，词，词，词]，[词，词，词]]\n",
        "def norm_txt(text):\n",
        "  new_txt = []\n",
        "  for sent in text:\n",
        "    tokens = sent.lower().split()\n",
        "    tokens = [re.sub('(^\\W+|\\W+$)', '', tkn) for tkn in tokens if (set(tkn)-punct)]\n",
        "    new_txt.append(tokens)\n",
        "  return new_txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqyFcsNz7zsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "badlist = norm_txt(bad)\n",
        "truelist = norm_txt(true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raMOgK7aNLXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('corpus_5000.txt', 'w')\n",
        "with gzip.open('lenta-ru-news.csv.gz', 'rt') as archive:\n",
        "    reader = csv.reader(archive, delimiter=',', quotechar='\"')\n",
        "    for i, line in enumerate(reader):\n",
        "        if i < 5000:\n",
        "            f.write(line[2].replace('\\xa0', ' ') + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL0GM9afjdOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(text):\n",
        "    normalized_text = [(word.strip(punctuation)) for word in text.lower().split()] # 按空格拆成单词后去标点，此列表项为word\n",
        "    normalized_text = [word for word in normalized_text if word] # 去除''空项\n",
        "    return normalized_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW9awhz1jdPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [] # [[\"\",\"\"],[\"\",\"\"],[\"\",\"\"]] 把词按句子分组\n",
        "for text in open('corpus_5000.txt').read().splitlines():\n",
        "    sents = sent_tokenize(text)\n",
        "    norm_sents = [normalize(sent) for sent in sents]\n",
        "    corpus += norm_sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vftd8H_djdSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WORDS = Counter() # corpus词出现的频次\n",
        "for sent in corpus:\n",
        "    WORDS.update(sent)\n",
        "dict_corp = dict(WORDS) # 库词：频次"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_EPWXMLx_Np",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "185fac03-d998-49f7-d5db-0ae2c20c3059"
      },
      "source": [
        "WORDS.most_common(10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('в', 41930),\n",
              " ('и', 20346),\n",
              " ('на', 17455),\n",
              " ('что', 11631),\n",
              " ('с', 9616),\n",
              " ('по', 8778),\n",
              " ('не', 7696),\n",
              " ('из', 4369),\n",
              " ('он', 4322),\n",
              " ('о', 3903)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcnrYvtCjdP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set去重corpus词\n",
        "vocab = set() # set会去重，列表update到set：列表中的项添加到set\n",
        "\n",
        "for sent in corpus:\n",
        "    vocab.update(sent)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YLJLKbbr0cnc"
      },
      "source": [
        "单个库词去掉n个字母的各种形式list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgPZb0p8jdU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deletes(word): # 找出差一个字母的选项\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R] # 漏打一个字母\n",
        "    return list(set(deletes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITFBZhH_10bV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 建dict_corp2 {错形式：[正确词], 错形式：[正确词, 正确词]}\n",
        "dict_corp2 = {}\n",
        "for word in dict_corp:\n",
        "  for edword in deletes(word):\n",
        "    if edword not in dict_corp2:\n",
        "      dict_corp2[edword] = [word]\n",
        "    else:\n",
        "      dict_corp2[edword].append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTB5LkwbIvev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62877654-dcba-4c7c-df6c-6dc425364f26"
      },
      "source": [
        "st = set()\n",
        "st.update([1,2])\n",
        "st.update([1,2,3,4])\n",
        "print(st)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1, 2, 3, 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "paaR0jPrds81",
        "colab": {}
      },
      "source": [
        "def correction(badword):\n",
        "  if badword in dict_corp:\n",
        "    corrected = badword # 没错不用改\n",
        "  else:\n",
        "    bad_forms = deletes(badword) # {bad1, bad2, ...}\n",
        "    variants = set()\n",
        "    for form in bad_forms:\n",
        "      if form in dict_corp2:\n",
        "        variants.update(dict_corp2[form])\n",
        "    dict_vars = {} # {候选：频次}\n",
        "    if variants:\n",
        "      dict_vars = {var:dict_corp[var] for var in list(variants)}\n",
        "      corrected = max(dict_vars, key=dict_vars.get)\n",
        "    else:\n",
        "      corrected = badword\n",
        "  return corrected"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhLL-NRwMUEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "truelist = []\n",
        "for sent in badlist:\n",
        "  for word in sent:\n",
        "    truelist.append(correction(word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiTavtU_Mnaa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "edc36a59-410d-40fb-bc26-862e1ee3251a"
      },
      "source": [
        "print(truelist[:20])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['симпатичнейшое', 'шпионской', 'устройство', 'такой', 'себе', 'гламурный', 'фотоаппарат', 'девушки', 'бонда', 'миниатюрная', 'модель', 'камеры', 'superheadz', 'camp', 'camera', 'апофеозом', 'дня', 'для', 'меня', 'сегодня']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXAoQ91Xe_w3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "20e7abcb-92a5-4d06-eaf4-46970a4e408b"
      },
      "source": [
        "%%time\n",
        "print(correction('сонце'))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "конце\n",
            "CPU times: user 2.15 ms, sys: 6 µs, total: 2.15 ms\n",
            "Wall time: 1.5 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTbw4v76jda_",
        "colab_type": "code",
        "outputId": "84d08d9c-753a-4253-e2cc-bcf8bb03040b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%%time\n",
        "correction('солнце')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
            "Wall time: 10.5 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'солнце'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmpfmMWPjdbR",
        "colab_type": "code",
        "outputId": "1d1806e1-a6b3-4cb0-f434-b731a283340e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%%time\n",
        "correction('насмехатьсяаававттававаываываы')"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 92 µs, sys: 3 µs, total: 95 µs\n",
            "Wall time: 100 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'насмехатьсяаававттававаываываы'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpVxB9JrjdFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# напишем функцию, которая будет сопоставлять слова в правильном и ошибочном варианте\n",
        "# разобьем предложение по пробелам и удалим пунктуация на границах слов\n",
        "# 匹配正确和错误的对(alignment)；按空格把句子拆分成词，去除标点\n",
        "def align_words(sent_1, sent_2):\n",
        "    tokens_1 = sent_1.lower().split()\n",
        "    tokens_2 = sent_2.lower().split()\n",
        "    \n",
        "    tokens_1 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_1 if (set(token)-punct)]\n",
        "    tokens_2 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_2 if (set(token)-punct)]\n",
        "    \n",
        "    return list(zip(tokens_1, tokens_2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0vOlzPsjdZ6",
        "colab_type": "code",
        "outputId": "e85c665a-f495-4f0f-d00d-223014ac63b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "correct = 0 # 订正后对的总词数（本来对没动的 + 本来错改对的）\n",
        "total = 0 # 总词数\n",
        "\n",
        "total_mistaken = 0 # 总错词数\n",
        "mistaken_fixed = 0 # 改对了数\n",
        "\n",
        "total_correct = 0 # 本来是对的数\n",
        "correct_broken = 0 # 改错了数\n",
        "\n",
        "cashed = {}\n",
        "for i in range(len(true)): # 正确词的数量\n",
        "    word_pairs = align_words(true[i], bad[i]) # 对照配对\n",
        "    for pair in word_pairs:\n",
        "        total += 1 # 总词数\n",
        "        predicted = cashed.get(pair[1], correction(pair[1])) # 错误词、词库修正后词配对字典\n",
        "        cashed[pair[0]] = predicted # 正确词、词库修正后词\n",
        "        if predicted == pair[0]: # 修正词 == 对词\n",
        "            correct += 1 # 订正后对的总词数\n",
        "        \n",
        "        if pair[0] == pair[1]: # 对词 == 对错\n",
        "            total_correct += 1 # 错词是对的数\n",
        "            if pair[0] !=  predicted: # 对词 != 修正词\n",
        "                correct_broken += 1 # 改错了数\n",
        "        else: # 错词 != 对词\n",
        "            total_mistaken += 1 # 总错词数\n",
        "            if pair[0] == predicted: # 对词 == 修正词\n",
        "                mistaken_fixed += 1 # 改对了数\n",
        "        \n",
        "    if not i % 100:\n",
        "        print(i)\n",
        "        "
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yyr7knZjdaW",
        "colab_type": "code",
        "outputId": "0a8f27a5-4bc9-403e-83b5-9e1f4f59863a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(correct/total) # 订正后总对的数/总词数\n",
        "print(mistaken_fixed/total_mistaken) # 改对了数/总错词数\n",
        "print(correct_broken/total_correct) # 改错了数/本来是对的数"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.682017982017982\n",
            "0.19800460475825019\n",
            "0.24554955782703572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m7avOgrjdHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mistakes = [] # 错误词list\n",
        "total = 0 # 总词数\n",
        "for i in range(len(true)): # len(true)是正确文本的句子数\n",
        "    word_pairs = align_words(true[i], bad[i]) # 每一句的正误词配对\n",
        "    for pair in word_pairs:\n",
        "        total += 1 # 每一句里的词总词数+1\n",
        "        if pair[0] != pair[1]: # 误词错误\n",
        "            mistakes.append(pair)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niK7UucpjdcX",
        "colab_type": "code",
        "outputId": "8cd2c602-37a5-42c3-c7d2-dae56a657912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "[(wt[0], wt[1], correction(wt[1])) for wt, _ in Counter(mistakes).most_common(10)] # mistakes: 错误词list"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('сегодня', 'седня', 'седан'),\n",
              " ('вообще', 'вобще', 'общей'),\n",
              " ('вообще', 'ваще', 'чаще'),\n",
              " ('естественно', 'естесственно', 'стесственно'),\n",
              " ('хочется', 'хочеться', 'очеться'),\n",
              " ('кстати', 'кстате', 'статье'),\n",
              " ('очень', 'ооочень', 'оочень'),\n",
              " ('как-то', 'както', 'актом'),\n",
              " ('очень', 'оооочень', 'ооооень'),\n",
              " ('это', 'ето', 'что')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKwOpUBXlyLm",
        "colab_type": "text"
      },
      "source": [
        "# Задание 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_aBFSsxql86",
        "colab_type": "code",
        "outputId": "a2fe8b0c-e322-4fd5-82af-8eac51f7a0d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "import itertools\n",
        "!pip install pymorphy2[fast]\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from collections import Counter, defaultdict\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from nltk.tokenize import sent_tokenize\n",
        "morph = MorphAnalyzer()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2[fast]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\r\u001b[K     |███████                         | 10kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 20kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 30kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 40kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 10.5MB/s \n",
            "\u001b[?25hCollecting DAWG>=0.7.3; extra == \"fast\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c0/d8d967bcaa0b572f9dc1d878bbf5a7bfd5afa2102a5ae426731f6ce3bc26/DAWG-0.7.8.tar.gz (255kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 48.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: DAWG\n",
            "  Building wheel for DAWG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DAWG: filename=DAWG-0.7.8-cp36-cp36m-linux_x86_64.whl size=764525 sha256=0f8f628bc8166a95b094014fc2674831d60c77c2d5edbaec5696c7ef7ccd0c16\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/88/d0/4e4abc83eb8f59a71e8dbd8ba99fd5615a3af1fac1ef7f8825\n",
            "Successfully built DAWG\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts, DAWG, pymorphy2\n",
            "Successfully installed DAWG-0.7.8 dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK8hubILb9DJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_tags(text):\n",
        "  tag_sents = [['<start>', '<start>'] + sent + ['<end>'] for sent in text]\n",
        "  return tag_sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfbVS-_UjdmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_corpus = add_tags(corpus)\n",
        "sentences_badlist = add_tags(badlist) # [[s,s,词，词，词，词,e]，[s,词，词，词,e]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l98msVj-3mfF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "fcf1eeda-50bf-472c-920d-6f669d2aead7"
      },
      "source": [
        "print(sentences_corpus[:5])\n",
        "print(sentences_badlist[:5])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['<start>', '<start>', 'text', '<end>'], ['<start>', '<start>', 'вице-премьер', 'по', 'социальным', 'вопросам', 'татьяна', 'голикова', 'рассказала', 'в', 'каких', 'регионах', 'россии', 'зафиксирована', 'наиболее', 'высокая', 'смертность', 'от', 'рака', 'сообщает', 'риа', 'новости', '<end>'], ['<start>', '<start>', 'по', 'словам', 'голиковой', 'чаще', 'всего', 'онкологические', 'заболевания', 'становились', 'причиной', 'смерти', 'в', 'псковской', 'тверской', 'тульской', 'и', 'орловской', 'областях', 'а', 'также', 'в', 'севастополе', '<end>'], ['<start>', '<start>', 'вице-премьер', 'напомнила', 'что', 'главные', 'факторы', 'смертности', 'в', 'россии', 'рак', 'и', 'болезни', 'системы', 'кровообращения', '<end>'], ['<start>', '<start>', 'в', 'начале', 'года', 'стало', 'известно', 'что', 'смертность', 'от', 'онкологических', 'заболеваний', 'среди', 'россиян', 'снизилась', 'впервые', 'за', 'три', 'года', '<end>']]\n",
            "[['<start>', '<start>', 'симпатичнейшое', 'шпионское', 'устройство', 'такой', 'себе', 'гламурный', 'фотоаппарат', 'девушки', 'бонда', 'миниатюрная', 'модель', 'камеры', 'superheadz', 'clap', 'camera', '<end>'], ['<start>', '<start>', 'опофеозом', 'дня', 'для', 'меня', 'сегодня', 'стала', 'фраза', 'услышанная', 'в', 'новостях', '<end>'], ['<start>', '<start>', 'пояним', 'эту', 'мысль', '<end>'], ['<start>', '<start>', 'полчатся', 'вот', 'такие', 'язычки', '<end>'], ['<start>', '<start>', 'в', 'массе', 'своей', 'они', 'конечно', 'все', 'оччччень', 'милые', '<end>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw_5wlZLrJNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ngrammer(tokens, n):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(tuple(tokens[i:i+n]))\n",
        "    return ngrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC60y6XVu92R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigrams = Counter()\n",
        "trigrams = Counter()\n",
        "\n",
        "for sentence in sentences_corpus:\n",
        "  bigrams.update(ngrammer(sentence, 2))\n",
        "  trigrams.update(ngrammer(sentence, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS6pPun7wbOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trigrams_badlist = [ngrammer(sentence, 3) for sentence in sentences_badlist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW268vFMUPGv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "2461e5fb-ddce-4e46-a9da-a8516648dc1a"
      },
      "source": [
        "print(list(trigrams.items())[:20])\n",
        "print(list(bigrams.items())[:20])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(('<start>', '<start>', 'text'), 1), (('<start>', 'text', '<end>'), 1), (('<start>', '<start>', 'вице-премьер'), 12), (('<start>', 'вице-премьер', 'по'), 2), (('вице-премьер', 'по', 'социальным'), 2), (('по', 'социальным', 'вопросам'), 2), (('социальным', 'вопросам', 'татьяна'), 2), (('вопросам', 'татьяна', 'голикова'), 2), (('татьяна', 'голикова', 'рассказала'), 1), (('голикова', 'рассказала', 'в'), 1), (('рассказала', 'в', 'каких'), 1), (('в', 'каких', 'регионах'), 2), (('каких', 'регионах', 'россии'), 2), (('регионах', 'россии', 'зафиксирована'), 1), (('россии', 'зафиксирована', 'наиболее'), 1), (('зафиксирована', 'наиболее', 'высокая'), 1), (('наиболее', 'высокая', 'смертность'), 1), (('высокая', 'смертность', 'от'), 1), (('смертность', 'от', 'рака'), 1), (('от', 'рака', 'сообщает'), 1)]\n",
            "[(('<start>', '<start>'), 59152), (('<start>', 'text'), 1), (('text', '<end>'), 1), (('<start>', 'вице-премьер'), 12), (('вице-премьер', 'по'), 6), (('по', 'социальным'), 4), (('социальным', 'вопросам'), 2), (('вопросам', 'татьяна'), 2), (('татьяна', 'голикова'), 4), (('голикова', 'рассказала'), 1), (('рассказала', 'в'), 28), (('в', 'каких'), 11), (('каких', 'регионах'), 2), (('регионах', 'россии'), 21), (('россии', 'зафиксирована'), 1), (('зафиксирована', 'наиболее'), 1), (('наиболее', 'высокая'), 1), (('высокая', 'смертность'), 1), (('смертность', 'от'), 6), (('от', 'рака'), 7)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArWt2RI0wkhI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1bd07772-e4e8-4f60-bb66-db9c8f57990e"
      },
      "source": [
        "print(trigrams_badlist[:20])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[('<start>', '<start>', 'симпатичнейшое'), ('<start>', 'симпатичнейшое', 'шпионское'), ('симпатичнейшое', 'шпионское', 'устройство'), ('шпионское', 'устройство', 'такой'), ('устройство', 'такой', 'себе'), ('такой', 'себе', 'гламурный'), ('себе', 'гламурный', 'фотоаппарат'), ('гламурный', 'фотоаппарат', 'девушки'), ('фотоаппарат', 'девушки', 'бонда'), ('девушки', 'бонда', 'миниатюрная'), ('бонда', 'миниатюрная', 'модель'), ('миниатюрная', 'модель', 'камеры'), ('модель', 'камеры', 'superheadz'), ('камеры', 'superheadz', 'clap'), ('superheadz', 'clap', 'camera'), ('clap', 'camera', '<end>')], [('<start>', '<start>', 'опофеозом'), ('<start>', 'опофеозом', 'дня'), ('опофеозом', 'дня', 'для'), ('дня', 'для', 'меня'), ('для', 'меня', 'сегодня'), ('меня', 'сегодня', 'стала'), ('сегодня', 'стала', 'фраза'), ('стала', 'фраза', 'услышанная'), ('фраза', 'услышанная', 'в'), ('услышанная', 'в', 'новостях'), ('в', 'новостях', '<end>')], [('<start>', '<start>', 'пояним'), ('<start>', 'пояним', 'эту'), ('пояним', 'эту', 'мысль'), ('эту', 'мысль', '<end>')], [('<start>', '<start>', 'полчатся'), ('<start>', 'полчатся', 'вот'), ('полчатся', 'вот', 'такие'), ('вот', 'такие', 'язычки'), ('такие', 'язычки', '<end>')], [('<start>', '<start>', 'в'), ('<start>', 'в', 'массе'), ('в', 'массе', 'своей'), ('массе', 'своей', 'они'), ('своей', 'они', 'конечно'), ('они', 'конечно', 'все'), ('конечно', 'все', 'оччччень'), ('все', 'оччччень', 'милые'), ('оччччень', 'милые', '<end>')], [('<start>', '<start>', 'нащщот'), ('<start>', 'нащщот', 'чавеса'), ('нащщот', 'чавеса', 'разве'), ('чавеса', 'разве', 'что'), ('разве', 'что', 'не'), ('что', 'не', 'соглашусь'), ('не', 'соглашусь', '<end>')], [('<start>', '<start>', 'многие'), ('<start>', 'многие', 'сетуют'), ('многие', 'сетуют', 'на'), ('сетуют', 'на', 'отсуствие'), ('на', 'отсуствие', 'живого'), ('отсуствие', 'живого', 'взаимодействия'), ('живого', 'взаимодействия', 'между'), ('взаимодействия', 'между', 'учеником'), ('между', 'учеником', 'и'), ('учеником', 'и', 'учителем'), ('и', 'учителем', 'а'), ('учителем', 'а', 'в'), ('а', 'в', 'чем'), ('в', 'чем', 'оно'), ('чем', 'оно', 'по'), ('оно', 'по', 'сути'), ('по', 'сути', '<end>')], [('<start>', '<start>', 'основая'), ('<start>', 'основая', 'цель'), ('основая', 'цель', 'мероприятия'), ('цель', 'мероприятия', 'практическая'), ('мероприятия', 'практическая', 'отработка'), ('практическая', 'отработка', 'навыков'), ('отработка', 'навыков', 'по'), ('навыков', 'по', 'оказанию'), ('по', 'оказанию', 'помощи'), ('оказанию', 'помощи', 'гражданам'), ('помощи', 'гражданам', 'попавшим'), ('гражданам', 'попавшим', 'в'), ('попавшим', 'в', 'дтп'), ('в', 'дтп', 'а'), ('дтп', 'а', 'также'), ('а', 'также', 'повышение'), ('также', 'повышение', 'и'), ('повышение', 'и', 'совершенствование'), ('и', 'совершенствование', 'уровня'), ('совершенствование', 'уровня', 'профессиональной'), ('уровня', 'профессиональной', 'подготовки'), ('профессиональной', 'подготовки', 'сотрудников'), ('подготовки', 'сотрудников', 'мчс'), ('сотрудников', 'мчс', 'при'), ('мчс', 'при', 'проведении'), ('при', 'проведении', 'аварийно-спасательных'), ('проведении', 'аварийно-спасательных', 'работ'), ('аварийно-спасательных', 'работ', 'по'), ('работ', 'по', 'ликвидации'), ('по', 'ликвидации', 'последствий'), ('ликвидации', 'последствий', 'дорожно-транспортных'), ('последствий', 'дорожно-транспортных', 'происшествий'), ('дорожно-транспортных', 'происшествий', 'сокращение'), ('происшествий', 'сокращение', 'временных'), ('сокращение', 'временных', 'показателей'), ('временных', 'показателей', 'реагирования'), ('показателей', 'реагирования', '<end>')], [('<start>', '<start>', 'нарасно'), ('<start>', 'нарасно', 'выброшенные'), ('нарасно', 'выброшенные', 'деньги'), ('выброшенные', 'деньги', 'на'), ('деньги', 'на', 'билет'), ('на', 'билет', 'в'), ('билет', 'в', 'кинотеатр'), ('в', 'кинотеатр', '<end>')], [('<start>', '<start>', 'вобщем'), ('<start>', 'вобщем', 'как'), ('вобщем', 'как', 'вы'), ('как', 'вы', 'знаете'), ('вы', 'знаете', 'из'), ('знаете', 'из', 'моего'), ('из', 'моего', 'не'), ('моего', 'не', 'давнего'), ('не', 'давнего', 'поста'), ('давнего', 'поста', 'я'), ('поста', 'я', 'жаловался'), ('я', 'жаловался', 'на'), ('жаловался', 'на', 'пропажу'), ('на', 'пропажу', 'писем'), ('пропажу', 'писем', 'с'), ('писем', 'с', 'моего'), ('с', 'моего', 'ящека'), ('моего', 'ящека', 'на'), ('ящека', 'на', 'почте.ру'), ('на', 'почте.ру', '<end>')], [('<start>', '<start>', 'предлагю'), ('<start>', 'предлагю', 'поиграть'), ('предлагю', 'поиграть', 'в'), ('поиграть', 'в', 'детскую'), ('в', 'детскую', 'игру'), ('детскую', 'игру', 'ассоциации'), ('игру', 'ассоциации', '<end>')], [('<start>', '<start>', 'сегодяшнее'), ('<start>', 'сегодяшнее', 'утро'), ('сегодяшнее', 'утро', 'выдалось'), ('утро', 'выдалось', 'просто'), ('выдалось', 'просто', 'волшебным'), ('просто', 'волшебным', '<end>')], [('<start>', '<start>', 'хороше'), ('<start>', 'хороше', 'что'), ('хороше', 'что', 'на'), ('что', 'на', 'выходгых'), ('на', 'выходгых', 'не'), ('выходгых', 'не', 'было'), ('не', 'было', 'стен'), ('было', 'стен', 'только'), ('стен', 'только', 'деревья'), ('только', 'деревья', 'да'), ('деревья', 'да', 'ручьи'), ('да', 'ручьи', '<end>')], [('<start>', '<start>', 'а'), ('<start>', 'а', 'рите'), ('а', 'рите', 'снятся'), ('рите', 'снятся', 'сны'), ('снятся', 'сны', 'в'), ('сны', 'в', 'которых'), ('в', 'которых', 'меня'), ('которых', 'меня', 'убивают'), ('меня', 'убивают', 'патаму'), ('убивают', 'патаму', 'шта'), ('патаму', 'шта', 'я'), ('шта', 'я', 'пытаюсь'), ('я', 'пытаюсь', 'всех'), ('пытаюсь', 'всех', 'спасти'), ('всех', 'спасти', '<end>')], [('<start>', '<start>', 'лчше'), ('<start>', 'лчше', 'б'), ('лчше', 'б', 'этот'), ('б', 'этот', 'бунт'), ('этот', 'бунт', 'эритроцитов'), ('бунт', 'эритроцитов', 'переждать'), ('эритроцитов', 'переждать', 'в'), ('переждать', 'в', 'дубраве'), ('в', 'дубраве', 'люминала'), ('дубраве', 'люминала', '<end>')], [('<start>', '<start>', 'поффтыкав'), ('<start>', 'поффтыкав', 'в'), ('поффтыкав', 'в', 'аэропорту'), ('в', 'аэропорту', 'поехали'), ('аэропорту', 'поехали', 'к'), ('поехали', 'к', 'билетным'), ('к', 'билетным', 'кассам'), ('билетным', 'кассам', 'где'), ('кассам', 'где', 'я'), ('где', 'я', 'взял'), ('я', 'взял', 'билет'), ('взял', 'билет', 'на'), ('билет', 'на', 'поезд'), ('на', 'поезд', '<end>')], [('<start>', '<start>', 'компютерная'), ('<start>', 'компютерная', 'программа'), ('компютерная', 'программа', 'для'), ('программа', 'для', 'улучшения'), ('для', 'улучшения', 'зрения'), ('улучшения', 'зрения', '<end>')], [('<start>', '<start>', 'а'), ('<start>', 'а', 'днем'), ('а', 'днем', 'мама'), ('днем', 'мама', 'снится'), ('мама', 'снится', 'как'), ('снится', 'как', 'будто'), ('как', 'будто', 'мы'), ('будто', 'мы', 'с'), ('мы', 'с', 'ней'), ('с', 'ней', 'в'), ('ней', 'в', 'соре'), ('в', 'соре', 'и'), ('соре', 'и', 'она'), ('и', 'она', 'мне'), ('она', 'мне', 'чтото'), ('мне', 'чтото', 'выговаривает'), ('чтото', 'выговаривает', '<end>')], [('<start>', '<start>', 'мошный'), ('<start>', 'мошный', 'лазер'), ('мошный', 'лазер', 'в'), ('лазер', 'в', 'нерабочем'), ('в', 'нерабочем', 'состоянии'), ('нерабочем', 'состоянии', '350'), ('состоянии', '350', 'кредиток'), ('350', 'кредиток', '<end>')], [('<start>', '<start>', 'хороше'), ('<start>', 'хороше', 'когда'), ('хороше', 'когда', 'каждый'), ('когда', 'каждый', 'год'), ('каждый', 'год', 'как'), ('год', 'как', 'первый'), ('как', 'первый', '<end>')]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2_qq7jKSQB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# выбираем, какой вариант подставить в триграмм\n",
        "def needed_trigram(ngram, variants):\n",
        "    dict_vars = {}\n",
        "    t_grs = [(ngram[0], ngram[1], variant) for variant in list(variants)]\n",
        "    for tgram in t_grs:\n",
        "        if tgram[:2] in bigrams:\n",
        "            freq_tr = trigrams[tgram]/bigrams[tgram[:2]]\n",
        "            if freq_tr != 0: # если вероятность ненулевая, добавляем в словарь\n",
        "                dict_vars[tgram[-1]] = freq_tr\n",
        "    \n",
        "    if not dict_vars: # если ничего не нашлось подходящего, берём вероятности по словам \n",
        "        dict_vars = {var:dict_corp[var] for var in list(variants)}\n",
        "    \n",
        "    return max(dict_vars, key=dict_vars.get)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQL76ybpQTV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# исправляем предложение с опорой на триграммы\n",
        "def trigrams_correction(ngrams): # 传错的字典的一句的3grams[('<start>', '<start>', 'симпатичнейшое'), ('<start>', 'симпатичнейшое', 'шпионское'),\n",
        "    corrected_sent = []\n",
        "    for ngram in ngrams: # ('<start>', '<start>', 'симпатичнейшое'),\n",
        "        # проверять будем только новые слова в триграммах, контекст типа (w ошибка w) не учитываем при исправлении\n",
        "        if ngram[-1] in dict_corp: # новое слово в триграмме правильные\n",
        "            corrected_sent.append(ngram[-1])\n",
        "        else: # попалось что-то неправильное\n",
        "            badword = ngram[-1]\n",
        "            bad_forms = deletes(badword)\n",
        "            variants = set()\n",
        "            for form in bad_forms:\n",
        "                if form in dict_corp2:\n",
        "                  variants.update(dict_corp2[form])\n",
        "            if variants:\n",
        "              corrected_sent.append(needed_trigram(ngram, variants))\n",
        "            else:\n",
        "              corrected_sent.append(badword)\n",
        "              \n",
        "    return corrected_sent[:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXTmlDHOQ8Br",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correcteds = []\n",
        "for sent in trigrams_badlist: # для каждого токенизированного предложения в bad\n",
        "    corrected_sent = trigrams_correction(sent)\n",
        "    correcteds.append(corrected_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKBWNx2Y_O2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f1d30ea1-0e0e-4744-894c-3cc89e17e92d"
      },
      "source": [
        "print(correcteds[:20])"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['симпатичнейшое', 'шпионской', 'устройство', 'такой', 'себе', 'гламурный', 'фотоаппарат', 'девушки', 'бонда', 'миниатюрная', 'модель', 'камеры', 'superheadz', 'camp', 'camera'], ['апофеозом', 'дня', 'для', 'меня', 'сегодня', 'стала', 'фраза', 'услышанная', 'в', 'новостях'], ['помним', 'эту', 'мысль'], ['полчатся', 'вот', 'такие', 'язычки'], ['в', 'массе', 'своей', 'они', 'конечно', 'все', 'оччччень', 'милые'], ['нащщот', 'навеса', 'разве', 'что', 'не', 'соглашусь'], ['многие', 'сетуют', 'на', 'отсуствие', 'живого', 'взаимодействия', 'между', 'учеником', 'и', 'учителем', 'а', 'в', 'чем', 'оно', 'по', 'сути'], ['основан', 'цель', 'мероприятия', 'практическая', 'отработка', 'навыков', 'по', 'оказанию', 'помощи', 'гражданам', 'попавшим', 'в', 'дтп', 'а', 'также', 'повышение', 'и', 'совершенствование', 'уровня', 'профессиональной', 'подготовки', 'сотрудников', 'мчс', 'при', 'проведении', 'аварийно-спасательных', 'работ', 'по', 'ликвидации', 'последствий', 'дорожно-транспортных', 'происшествий', 'сокращение', 'временных', 'показателей', 'реагирования'], ['нарасно', 'выброшенные', 'деньги', 'на', 'билет', 'в', 'кинотеатр'], ['вообще', 'как', 'вы', 'знаете', 'из', 'моего', 'не', 'давнего', 'поста', 'я', 'жаловался', 'на', 'пропажу', 'писем', 'с', 'моего', 'щенка', 'на', 'почте.ру'], ['предлагю', 'поиграть', 'в', 'детскую', 'игру', 'ассоциации'], ['сегодяшнее', 'утро', 'выдались', 'просто', 'волшебным'], ['хорошо', 'что', 'на', 'выходных', 'не', 'было', 'стен', 'только', 'деревья', 'да', 'ручки'], ['а', 'ритм', 'снялся', 'сны', 'в', 'которых', 'меня', 'убивают', 'патаму', 'сша', 'я', 'пытаюсь', 'всех', 'спасти'], ['лече', 'б', 'этот', 'бунт', 'эритроцитов', 'переждать', 'в', 'дубраве', 'люминала'], ['поффтыкав', 'в', 'аэропорту', 'поехали', 'к', 'билетные', 'класса', 'где', 'я', 'взял', 'билет', 'на', 'поезд'], ['компютерная', 'программа', 'для', 'улучшения', 'зрения'], ['а', 'днем', 'мама', 'снится', 'как', 'будто', 'мы', 'с', 'ней', 'в', 'свое', 'и', 'она', 'мне', 'то-то', 'выговаривает'], ['модный', 'лазер', 'в', 'нерабочем', 'состоянии', '350', 'кредиток'], ['хорошо', 'когда', 'каждый', 'год', 'как', 'первый']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "R4sJya1zjdnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# оцените качество также как и раньше\n",
        "correct = 0 # 订正后对的总词数（本来对没动的 + 本来错改对的）\n",
        "total = 0 # 总词数\n",
        "\n",
        "mistakes = []\n",
        "total_mistaken = 0 # 总错词数\n",
        "mistaken_fixed = 0 # 改对了数\n",
        "\n",
        "total_correct = 0 # 本来是对的数\n",
        "correct_broken = 0 # 改错了数\n",
        "\n",
        "\n",
        "for i in range(len(true)):\n",
        "    word_pairs = align_words(true[i], bad[i])\n",
        "    \n",
        "    word_pairs = [('<start>', '<start>')] + word_pairs\n",
        "    pred_sent = []\n",
        "    for j in range(1, len(word_pairs)):\n",
        "        \n",
        "        pred = None\n",
        "        predicted = get_closest_hybrid_match(word_pairs[j][1], X, vec)\n",
        "        \n",
        "        \n",
        "        prev_word = word_pairs[j-1][1]\n",
        "        \n",
        "        \n",
        "        if prev_word not in unigrams:\n",
        "            pred = predicted[0][0]\n",
        "            \n",
        "        \n",
        "        else:\n",
        "            \n",
        "            lm_predicted = []\n",
        "            for word, m in predicted:\n",
        "                bigram = ' '.join([prev_word, word])\n",
        "                # домножаем полученную метрику для слова на вероятность биграма\n",
        "                # биграм - предыдущее слово + текущее слово кандидат\n",
        "                lm_predicted.append((word, (m)*(1+(bigrams[bigram]/unigrams[prev_word]))))\n",
        "            if lm_predicted:\n",
        "                \n",
        "                pred = sorted(lm_predicted, key=lambda x: -x[1])[0][0]\n",
        "            \n",
        "        \n",
        "        if pred is None:\n",
        "            pred = word_pairs[j][1]\n",
        "        \n",
        "\n",
        "        \n",
        "        if pred == word_pairs[j][0]:\n",
        "            correct += 1\n",
        "        else:\n",
        "            mistakes.append((word_pairs[j][0], word_pairs[j][1], pred))\n",
        "        total += 1\n",
        "            \n",
        "        if word_pairs[j][0] == word_pairs[j][1]:\n",
        "            total_correct += 1\n",
        "            if word_pairs[j][0] !=  pred:\n",
        "                correct_broken += 1\n",
        "        else:\n",
        "            total_mistaken += 1\n",
        "            if word_pairs[j][0] == pred:\n",
        "                mistaken_fixed += 1\n",
        "    \n",
        "    if not i % 50:\n",
        "        print(i)\n",
        "        print(correct/total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqZ81PeWjdnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(correct/total)\n",
        "print(mistaken_fixed/total_mistaken)\n",
        "print(correct_broken/total_correct)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}