{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yan-Weijia/CompLing/blob/master/HW03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMzkTaSelgeL",
        "colab_type": "code",
        "outputId": "02656cff-dc0a-450c-d01e-dcbd2bd125bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "import re\n",
        "from string import punctuation\n",
        "from collections import Counter, defaultdict\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "from nltk import sent_tokenize\n",
        "import gzip\n",
        "import csv\n",
        "punctuation += \"«»—…“”\"\n",
        "punct = set(punctuation)\n",
        "import itertools\n",
        "!pip install pymorphy2[fast]\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "morph = MorphAnalyzer()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Requirement already satisfied: pymorphy2[fast] in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (2.4.393442.3710985)\n",
            "Requirement already satisfied: DAWG>=0.7.3; extra == \"fast\" in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.7.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGeOUvuUnOsN",
        "colab_type": "code",
        "outputId": "c97ff3b7-780d-4672-fa40-0a8844bc5bdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/sents_with_mistakes.txt\n",
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/correct_sents.txt\n",
        "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-27 16:54:05--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/sents_with_mistakes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 123167 (120K) [text/plain]\n",
            "Saving to: ‘sents_with_mistakes.txt.2’\n",
            "\n",
            "\r          sents_wit   0%[                    ]       0  --.-KB/s               \rsents_with_mistakes 100%[===================>] 120.28K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-11-27 16:54:06 (3.16 MB/s) - ‘sents_with_mistakes.txt.2’ saved [123167/123167]\n",
            "\n",
            "--2019-11-27 16:54:08--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/correct_sents.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 120672 (118K) [text/plain]\n",
            "Saving to: ‘correct_sents.txt.2’\n",
            "\n",
            "correct_sents.txt.2 100%[===================>] 117.84K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-11-27 16:54:09 (3.09 MB/s) - ‘correct_sents.txt.2’ saved [120672/120672]\n",
            "\n",
            "--2019-11-27 16:54:10--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191127T165410Z&X-Amz-Expires=300&X-Amz-Signature=ad1781749e61d008b91b29e7102db94d152d9650779942c44a0756f020503561&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-11-27 16:54:10--  https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191127T165410Z&X-Amz-Expires=300&X-Amz-Signature=ad1781749e61d008b91b29e7102db94d152d9650779942c44a0756f020503561&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.95.115\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.95.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 527373240 (503M) [application/octet-stream]\n",
            "Saving to: ‘lenta-ru-news.csv.gz.2’\n",
            "\n",
            "lenta-ru-news.csv.g 100%[===================>] 502.94M  60.2MB/s    in 8.7s    \n",
            "\n",
            "2019-11-27 16:54:19 (58.0 MB/s) - ‘lenta-ru-news.csv.gz.2’ saved [527373240/527373240]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqOgS_2_lhVY",
        "colab_type": "text"
      },
      "source": [
        "# Задание 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUtpeAobnWCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
        "true = open('correct_sents.txt', encoding='utf8').read().splitlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zo4-yiut9y9C",
        "colab": {}
      },
      "source": [
        "def norm_txt(text):\n",
        "  new_txt = []\n",
        "  for sent in text:\n",
        "    tokens = sent.lower().split()\n",
        "    tokens = [re.sub('(^\\W+|\\W+$)', '', tkn) for tkn in tokens if (set(tkn)-punct)]\n",
        "    new_txt.append(tokens)\n",
        "  return new_txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqyFcsNz7zsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "badlist = norm_txt(bad)\n",
        "truelist = norm_txt(true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZlaMk6ukbvo",
        "colab_type": "code",
        "outputId": "c601ec78-7d16-48a0-ccad-04ddd6f5394b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(truelist[:5])\n",
        "print(badlist[:5])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['симпатичнейшее', 'шпионское', 'устройство', 'такой', 'себе', 'гламурный', 'фотоаппарат', 'девушки', 'бонда', 'миниатюрная', 'модель', 'камеры', 'superheadz', 'clap', 'camera'], ['апофеозом', 'дня', 'для', 'меня', 'сегодня', 'стала', 'фраза', 'услышанная', 'в', 'новостях'], ['поясним', 'эту', 'мысль'], ['получатся', 'вот', 'такие', 'язычки'], ['в', 'массе', 'своей', 'они', 'конечно', 'все', 'очень', 'милые']]\n",
            "[['симпатичнейшое', 'шпионское', 'устройство', 'такой', 'себе', 'гламурный', 'фотоаппарат', 'девушки', 'бонда', 'миниатюрная', 'модель', 'камеры', 'superheadz', 'clap', 'camera'], ['опофеозом', 'дня', 'для', 'меня', 'сегодня', 'стала', 'фраза', 'услышанная', 'в', 'новостях'], ['пояним', 'эту', 'мысль'], ['полчатся', 'вот', 'такие', 'язычки'], ['в', 'массе', 'своей', 'они', 'конечно', 'все', 'оччччень', 'милые']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raMOgK7aNLXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('corpus_5000.txt', 'w')\n",
        "with gzip.open('lenta-ru-news.csv.gz', 'rt') as archive:\n",
        "    reader = csv.reader(archive, delimiter=',', quotechar='\"')\n",
        "    for i, line in enumerate(reader):\n",
        "        if i < 5000:\n",
        "            f.write(line[2].replace('\\xa0', ' ') + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL0GM9afjdOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(text):\n",
        "    normalized_text = [(word.strip(punctuation)) for word in text.lower().split()] \n",
        "    normalized_text = [word for word in normalized_text if word] \n",
        "    return normalized_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW9awhz1jdPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "for text in open('corpus_5000.txt').read().splitlines():\n",
        "    sents = sent_tokenize(text)\n",
        "    norm_sents = [normalize(sent) for sent in sents]\n",
        "    corpus += norm_sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vftd8H_djdSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WORDS = Counter() \n",
        "for sent in corpus:\n",
        "    WORDS.update(sent)\n",
        "dict_corp = dict(WORDS) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_EPWXMLx_Np",
        "colab_type": "code",
        "outputId": "b0da9d19-0846-4c43-bf6a-d237fab88dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "WORDS.most_common(10)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('в', 41930),\n",
              " ('и', 20346),\n",
              " ('на', 17455),\n",
              " ('что', 11631),\n",
              " ('с', 9616),\n",
              " ('по', 8778),\n",
              " ('не', 7696),\n",
              " ('из', 4369),\n",
              " ('он', 4322),\n",
              " ('о', 3903)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcnrYvtCjdP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set() \n",
        "\n",
        "for sent in corpus:\n",
        "    vocab.update(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgPZb0p8jdU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deletes(word):\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R] \n",
        "    return list(set(deletes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITFBZhH_10bV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_corp2 = {}\n",
        "for word in dict_corp:\n",
        "  for delword in deletes(word):\n",
        "    if delword not in dict_corp2:\n",
        "      dict_corp2[delword] = [word]\n",
        "    else:\n",
        "      dict_corp2[delword].append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "paaR0jPrds81",
        "colab": {}
      },
      "source": [
        "def correction(badword):\n",
        "  if badword in dict_corp:\n",
        "    corrected = badword\n",
        "  else:\n",
        "    bad_forms = deletes(badword)\n",
        "    variants = set()\n",
        "    for form in bad_forms:\n",
        "      if form in dict_corp2:\n",
        "        variants.update(dict_corp2[form])\n",
        "    dict_vars = {} \n",
        "    if variants:\n",
        "      dict_vars = {var:dict_corp[var] for var in list(variants)}\n",
        "      corrected = max(dict_vars, key=dict_vars.get)\n",
        "    else:\n",
        "      corrected = badword\n",
        "  return corrected"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhLL-NRwMUEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corrected_list = []\n",
        "for sent in badlist:\n",
        "  for word in sent:\n",
        "    corrected_list.append(correction(word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiTavtU_Mnaa",
        "colab_type": "code",
        "outputId": "b34ab3b7-8653-4cc4-dff6-b948f6351983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(corrected_list[:20])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['симпатичнейшое', 'шпионской', 'устройство', 'такой', 'себе', 'гламурный', 'фотоаппарат', 'девушки', 'бонда', 'миниатюрная', 'модель', 'камеры', 'superheadz', 'camp', 'camera', 'апофеозом', 'дня', 'для', 'меня', 'сегодня']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXAoQ91Xe_w3",
        "colab_type": "code",
        "outputId": "e42aeffd-9a59-4bb8-94cc-55a3d434a320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "print(correction('сонце'))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "конце\n",
            "CPU times: user 186 µs, sys: 971 µs, total: 1.16 ms\n",
            "Wall time: 1.06 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTbw4v76jda_",
        "colab_type": "code",
        "outputId": "454c7e62-412f-4233-b408-0e22cefcd573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "correction('солнце')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
            "Wall time: 10.3 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'солнце'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmpfmMWPjdbR",
        "colab_type": "code",
        "outputId": "5795bb79-4bba-47f8-9734-6fc7417a8624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "correction('насмехатьсяаававттававаываываы')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 52 µs, sys: 2 µs, total: 54 µs\n",
            "Wall time: 55.8 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'насмехатьсяаававттававаываываы'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpVxB9JrjdFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def align_words(sent_1, sent_2):\n",
        "    tokens_1 = sent_1.lower().split()\n",
        "    tokens_2 = sent_2.lower().split()\n",
        "    \n",
        "    tokens_1 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_1 if (set(token)-punct)]\n",
        "    tokens_2 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_2 if (set(token)-punct)]\n",
        "    \n",
        "    return list(zip(tokens_1, tokens_2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VWCUZIFndPh",
        "colab_type": "code",
        "outputId": "325c516b-7a80-476c-e866-c78155c8215a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(align_words(true[1], bad[1]))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('апофеозом', 'опофеозом'), ('дня', 'дня'), ('для', 'для'), ('меня', 'меня'), ('сегодня', 'сегодня'), ('стала', 'стала'), ('фраза', 'фраза'), ('услышанная', 'услышанная'), ('в', 'в'), ('новостях', 'новостях')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0vOlzPsjdZ6",
        "colab_type": "code",
        "outputId": "15047448-f5f1-456c-b248-2c77d420c5fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "correct = 0 \n",
        "total = 0 \n",
        "\n",
        "total_mistaken = 0 \n",
        "mistaken_fixed = 0 \n",
        "\n",
        "total_correct = 0 \n",
        "correct_broken = 0 \n",
        "\n",
        "cashed = {}\n",
        "for i in range(len(true)):\n",
        "    word_pairs = align_words(true[i], bad[i]) \n",
        "    for pair in word_pairs: \n",
        "        total += 1 \n",
        "        predicted = cashed.get(pair[1], correction(pair[1]))\n",
        "        cashed[pair[0]] = predicted \n",
        "        if predicted == pair[0]: \n",
        "            correct += 1 \n",
        "        \n",
        "        if pair[0] == pair[1]: \n",
        "            total_correct += 1 \n",
        "            if pair[0] !=  predicted: \n",
        "                correct_broken += 1 \n",
        "        else: \n",
        "            total_mistaken += 1 \n",
        "            if pair[0] == predicted:\n",
        "                mistaken_fixed += 1 \n",
        "        \n",
        "    if not i % 100:\n",
        "        print(i)\n",
        "        "
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yyr7knZjdaW",
        "colab_type": "code",
        "outputId": "75f257e5-7026-4f80-ff55-1cd8e024d890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(correct/total) # 订正后总对的数/总词数\n",
        "print(mistaken_fixed/total_mistaken) # 改对了数/总错词数\n",
        "print(correct_broken/total_correct) # 改错了数/本来是对的数"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6821178821178822\n",
            "0.1987720644666155\n",
            "0.24554955782703572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m7avOgrjdHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mistakes = [] \n",
        "total = 0 \n",
        "for i in range(len(true)): \n",
        "    word_pairs = align_words(true[i], bad[i]) \n",
        "    for pair in word_pairs:\n",
        "        total += 1 \n",
        "        if pair[0] != pair[1]: \n",
        "            mistakes.append(pair)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niK7UucpjdcX",
        "colab_type": "code",
        "outputId": "e0232ddb-1d96-4523-8adb-780b8ebb90d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "[(wt[0], wt[1], correction(wt[1])) for wt, _ in Counter(mistakes).most_common(10)] "
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('сегодня', 'седня', 'седан'),\n",
              " ('вообще', 'вобще', 'общей'),\n",
              " ('вообще', 'ваще', 'чаще'),\n",
              " ('естественно', 'естесственно', 'естесственно'),\n",
              " ('хочется', 'хочеться', 'хочеться'),\n",
              " ('кстати', 'кстате', 'статье'),\n",
              " ('очень', 'ооочень', 'ооочень'),\n",
              " ('как-то', 'както', 'актом'),\n",
              " ('очень', 'оооочень', 'оооочень'),\n",
              " ('это', 'ето', 'что')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKwOpUBXlyLm",
        "colab_type": "text"
      },
      "source": [
        "# Задание 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK8hubILb9DJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_tags(text):\n",
        "  tag_sents = [['<start>', '<start>'] + sent + ['<end>'] for sent in text]\n",
        "  return tag_sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfbVS-_UjdmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_corpus = add_tags(corpus)\n",
        "sentences_badlist = add_tags(badlist) # [[s,s,词，词，词，词,e]，[s,词，词，词,e]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l98msVj-3mfF",
        "colab_type": "code",
        "outputId": "8c9b5e9c-a88a-4a0b-9896-16f5f2e429e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(sentences_corpus[:5])\n",
        "print(sentences_badlist[:5])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['<start>', '<start>', 'text', '<end>'], ['<start>', '<start>', 'вице-премьер', 'по', 'социальным', 'вопросам', 'татьяна', 'голикова', 'рассказала', 'в', 'каких', 'регионах', 'россии', 'зафиксирована', 'наиболее', 'высокая', 'смертность', 'от', 'рака', 'сообщает', 'риа', 'новости', '<end>'], ['<start>', '<start>', 'по', 'словам', 'голиковой', 'чаще', 'всего', 'онкологические', 'заболевания', 'становились', 'причиной', 'смерти', 'в', 'псковской', 'тверской', 'тульской', 'и', 'орловской', 'областях', 'а', 'также', 'в', 'севастополе', '<end>'], ['<start>', '<start>', 'вице-премьер', 'напомнила', 'что', 'главные', 'факторы', 'смертности', 'в', 'россии', 'рак', 'и', 'болезни', 'системы', 'кровообращения', '<end>'], ['<start>', '<start>', 'в', 'начале', 'года', 'стало', 'известно', 'что', 'смертность', 'от', 'онкологических', 'заболеваний', 'среди', 'россиян', 'снизилась', 'впервые', 'за', 'три', 'года', '<end>']]\n",
            "[['<start>', '<start>', 'симпатичнейшое', 'шпионское', 'устройство', 'такой', 'себе', 'гламурный', 'фотоаппарат', 'девушки', 'бонда', 'миниатюрная', 'модель', 'камеры', 'superheadz', 'clap', 'camera', '<end>'], ['<start>', '<start>', 'опофеозом', 'дня', 'для', 'меня', 'сегодня', 'стала', 'фраза', 'услышанная', 'в', 'новостях', '<end>'], ['<start>', '<start>', 'пояним', 'эту', 'мысль', '<end>'], ['<start>', '<start>', 'полчатся', 'вот', 'такие', 'язычки', '<end>'], ['<start>', '<start>', 'в', 'массе', 'своей', 'они', 'конечно', 'все', 'оччччень', 'милые', '<end>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw_5wlZLrJNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ngrammer(tokens, n):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(tuple(tokens[i:i+n]))\n",
        "    return ngrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC60y6XVu92R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigrams = Counter()\n",
        "trigrams = Counter()\n",
        "\n",
        "for sentence in sentences_corpus:\n",
        "  bigrams.update(ngrammer(sentence, 2))\n",
        "  trigrams.update(ngrammer(sentence, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS6pPun7wbOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trigrams_badlist = [ngrammer(sentence, 3) for sentence in sentences_badlist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW268vFMUPGv",
        "colab_type": "code",
        "outputId": "5cf36ec4-356b-40e0-d94d-3ad0aaf54f23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(list(trigrams.items())[:5])\n",
        "print(list(bigrams.items())[:5])"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(('<start>', '<start>', 'text'), 1), (('<start>', 'text', '<end>'), 1), (('<start>', '<start>', 'вице-премьер'), 12), (('<start>', 'вице-премьер', 'по'), 2), (('вице-премьер', 'по', 'социальным'), 2)]\n",
            "[(('<start>', '<start>'), 59152), (('<start>', 'text'), 1), (('text', '<end>'), 1), (('<start>', 'вице-премьер'), 12), (('вице-премьер', 'по'), 6)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArWt2RI0wkhI",
        "colab_type": "code",
        "outputId": "ebed37e0-1583-4c58-a8c1-b9c940b81975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(trigrams_badlist[:5])"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[('<start>', '<start>', 'симпатичнейшое'), ('<start>', 'симпатичнейшое', 'шпионское'), ('симпатичнейшое', 'шпионское', 'устройство'), ('шпионское', 'устройство', 'такой'), ('устройство', 'такой', 'себе'), ('такой', 'себе', 'гламурный'), ('себе', 'гламурный', 'фотоаппарат'), ('гламурный', 'фотоаппарат', 'девушки'), ('фотоаппарат', 'девушки', 'бонда'), ('девушки', 'бонда', 'миниатюрная'), ('бонда', 'миниатюрная', 'модель'), ('миниатюрная', 'модель', 'камеры'), ('модель', 'камеры', 'superheadz'), ('камеры', 'superheadz', 'clap'), ('superheadz', 'clap', 'camera'), ('clap', 'camera', '<end>')], [('<start>', '<start>', 'опофеозом'), ('<start>', 'опофеозом', 'дня'), ('опофеозом', 'дня', 'для'), ('дня', 'для', 'меня'), ('для', 'меня', 'сегодня'), ('меня', 'сегодня', 'стала'), ('сегодня', 'стала', 'фраза'), ('стала', 'фраза', 'услышанная'), ('фраза', 'услышанная', 'в'), ('услышанная', 'в', 'новостях'), ('в', 'новостях', '<end>')], [('<start>', '<start>', 'пояним'), ('<start>', 'пояним', 'эту'), ('пояним', 'эту', 'мысль'), ('эту', 'мысль', '<end>')], [('<start>', '<start>', 'полчатся'), ('<start>', 'полчатся', 'вот'), ('полчатся', 'вот', 'такие'), ('вот', 'такие', 'язычки'), ('такие', 'язычки', '<end>')], [('<start>', '<start>', 'в'), ('<start>', 'в', 'массе'), ('в', 'массе', 'своей'), ('массе', 'своей', 'они'), ('своей', 'они', 'конечно'), ('они', 'конечно', 'все'), ('конечно', 'все', 'оччччень'), ('все', 'оччччень', 'милые'), ('оччччень', 'милые', '<end>')]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2_qq7jKSQB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def needed_trigram(ngram, variants):\n",
        "    dict_vars = {}\n",
        "    t_grs = [(ngram[0], ngram[1], variant) for variant in list(variants)]\n",
        "    for tgram in t_grs:\n",
        "        if tgram[:2] in bigrams:\n",
        "            freq_tr = trigrams[tgram]/bigrams[tgram[:2]]\n",
        "            if freq_tr != 0: \n",
        "                dict_vars[tgram[-1]] = freq_tr\n",
        "    \n",
        "    if not dict_vars:  \n",
        "        dict_vars = {var:dict_corp[var] for var in list(variants)}\n",
        "    \n",
        "    return max(dict_vars, key=dict_vars.get)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQL76ybpQTV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trigrams_correction(ngrams): \n",
        "    corrected_sent = []\n",
        "    for ngram in ngrams: # ('<start>', '<start>', 'симпатичнейшое'),\n",
        "        if ngram[-1] in dict_corp: \n",
        "            corrected_sent.append(ngram[-1])\n",
        "        else: \n",
        "            badword = ngram[-1]\n",
        "            bad_forms = deletes(badword)\n",
        "            variants = set()\n",
        "            for form in bad_forms:\n",
        "                if form in dict_corp2:\n",
        "                  variants.update(dict_corp2[form])\n",
        "            if variants:\n",
        "              corrected_sent.append(needed_trigram(ngram, variants))\n",
        "            else:\n",
        "              corrected_sent.append(badword)\n",
        "              \n",
        "    return corrected_sent[:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXTmlDHOQ8Br",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corrected_sents = []\n",
        "for sent in trigrams_badlist: \n",
        "    corrected_sent = trigrams_correction(sent)\n",
        "    corrected_sents.append(corrected_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKBWNx2Y_O2B",
        "colab_type": "code",
        "outputId": "e81cc6ea-f134-4ad3-a6c0-dec3613b9d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(corrected_sents[:5])"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['симпатичнейшое', 'шпионской', 'устройство', 'такой', 'себе', 'гламурный', 'фотоаппарат', 'девушки', 'бонда', 'миниатюрная', 'модель', 'камеры', 'superheadz', 'camp', 'camera'], ['апофеозом', 'дня', 'для', 'меня', 'сегодня', 'стала', 'фраза', 'услышанная', 'в', 'новостях'], ['помним', 'эту', 'мысль'], ['полчатся', 'вот', 'такие', 'язычки'], ['в', 'массе', 'своей', 'они', 'конечно', 'все', 'оччччень', 'милые']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5310bb7d-5234-461d-c62c-6b6adddc0884",
        "id": "aAeUjZ75oKXD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "correct = 0 \n",
        "total = 0 \n",
        "\n",
        "total_mistaken = 0 \n",
        "mistaken_fixed = 0 \n",
        "\n",
        "total_correct = 0 \n",
        "correct_broken = 0 \n",
        "\n",
        "cashed = {}\n",
        "for i in range(len(true)): \n",
        "    word_pairs = align_words(true[i], bad[i]) \n",
        "    sent_corrected = corrected_sents[i] \n",
        "    for j in range(len(word_pairs)): \n",
        "        total += 1\n",
        "        pair = word_pairs[j]\n",
        "        predicted = cashed.get(pair[1], sent_corrected[j]) \n",
        "        cashed[pair[0]] = predicted \n",
        "        if predicted == pair[0]: \n",
        "            correct += 1 \n",
        "        \n",
        "        if pair[0] == pair[1]: \n",
        "            total_correct += 1 \n",
        "            if pair[0] !=  predicted: \n",
        "                correct_broken += 1 \n",
        "        else: \n",
        "            total_mistaken += 1\n",
        "            if pair[0] == predicted: \n",
        "                mistaken_fixed += 1 \n",
        "        \n",
        "    if not i % 100:\n",
        "        print(i)\n",
        "        "
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqZ81PeWjdnN",
        "colab_type": "code",
        "outputId": "7976ce5d-dbba-4335-ed5c-6f527c5c7783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(correct/total)\n",
        "print(mistaken_fixed/total_mistaken)\n",
        "print(correct_broken/total_correct)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.685014985014985\n",
            "0.20721412125863392\n",
            "0.24348225565636844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljvwNdu1spDJ",
        "colab_type": "text"
      },
      "source": [
        "# Оценка\n",
        "Триграммная модель немного улучшила исправление"
      ]
    }
  ]
}