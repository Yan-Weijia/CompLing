{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW0402.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8nKXOkvwXCc4U47JtZb1I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yan-Weijia/CompLing/blob/master/HW0402.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlfTTnM03kZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install deeppavlov"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFgSqu6V5LYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBe-hpGg5MGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get --yes install git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKtKZbaI5Sd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install git+https://github.com/deepmipt/bert.git@feat/multi_gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyecyK6E6SmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciBqxG1v6mr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/pristavki.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Bf7wBP-Q-v0",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('pristavki.csv', header=None, names=['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9JswsnA9aU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Yan-Weijia/CompLing/master/HW04data/test.txt\n",
        "!wget https://raw.githubusercontent.com/Yan-Weijia/CompLing/master/HW04data/train.txt\n",
        "!wget https://raw.githubusercontent.com/Yan-Weijia/CompLing/master/HW04data/valid.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_MW99yi7SAt",
        "colab_type": "code",
        "outputId": "776150dc-c050-4d33-e3d6-51619612cb8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!head train.txt"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Чайковский B-PERSON\r\n",
            "написал O\r\n",
            "всего O\r\n",
            "10 O\r\n",
            "Опер B-WORK_OF_ART\r\n",
            "в O\r\n",
            "своей O\r\n",
            "жизни O\r\n",
            ". O\r\n",
            "Первую O\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tsvydQwjbHo2",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from deeppavlov import configs, build_model, train_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ig-ncJQ9yK4",
        "colab_type": "code",
        "outputId": "9a401713-2bb3-4083-8723-55f13d9d7526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with configs.ner.ner_ontonotes_bert_mult.open(encoding='utf8') as f:\n",
        "    ner_config = json.load(f)\n",
        "\n",
        "ner_config['dataset_reader']['data_path'] = './'  # directory with train.txt, valid.txt and test.txt files\n",
        "ner_config['metadata']['variables']['NER_PATH'] = './'\n",
        "ner_config['metadata']['download'] = [ner_config['metadata']['download'][-1]]  # do not download the pretrained ontonotes model\n",
        "\n",
        "ner_model = train_model(ner_config, download=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-23 04:17:59.342 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip download because of matching hashes\n",
            "2020-01-23 04:17:59.346 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
            "2020-01-23 04:17:59.740 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/tag.dict]\n",
            "2020-01-23 04:17:59.742 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/tag.dict]\n",
            "2020-01-23 04:18:33.582 INFO in 'deeppavlov.models.bert.bert_sequence_tagger'['bert_sequence_tagger'] at line 251: [initializing model with Bert from /root/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-23 04:18:39.573 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 59 tokens with 10 phrases; found: 38 phrases; correct: 0.\n",
            "\n",
            "precision:  0.00%; recall:  0.00%; FB1:  0.00\n",
            "\n",
            "\tCARDINAL: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\tPERSON: precision:  0.00%; recall:  0.00%; F1:  0.00 22\n",
            "\n",
            "\tWORK_OF_ART: precision:  0.00%; recall:  0.00%; F1:  0.00 15\n",
            "\n",
            "\n",
            "2020-01-23 04:18:39.578 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best ner_f1 of 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 1, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 35.9551}, \"time_spent\": \"0:00:03\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 100}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-23 04:20:26.57 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 68 tokens with 15 phrases; found: 12 phrases; correct: 0.\n",
            "\n",
            "precision:  91.67%; recall:  73.33%; FB1:  81.48\n",
            "\n",
            "\tCARDINAL: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tDATE: precision:  100.00%; recall:  100.00%; F1:  100.00 5\n",
            "\n",
            "\tPERSON: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tWORK_OF_ART: precision:  85.71%; recall:  75.00%; F1:  80.00 7\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/trainers/nn_trainer.py:249: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "{\"train\": {\"eval_examples_count\": 1, \"metrics\": {\"ner_f1\": 81.4815, \"ner_token_f1\": 97.1429}, \"time_spent\": \"0:01:49\", \"epochs_done\": 19, \"batches_seen\": 20, \"train_examples_seen\": 20, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 108.72524032592773}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-23 04:20:26.520 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 59 tokens with 10 phrases; found: 12 phrases; correct: 0.\n",
            "\n",
            "precision:  66.67%; recall:  80.00%; FB1:  72.73\n",
            "\n",
            "\tPERSON: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tWORK_OF_ART: precision:  66.67%; recall:  88.89%; F1:  76.19 12\n",
            "\n",
            "\n",
            "2020-01-23 04:20:26.523 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 72.7273\n",
            "2020-01-23 04:20:26.527 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-01-23 04:20:26.671 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 1, \"metrics\": {\"ner_f1\": 72.7273, \"ner_token_f1\": 86.6667}, \"time_spent\": \"0:01:50\", \"epochs_done\": 19, \"batches_seen\": 20, \"train_examples_seen\": 20, \"impatience\": 0, \"patience_limit\": 100}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-23 04:21:26.288 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/tag.dict]\n",
            "2020-01-23 04:21:53.883 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-23 04:22:24.949 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 59 tokens with 10 phrases; found: 12 phrases; correct: 0.\n",
            "\n",
            "precision:  66.67%; recall:  80.00%; FB1:  72.73\n",
            "\n",
            "\tPERSON: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tWORK_OF_ART: precision:  66.67%; recall:  88.89%; F1:  76.19 12\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 1, \"metrics\": {\"ner_f1\": 72.7273, \"ner_token_f1\": 86.6667}, \"time_spent\": \"0:00:03\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-23 04:22:25.453 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 48 tokens with 7 phrases; found: 8 phrases; correct: 0.\n",
            "\n",
            "precision:  12.50%; recall:  14.29%; FB1:  13.33\n",
            "\n",
            "\tDATE: precision:  0.00%; recall:  0.00%; F1:  0.00 3\n",
            "\n",
            "\tPERSON: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tWORK_OF_ART: precision:  20.00%; recall:  20.00%; F1:  20.00 5\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"test\": {\"eval_examples_count\": 1, \"metrics\": {\"ner_f1\": 13.3333, \"ner_token_f1\": 75.3623}, \"time_spent\": \"0:00:01\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-23 04:22:26.430 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/tag.dict]\n",
            "2020-01-23 04:22:54.658 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt2iZekX_glj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "3ddcf432-70c4-46d0-e51a-d435895d90fc"
      },
      "source": [
        "ner_model(['Глинка', 'Чайковский', '«Руслан и Людмила»', 'Дмитрий Дмитрьевич Шостакович'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['Глинка'],\n",
              "  ['Чайковский'],\n",
              "  ['«', 'Руслан', 'и', 'Людмила', '»'],\n",
              "  ['Дмитрий', 'Дмитрьевич', 'Шостакович']],\n",
              " [['I-WORK_OF_ART'],\n",
              "  ['I-WORK_OF_ART'],\n",
              "  ['I-WORK_OF_ART',\n",
              "   'I-WORK_OF_ART',\n",
              "   'I-WORK_OF_ART',\n",
              "   'I-WORK_OF_ART',\n",
              "   'I-WORK_OF_ART'],\n",
              "  ['I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART']]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VKEWNLwhiK-H",
        "colab": {}
      },
      "source": [
        "marked = []\n",
        "\n",
        "for text in data.text.values[:1000]:\n",
        "    # BERT имеет лимит на длину текста в 512 слов, возьмем даже еще меньше\n",
        "    if len(text.split()) > 100:\n",
        "        continue\n",
        "    pred = ner_model([text])\n",
        "    sent, tags = pred[0][0], pred[1][0]\n",
        "    \n",
        "    # достанем только тексты с сущностями\n",
        "    if len(set(tags[0])) > 1:\n",
        "        marked.append(list(zip(sent,tags)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaRntsMQ_-rZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ner_model = build_model(configs.ner.ner_ontonotes_bert_mult, download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}